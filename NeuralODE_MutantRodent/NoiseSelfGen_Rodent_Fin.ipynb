{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e4957d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fourierseries\n",
    "import util\n",
    "import phaser\n",
    "import dataloader\n",
    "# Preprocess data for a single subject - to be send to modeling frameworks\n",
    "def find_phase(k):\n",
    "    \"\"\"\n",
    "    Detrend and compute the phase estimate using Phaser\n",
    "    INPUT:\n",
    "      k -- dataframe\n",
    "    OUTPUT:\n",
    "      k -- dataframe\n",
    "    \"\"\"\n",
    "    #l = ['hip_flexion_l','hip_flexion_r'] # Phase variables = hip flexion angles\n",
    "    y = np.array(k)\n",
    "    print(y.shape)\n",
    "    y = util.detrend(y.T).T\n",
    "    print(y.shape)\n",
    "    phsr = phaser.Phaser(y=y)\n",
    "    k[:] = phsr.phaserEval(y)[0,:]\n",
    "    return k\n",
    "\n",
    "import os\n",
    "import scipy.io\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torch.utils.data import DataLoader\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "samp_trajs_TE = torch.load('samp_trajs_TE_nonoise_Xcoord_tau6k9.pt')\n",
    "samp_trajs_val_TE = torch.load('samp_trajs_val_TE_nonoise_Xcoord_tau6k9.pt')\n",
    "\n",
    "tau = 6\n",
    "k = 9\n",
    "mesured_dim = 10\n",
    "\n",
    "trial_num = 401\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#batch = 1500 #for lstm512\n",
    "batch = 3000 #for lstm256\n",
    "\n",
    "ts_num = 0.25\n",
    "tot_num = 50\n",
    "\n",
    "samp_ts = np.linspace(0, ts_num, num=tot_num)\n",
    "samp_ts = torch.from_numpy(samp_ts).float().to(device)\n",
    "\n",
    "orig_trajs_TE = np.load('orig_trajs_TE_tau6k9_Xcoord.npy')\n",
    "orig_trajs_TE = orig_trajs_TE.reshape(trial_num, 200*34, mesured_dim*(k+1)+2)\n",
    "samp_trajs_TE_test = orig_trajs_TE[:, :tot_num, :]\n",
    "samp_trajs_TE_test = torch.from_numpy(samp_trajs_TE_test).float().to(device).reshape(trial_num, tot_num, mesured_dim*(k+1)+2)\n",
    "\n",
    "#Load to Dataloader\n",
    "train_loader = DataLoader(dataset = samp_trajs_TE, batch_size = batch, shuffle = True, drop_last = True)\n",
    "val_loader = DataLoader(dataset = samp_trajs_TE, batch_size = batch, shuffle = True, drop_last = True)\n",
    "\n",
    "\n",
    "class LatentODEfunc(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, nhidden=50):\n",
    "        super(LatentODEfunc, self).__init__()\n",
    "        #self.tanh = nn.ELU(inplace= True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, nhidden)\n",
    "        self.fc3 = nn.Linear(nhidden, latent_dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "class RecognitionRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, obs_dim=46, nhidden=50, nbatch=1):\n",
    "        super(RecognitionRNN, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.nbatch = nbatch\n",
    "        #self.h1o = nn.Linear(obs_dim, 8)\n",
    "        self.h1o = nn.Linear(obs_dim, 20)\n",
    "        self.h3o = nn.Linear(20, latent_dim*2)\n",
    "        self.lstm = nn.LSTMCell(latent_dim*2, nhidden)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.h2o = nn.Linear(nhidden, latent_dim*2)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        xo = self.h1o(x)\n",
    "        xo = self.tanh(xo)\n",
    "        xxo = self.h3o(xo)\n",
    "        hn, cn = self.lstm(xxo, (h,c))\n",
    "        hn = self.tanh(hn)\n",
    "        out = self.h2o(hn)\n",
    "        return out, hn, cn\n",
    "    \n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.nbatch, self.nhidden)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, obs_dim=46, nhidden=50):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, nhidden*2)\n",
    "        self.fc3 = nn.Linear(nhidden*2, obs_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val\n",
    "\n",
    "\n",
    "def log_normal_pdf(x, mean, logvar):\n",
    "    const = torch.from_numpy(np.array([2. * np.pi])).float().to(x.device)\n",
    "    const = torch.log(const)\n",
    "    return -.5 * (const + logvar + (x - mean) ** 2. / torch.exp(logvar))\n",
    "\n",
    "def mseloss(x, mean):\n",
    "    loss = nn.MSELoss()\n",
    "    return loss(x, mean)\n",
    "\n",
    "def normal_kl(mu1, lv1, mu2, lv2):\n",
    "    v1 = torch.exp(lv1)\n",
    "    v2 = torch.exp(lv2)\n",
    "    lstd1 = lv1 / 2.\n",
    "    lstd2 = lv2 / 2.\n",
    "\n",
    "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
    "    return kl\n",
    "\n",
    "def MSELoss(yhat, y):\n",
    "    assert type(yhat) == torch.Tensor\n",
    "    assert type(y) == torch.Tensor\n",
    "    return torch.mean((yhat - y) ** 2)\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    return {'latent_dim': latent_dim,\n",
    "            'obs_dim': obs_dim,\n",
    "            'nhidden': nhidden,\n",
    "            'dec_nhidden' : dec_nhidden,\n",
    "            'rnn_nhidden': rnn_nhidden,\n",
    "            'device': device}\n",
    "\n",
    "def get_state_dicts():\n",
    "    return {'odefunc_state_dict': func.state_dict(),\n",
    "            'encoder_state_dict': rec.state_dict(),\n",
    "            'decoder_state_dict': dec.state_dict()}\n",
    "\n",
    "def data_get_dict():\n",
    "    return {\n",
    "        'samp_trajs_TE': samp_trajs_TE,\n",
    "        'samp_trajs_val_TE': samp_trajs_val_TE,\n",
    "        'samp_ts': samp_ts,\n",
    "    }\n",
    "\n",
    "def get_losses():\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_losses_k1': val_losses_k1,\n",
    "        'val_losses_k2': val_losses_k2,\n",
    "        'val_losses_k3': val_losses_k3,\n",
    "        'val_losses_k4': val_losses_k4,\n",
    "        'val_losses_k5': val_losses_k5,\n",
    "        'val_losses_k6': val_losses_k6,\n",
    "        'val_losses_k7': val_losses_k7,\n",
    "        'val_losses_k8': val_losses_k8,\n",
    "        'val_losses_k9': val_losses_k9,\n",
    "    }\n",
    "\n",
    "def save_model(tau, k, latent_dim, itr):\n",
    "\n",
    "    save_dict = {\n",
    "        'model_args': get_args(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #'data': data_get_dict(),\n",
    "        'train_loss': get_losses()\n",
    "    }\n",
    "    \n",
    "    save_dict.update(get_state_dicts())\n",
    "    \n",
    "    torch.save(save_dict, 'model/ODE_TakenEmbedding_rnn2_lstm{}_tau{}k{}_LSTM_lr0.008_latent{}_LSTMautoencoder_Dataloader_epoch{}.pth'.format(rnn_nhidden, tau, k, latent_dim, itr))\n",
    "\n",
    "    \n",
    "def data_for_plot_graph(gen_index):\n",
    "    with torch.no_grad():\n",
    "        # sample from trajectorys' approx. posterior\n",
    "\n",
    "        ts_pos = np.linspace(0, 0.25*gen_index, num=50*gen_index)\n",
    "        ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "    \n",
    "        h = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "        c = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "    \n",
    "        hn = h[0, :, :]\n",
    "        cn = c[0, :, :]\n",
    "    \n",
    "        for t in reversed(range(samp_trajs_TE_test.size(1))):\n",
    "            obs = samp_trajs_TE_test[:, t, :]\n",
    "            out, hn, cn = rec.forward(obs, hn, cn)\n",
    "        qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "        epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "        # forward in time and solve ode for reconstructions\n",
    "        pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "        pred_x = dec(pred_z)\n",
    "        \n",
    "        return pred_x, pred_z\n",
    "    \n",
    "def plot_graph(gen_index, times_index, dataset_value, deriv_index, pred_x_forgraph, orig_trajs, itr, path):\n",
    "    with torch.no_grad():\n",
    "        orig_trajs_forgraph = orig_trajs\n",
    "        ts_pos_combined = np.linspace(0, 0.25*gen_index, num=50*gen_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15, 9)) #####MAKE SURE ROW COL MATCHES THE NUM OF FEATURES\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.scatter(ts_pos_combined[times_index:times_index+50*gen_index], orig_trajs_forgraph[dataset_value,times_index:50*gen_index, i*(k+1)+deriv_index], label='sampled data', s = 5)\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+50*gen_index], pred_x_forgraph[dataset_value, times_index:times_index+50*gen_index, i*(k+1)+deriv_index], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "            ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "        plt.legend()\n",
    "        plot_name = 'lstm_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, gen_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()\n",
    "    \n",
    "def load_data_un_normalize(mesured_dim, datafilepath, pred_x_forgraph):\n",
    "    #datafilepath = 'C:/Users/shiny/Documents/NeuralODE_MutantRodent/All_Rodent_concatenated_csv/RodentXcoord_fps200.npy'\n",
    "    data = np.load(datafilepath)\n",
    "    traj_tot = np.load(datafilepath).reshape(trial_num, 9900, mesured_dim)\n",
    "    traj_tot = traj_tot[:,2000:9000,:]\n",
    "    data = data[:, 2000:9000, :]\n",
    "    pred_x_unormalize = pred_x_forgraph[:, : , deriv_index::k][:,:,:mesured_dim]\n",
    "    \n",
    "\n",
    "    X = np.zeros((data.shape[0],pred_x_unormalize.shape[1],data.shape[2]))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[2]):\n",
    "            trajs = pred_x_unormalize[i,:,j]\n",
    "            trajs_tot = traj_tot[i,:,j]\n",
    "            X[i,:,j] = (trajs * trajs_tot.std())+ trajs_tot.mean()\n",
    "            \n",
    "    #samp_trajs += npr.randn(*samp_trajs.shape) * noise_std #add noise\n",
    "\n",
    "    return X\n",
    "\n",
    "def gen_noise(z0, std_lvl):\n",
    "    z0_noise = torch.zeros(z0.shape[0],z0.shape[1]).to(device)\n",
    "    for p in range(pred_z_tot.shape[0]):\n",
    "        for q in range(pred_z_tot.shape[2]):\n",
    "            z0_noise[p,q] = z0[p,q] + pred_z[p,:tot_num*gen_noise_index,q].std()*std_lvl*torch.randn(1).to(device)\n",
    "    return z0_noise\n",
    "\n",
    "def plot_graph_noise_nonoise(times_index, tot_index, dataset_value, deriv_index, itr, path):\n",
    "    with torch.no_grad():\n",
    "        ts_pos_combined = np.linspace(0, ts_num*tot_index, num=tot_num*tot_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_forgraph[dataset_value,times_index:tot_num*tot_index, i*(k+1)+deriv_index], 'r')\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_noise_forgraph[dataset_value, times_index:times_index+tot_num*tot_index, i*(k+1)+deriv_index], 'b')\n",
    "            ax.set_ylim(-3, 3)\n",
    "\n",
    "        \n",
    "        plot_name = 'Noise_vs_Nonoise_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, tot_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "latent_dim = 4\n",
    "nhidden = 64\n",
    "dec_nhidden = 20\n",
    "obs_dim = 10*(k+1)+2\n",
    "rnn_nhidden = 256\n",
    "nitrs = 3000\n",
    "noise_std = 0.2\n",
    "\n",
    "func = LatentODEfunc(latent_dim, nhidden).to(device)\n",
    "rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, batch).to(device)\n",
    "dec = Decoder(latent_dim, obs_dim, dec_nhidden).to(device)\n",
    "params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))\n",
    "optimizer = optim.Adam(params, lr=0.008)\n",
    "loss_meter = RunningAverageMeter()\n",
    "\n",
    "\n",
    "checkpoint = torch.load('model/ODE_Xcoord_TakenEmbedding_rnn2_lstm256_tau6k9_LSTM_lr0.008_latent4_LSTMautoencoder_Dataloader_epoch315.pth')\n",
    "rec.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "func.load_state_dict(checkpoint['odefunc_state_dict'])\n",
    "dec.load_state_dict(checkpoint['decoder_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547217f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_index_tot = [0, 500, 1000, 1500, 2000, 2500]\n",
    "Training_Trial = 4\n",
    "itr=315\n",
    "deriv_index = 5\n",
    "\n",
    "checkpoint = torch.load('model/ODE_Xcoord_TakenEmbedding_rnn2_lstm256_tau6k9_LSTM_lr0.008_latent4_LSTMautoencoder_Dataloader_epoch315.pth')\n",
    "rec.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "func.load_state_dict(checkpoint['odefunc_state_dict'])\n",
    "dec.load_state_dict(checkpoint['decoder_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba45164",
   "metadata": {},
   "source": [
    "## Generate primary data without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e4b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_noise_index = 4\n",
    "total_run = 10\n",
    "tot_index = total_run * gen_noise_index\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    ts_pos = np.linspace(0, ts_num*gen_noise_index*(tot_num*gen_noise_index+1)/(tot_num*gen_noise_index), num=tot_num*gen_noise_index+1)\n",
    "    ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "\n",
    "    h = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "    c = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "\n",
    "    hn = h[0, :, :]\n",
    "    cn = c[0, :, :]\n",
    "\n",
    "    for t in reversed(range(samp_trajs_TE_test.size(1))):\n",
    "        obs = samp_trajs_TE_test[:, t, :]\n",
    "        out, hn, cn = rec.forward(obs, hn, cn)\n",
    "    qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "    epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "    #z0_noise = qz0_mean + epsilon * torch.exp(.5 * qz0_logvar) * 100\n",
    "\n",
    "    # forward in time and solve ode for reconstructions\n",
    "    \n",
    "    for i in range(10):\n",
    "        if i == 0:\n",
    "            pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "            pred_z_tot = np.array(pred_z[:,:tot_num*gen_noise_index,:].detach().cpu().numpy())\n",
    "            #update z0 with noise\n",
    "            z0 = pred_z[:,-1,:] # + noise\n",
    "            pred_x = dec(pred_z)\n",
    "            pred_x_tot = np.array(pred_x[:,:tot_num*gen_noise_index,:].detach().cpu().numpy())\n",
    "        else:\n",
    "            pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "            pred_z_tot = np.append(pred_z_tot, np.array(pred_z[:,:tot_num*gen_noise_index,:].detach().cpu().numpy()), axis =1)\n",
    "            #update z0 with noise\n",
    "            z0 = pred_z[:,-1,:] # + noise\n",
    "            pred_x = dec(pred_z)\n",
    "            pred_x_tot = np.append(pred_x_tot, np.array(pred_x[:,:tot_num*gen_noise_index,:].detach().cpu().numpy()), axis =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20cab4e",
   "metadata": {},
   "source": [
    "### Using the previously generated we will select z from different times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "493de130",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_noise_index = 4\n",
    "total_run = 10\n",
    "tot_index = total_run * gen_noise_index\n",
    "\n",
    "for p in range(10):\n",
    "\n",
    "    total_run = 40\n",
    "    tot_index = total_run * gen_noise_index\n",
    "    std_lvl = 0.3\n",
    "    with torch.no_grad():\n",
    "        z0 = torch.from_numpy(pred_z_tot[:,p*10,:]).float().to(device)\n",
    "        #z0_noise = qz0_mean + epsilon * torch.exp(.5 * qz0_logvar) * 100\n",
    "\n",
    "        # forward in time and solve ode for reconstructions\n",
    "\n",
    "        for i in range(total_run):\n",
    "            if i == 0:\n",
    "                pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "                pred_z_tot_noise = np.array(pred_z[:,:tot_num*gen_noise_index,:].detach().cpu().numpy())\n",
    "                #update z0 with noise\n",
    "                z0 = pred_z[:,-1,:]\n",
    "                z0_noise = gen_noise(z0, std_lvl)\n",
    "                pred_x = dec(pred_z)\n",
    "                pred_x_tot_noise = np.array(pred_x[:,:tot_num*gen_noise_index,:].detach().cpu().numpy())\n",
    "            else:\n",
    "                pred_z = odeint(func, z0_noise, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "                pred_z_tot_noise = np.append(pred_z_tot_noise, np.array(pred_z[:,:tot_num*gen_noise_index,:].detach().cpu().numpy()), axis =1)\n",
    "                #update z0 with noise\n",
    "                z0 = pred_z[:,-1,:]\n",
    "                z0_noise = gen_noise(z0, std_lvl)\n",
    "                pred_x = dec(pred_z)\n",
    "                pred_x_tot_noise = np.append(pred_x_tot_noise, np.array(pred_x[:,:tot_num*gen_noise_index,:].detach().cpu().numpy()), axis =1)\n",
    "                \n",
    "    deriv_index = 5\n",
    "    os.path.join(os.getcwd(), 'All_Rodent_concatenated_csv')\n",
    "    Concatenated_Rodent_path = os.path.join(os.getcwd(), 'All_Rodent_concatenated_csv')\n",
    "    Concatenated_file_name = os.path.join(Concatenated_Rodent_path, 'RodentXcoord_fps200.npy')\n",
    "    unnorm_data = load_data_un_normalize(mesured_dim, Concatenated_file_name, pred_x_tot_noise)\n",
    "    \n",
    "    self_gen_save_path = os.path.join(os.getcwd(), 'Noise_SelfGen_Rodent')\n",
    "    if not os.path.exists(self_gen_save_path):\n",
    "        os.makedirs(self_gen_save_path)\n",
    "    \n",
    "    self_gen_save_path_sub = os.path.join(self_gen_save_path, \"noise_{}\".format(std_lvl))\n",
    "    if not os.path.exists(self_gen_save_path_sub):\n",
    "        os.makedirs(self_gen_save_path_sub)\n",
    "    file_name = \"Rodent_gen{}_trial{}.npy\".format(tot_index, p)\n",
    "    np.save(os.path.join(self_gen_save_path_sub, file_name),unnorm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34007221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
