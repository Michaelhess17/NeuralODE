{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa217dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fourierseries\n",
    "import util\n",
    "import phaser\n",
    "import dataloader\n",
    "# Preprocess data for a single subject - to be send to modeling frameworks\n",
    "def find_phase(k):\n",
    "    \"\"\"\n",
    "    Detrend and compute the phase estimate using Phaser\n",
    "    INPUT:\n",
    "      k -- dataframe\n",
    "    OUTPUT:\n",
    "      k -- dataframe\n",
    "    \"\"\"\n",
    "    #l = ['hip_flexion_l','hip_flexion_r'] # Phase variables = hip flexion angles\n",
    "    y = np.array(k)\n",
    "    print(y.shape)\n",
    "    y = util.detrend(y.T).T\n",
    "    print(y.shape)\n",
    "    phsr = phaser.Phaser(y=y)\n",
    "    k[:] = phsr.phaserEval(y)[0,:]\n",
    "    return k\n",
    "\n",
    "import os\n",
    "import scipy.io\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torch.utils.data import DataLoader\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "samp_trajs_TE = torch.load('samp_trajs_TE_tau18k5_timestep500.pt')\n",
    "samp_trajs_val_TE = torch.load('samp_trajs_val_TE_tau18k5_timestep500.pt')\n",
    "tau = 18\n",
    "k = 5\n",
    "mesured_dim = 6\n",
    "\n",
    "trial_num = 72\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch = 144 #for lstm256\n",
    "learning_rate = 0.008\n",
    "ts_num = 2.5\n",
    "tot_num = 500\n",
    "\n",
    "samp_ts = np.linspace(0, ts_num, num=tot_num)\n",
    "samp_ts = torch.from_numpy(samp_ts).float().to(device)\n",
    "\n",
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6_timestep500.npy')\n",
    "samp_trajs_TE_test = orig_trajs_TE[:, :tot_num, :]\n",
    "samp_trajs_TE_test = torch.from_numpy(samp_trajs_TE_test).float().to(device).reshape(trial_num, tot_num, mesured_dim*(k+1))\n",
    "\n",
    "#Load to Dataloader\n",
    "train_loader = DataLoader(dataset = samp_trajs_TE, batch_size = batch, shuffle = True, drop_last = True)\n",
    "val_loader = DataLoader(dataset = samp_trajs_val_TE, batch_size = batch, shuffle = True, drop_last = True)\n",
    "\n",
    "\n",
    "if not os.path.exists('model'):\n",
    "           os.makedirs('model')\n",
    "        \n",
    "class LatentODEfunc(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, nhidden=50):\n",
    "        super(LatentODEfunc, self).__init__()\n",
    "        #self.tanh = nn.ELU(inplace= True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, nhidden)\n",
    "        self.fc3 = nn.Linear(nhidden, latent_dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "class RecognitionRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, obs_dim=46, nhidden=50, nbatch=1):\n",
    "        super(RecognitionRNN, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.nbatch = nbatch\n",
    "        #self.h1o = nn.Linear(obs_dim, latent_dim*4)\n",
    "        #self.h3o = nn.Linear(latent_dim*4, latent_dim*2)\n",
    "        #self.lstm = nn.LSTMCell(latent_dim*2, nhidden)\n",
    "        self.h1o = nn.Linear(obs_dim, 12)\n",
    "        self.h3o = nn.Linear(12, 6)\n",
    "        self.lstm = nn.LSTMCell(6, nhidden)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.h2o = nn.Linear(nhidden, latent_dim*2)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        xo = self.h1o(x)\n",
    "        xo = self.tanh(xo)\n",
    "        xxo = self.h3o(xo)\n",
    "        hn, cn = self.lstm(xxo, (h,c))\n",
    "        hn = self.tanh(hn)\n",
    "        out = self.h2o(hn)\n",
    "        return out, hn, cn\n",
    "    \n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.nbatch, self.nhidden)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, obs_dim=46, nhidden=50):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, nhidden*2)\n",
    "        self.fc3 = nn.Linear(nhidden*2, obs_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val\n",
    "\n",
    "\n",
    "def log_normal_pdf(x, mean, logvar):\n",
    "    const = torch.from_numpy(np.array([2. * np.pi])).float().to(x.device)\n",
    "    const = torch.log(const)\n",
    "    return -.5 * (const + logvar + (x - mean) ** 2. / torch.exp(logvar))\n",
    "\n",
    "def mseloss(x, mean):\n",
    "    loss = nn.MSELoss()\n",
    "    return loss(x, mean)\n",
    "\n",
    "def normal_kl(mu1, lv1, mu2, lv2):\n",
    "    v1 = torch.exp(lv1)\n",
    "    v2 = torch.exp(lv2)\n",
    "    lstd1 = lv1 / 2.\n",
    "    lstd2 = lv2 / 2.\n",
    "\n",
    "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
    "    return kl\n",
    "\n",
    "def MSELoss(yhat, y):\n",
    "    assert type(yhat) == torch.Tensor\n",
    "    assert type(y) == torch.Tensor\n",
    "    return torch.mean((yhat - y) ** 2)\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    return {'latent_dim': latent_dim,\n",
    "            'obs_dim': obs_dim,\n",
    "            'nhidden': nhidden,\n",
    "            'dec_nhidden' : dec_nhidden,\n",
    "            'rnn_nhidden': rnn_nhidden,\n",
    "            'device': device,\n",
    "            'learning_rate': learning_rate,\n",
    "            'tau': tau,\n",
    "            'k': k}\n",
    "\n",
    "def get_state_dicts():\n",
    "    return {'odefunc_state_dict': func.state_dict(),\n",
    "            'encoder_state_dict': rec.state_dict(),\n",
    "            'decoder_state_dict': dec.state_dict()}\n",
    "\n",
    "def data_get_dict():\n",
    "    return {\n",
    "        'samp_trajs_TE': samp_trajs_TE,\n",
    "        'samp_trajs_val_TE': samp_trajs_val_TE,\n",
    "        'samp_ts': samp_ts,\n",
    "    }\n",
    "\n",
    "def get_losses():\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_losses_k1': val_losses_k1,\n",
    "        'val_losses_k2': val_losses_k2,\n",
    "        'val_losses_k3': val_losses_k3,\n",
    "        'val_losses_k4': val_losses_k4,\n",
    "        'val_losses_k5': val_losses_k5,\n",
    "        'val_losses_k6': val_losses_k6,\n",
    "        'val_losses_k7': val_losses_k7,\n",
    "        'val_losses_k8': val_losses_k8,\n",
    "        'val_losses_k9': val_losses_k9,\n",
    "    }\n",
    "\n",
    "def save_model(Training_Trial, rnn_nhidden, tau, k, lr, latent_dim, itr):\n",
    "\n",
    "    save_dict = {\n",
    "        'model_args': get_args(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #'data': data_get_dict(),\n",
    "        'train_loss': get_losses()\n",
    "    }\n",
    "    \n",
    "    save_dict.update(get_state_dicts())\n",
    "    \n",
    "    torch.save(save_dict, 'model/ODE_Xcoord_Trial{}_TakenEmbedding_rnn2_lstm{}_tau{}k{}_LSTM_lr{}_latent{}_LSTMautoencoder_Dataloader_epoch{}.pth'.format(Training_Trial, rnn_nhidden, tau, k, lr, latent_dim, itr))\n",
    "\n",
    "    \n",
    "def data_for_plot_graph(gen_index):\n",
    "    with torch.no_grad():\n",
    "        # sample from trajectorys' approx. posterior\n",
    "\n",
    "        ts_pos = np.linspace(0, ts_num*gen_index, num=tot_num*gen_index)\n",
    "        ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "    \n",
    "        h = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "        c = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "    \n",
    "        hn = h[0, :, :]\n",
    "        cn = c[0, :, :]\n",
    "    \n",
    "        for t in reversed(range(samp_trajs_TE_test.size(1))):\n",
    "            obs = samp_trajs_TE_test[:, t, :]\n",
    "            out, hn, cn = rec.forward(obs, hn, cn)\n",
    "        qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "        epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "        # forward in time and solve ode for reconstructions\n",
    "        pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "        pred_x = dec(pred_z)\n",
    "        \n",
    "        return pred_x, pred_z\n",
    "    \n",
    "def plot_graph(gen_index, times_index, tot_index, dataset_value, deriv_index, pred_x_forgraph, orig_trajs, itr, path):\n",
    "    with torch.no_grad():\n",
    "        orig_trajs_forgraph = orig_trajs\n",
    "        ts_pos_combined = np.linspace(0, ts_num*tot_index, num=tot_num*tot_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.scatter(ts_pos_combined[times_index:times_index+tot_num*gen_index], orig_trajs_forgraph[dataset_value,times_index:tot_num*gen_index, i*(k+1)+deriv_index], s = 5)\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_forgraph[dataset_value, times_index:times_index+tot_num*tot_index, i*(k+1)+deriv_index], 'r')\n",
    "            ax.set_ylim(-3, 3)\n",
    "\n",
    "        \n",
    "        plot_name = 'lstm_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, tot_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()\n",
    "    \n",
    "def plot_graph_time(gen_index, times_index, dataset_value, deriv_index, pred_x_forgraph, orig_trajs, itr, path):\n",
    "    with torch.no_grad():\n",
    "        orig_trajs_forgraph = orig_trajs\n",
    "        ts_pos_combined = np.linspace(0, ts_num*gen_index, num=tot_num*gen_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9)) #####MAKE SURE ROW COL MATCHES THE NUM OF FEATURES\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.scatter(ts_pos_combined[times_index:times_index+tot_num*gen_index], orig_trajs_forgraph[dataset_value,times_index:tot_num*gen_index, i*(k+1)+deriv_index], label='sampled data', s = 5)\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*gen_index], pred_x_forgraph[dataset_value, times_index:times_index+tot_num*gen_index, i*(k+1)+deriv_index], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "            ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "        plt.legend()\n",
    "        plot_name = 'lstm_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}_time{}.png'.format(dataset_value, latent_dim, gen_index, deriv_index, itr, times_index)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()\n",
    "        \n",
    "def plot_z_graph(gen_index, times_index, dataset_value, deriv_index, pred_z_forgraph, orig_trajs, itr, path):\n",
    "    with torch.no_grad():\n",
    "        orig_trajs_forgraph = orig_trajs\n",
    "        out, hn, cn = rec.forward(orig_trajs)\n",
    "        qz_mean, qz_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "        epsilon = torch.randn(qz_mean.size()).to(device)\n",
    "        z = epsilon * torch.exp(.5 * qz_logvar) + qz_mean\n",
    "        \n",
    "        z_forgraph = z.detach().cpu().numpy()\n",
    "        ts_pos_combined = np.linspace(0, ts_num*gen_index, num=tot_num*gen_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.scatter(ts_pos_combined[times_index:50*gen_index], z_forgraph[dataset_value, 0:50*gen_index, i], label='sampled data', s = 5)\n",
    "            ax.plot(ts_pos_combined[times_index:+50*gen_index], pred_z_forgraph[dataset_value, times_index:+50*gen_index, i], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "            ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "        plt.legend()\n",
    "        plot_name = 'Zgraph_lstm_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, gen_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "latent_dim = 12\n",
    "nhidden = 64\n",
    "dec_nhidden = 12\n",
    "obs_dim = 6*(k+1)\n",
    "rnn_nhidden = 256\n",
    "nitrs = 3000\n",
    "noise_std = 0.2\n",
    "\n",
    "func = LatentODEfunc(latent_dim, nhidden).to(device)\n",
    "rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, batch).to(device)\n",
    "dec = Decoder(latent_dim, obs_dim, dec_nhidden).to(device)\n",
    "params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))\n",
    "optimizer = optim.Adam(params, lr=0.008)\n",
    "loss_meter = RunningAverageMeter()\n",
    "\n",
    "\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import interpolate\n",
    "from scipy.special import iv\n",
    "from numpy import sin,cos,pi,array,linspace,cumsum,asarray,dot,ones\n",
    "from pylab import plot, legend, axis, show, randint, randn, std,lstsq\n",
    "\n",
    "\n",
    "def load_data_un_normalize(Gen_data, obs_dim, datafilepath):\n",
    "    #datafilepath = 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy'\n",
    "    data = np.load(datafilepath)\n",
    "    traj_tot = np.load(datafilepath).reshape(72, 1500, obs_dim)\n",
    "    traj_tot = traj_tot[:,50:1450,:]\n",
    "    pred_x_unormalize = Gen_data[:, : , deriv_index::(k+1)]\n",
    "    \n",
    "\n",
    "    X = np.zeros((data.shape[0],pred_x_unormalize.shape[1],data.shape[2]))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[2]):\n",
    "            trajs = pred_x_unormalize[i,:,j]\n",
    "            trajs_tot = traj_tot[i,:,j]\n",
    "            X[i,:,j] = (trajs * trajs_tot.std())+ trajs_tot.mean()\n",
    "            \n",
    "    #samp_trajs += npr.randn(*samp_trajs.shape) * noise_std #add noise\n",
    "\n",
    "    return X\n",
    "\n",
    "def gen_noise(z0, std_lvl):\n",
    "    z0_noise = torch.zeros(z0.shape[0],z0.shape[1]).to(device)\n",
    "    for p in range(pred_z_tot.shape[0]):\n",
    "        for q in range(pred_z_tot.shape[2]):\n",
    "            z0_noise[p,q] = z0[p,q] + pred_z[p,:tot_num*gen_noise_index,q].std()*std_lvl*torch.randn(1).to(device)\n",
    "    return z0_noise\n",
    "\n",
    "def plot_graph_noise_nonoise(times_index, tot_index, dataset_value, deriv_index, itr, path):\n",
    "    with torch.no_grad():\n",
    "        ts_pos_combined = np.linspace(0, ts_num*tot_index, num=tot_num*tot_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_forgraph[dataset_value,times_index:tot_num*tot_index, i*(k+1)+deriv_index], 'r')\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_noise_forgraph[dataset_value, times_index:times_index+tot_num*tot_index, i*(k+1)+deriv_index], 'b')\n",
    "            ax.set_ylim(-3, 3)\n",
    "\n",
    "        \n",
    "        plot_name = 'Noise_vs_Nonoise_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, tot_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c2d8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph_noise_nonoise(times_index, tot_index, dataset_value, deriv_index, itr, path):\n",
    "    with torch.no_grad():\n",
    "        ts_pos_combined = np.linspace(0, ts_num*tot_index, num=tot_num*tot_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_forgraph[dataset_value,times_index:tot_num*tot_index, i*(k+1)+deriv_index], 'r')\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_noise_forgraph[dataset_value, times_index:times_index+tot_num*tot_index, i*(k+1)+deriv_index], 'b')\n",
    "            ax.set_ylim(-3, 3)\n",
    "\n",
    "        \n",
    "        plot_name = 'Noise_vs_Nonoise_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, tot_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b734b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph_nonoise(times_index, tot_index, dataset_value, deriv_index, itr, path):\n",
    "    with torch.no_grad():\n",
    "        ts_pos_combined = np.linspace(0, ts_num*tot_index, num=tot_num*tot_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_forgraph[dataset_value,times_index:tot_num*tot_index, i*(k+1)+deriv_index], 'r')\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_noise_forgraph[dataset_value, times_index:times_index+tot_num*tot_index, i*(k+1)+deriv_index], 'b')\n",
    "            ax.set_ylim(-3, 3)\n",
    "\n",
    "        \n",
    "        plot_name = 'Nonoise_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, tot_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da762074",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a44d0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_index_tot = [0, 500, 1000, 1500, 2000, 2500]\n",
    "Training_Trial = 2\n",
    "itr = 5325\n",
    "training_model_name = 'model/ODE_Xcoord_Trial{}_TakenEmbedding_rnn2_lstm{}_tau{}k{}_LSTM_lr{}_latent{}_LSTMautoencoder_Dataloader_epoch{}.pth'.format(Training_Trial, rnn_nhidden, tau, k, learning_rate, latent_dim, itr)\n",
    "\n",
    "checkpoint = torch.load('model/ODE_TakenEmbedding_RLONG_rnn2_lstm256_tau18k5_LSTM_lr0.008_latent12_LSTMautoencoder_Dataloader_timestep500_Trial2_epoch5325.pth')\n",
    "rec.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "func.load_state_dict(checkpoint['odefunc_state_dict'])\n",
    "dec.load_state_dict(checkpoint['decoder_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe07110",
   "metadata": {},
   "source": [
    "## Generate primary data without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4458913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_noise_index = 1\n",
    "ts_num = 2.5\n",
    "tot_num = 500\n",
    "total_run = 50\n",
    "std_lvl = 0.5\n",
    "tot_index = total_run * gen_noise_index\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    ts_pos = np.linspace(0, ts_num*gen_noise_index*(tot_num*gen_noise_index+1)/(tot_num*gen_noise_index), num=tot_num*gen_noise_index+1)\n",
    "    ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "\n",
    "    h = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "    c = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "\n",
    "    hn = h[0, :, :]\n",
    "    cn = c[0, :, :]\n",
    "\n",
    "    for t in reversed(range(samp_trajs_TE_test.size(1))):\n",
    "        obs = samp_trajs_TE_test[:, t, :]\n",
    "        out, hn, cn = rec.forward(obs, hn, cn)\n",
    "    qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "    epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "    #z0_noise = qz0_mean + epsilon * torch.exp(.5 * qz0_logvar) * 100\n",
    "\n",
    "    # forward in time and solve ode for reconstructions\n",
    "    \n",
    "    for i in range(total_run):\n",
    "        if i == 0:\n",
    "            pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "            pred_z_tot = np.array(pred_z[:,:tot_num*gen_noise_index,:].detach().cpu().numpy())\n",
    "            #update z0 with noise\n",
    "            z0 = pred_z[:,-1,:] # + noise\n",
    "            pred_x = dec(pred_z)\n",
    "            pred_x_tot = np.array(pred_x[:,:tot_num*gen_noise_index,:].detach().cpu().numpy())\n",
    "        else:\n",
    "            pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "            pred_z_tot = np.append(pred_z_tot, np.array(pred_z[:,:tot_num*gen_noise_index,:].detach().cpu().numpy()), axis =1)\n",
    "            #update z0 with noise\n",
    "            z0 = pred_z[:,-1,:] # + noise\n",
    "            pred_x = dec(pred_z)\n",
    "            pred_x_tot = np.append(pred_x_tot, np.array(pred_x[:,:tot_num*gen_noise_index,:].detach().cpu().numpy()), axis =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61af976",
   "metadata": {},
   "source": [
    "## Generate without noise, for fly and rodents, need to genereate starting near limit cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a4b84f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_noise_index = 1\n",
    "ts_num = 2.5\n",
    "tot_num = 500\n",
    "total_run = 50\n",
    "std_lvl = 0.5\n",
    "tot_index = total_run * gen_noise_index\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    ts_pos = np.linspace(0, ts_num*gen_noise_index*(tot_num*gen_noise_index+1)/(tot_num*gen_noise_index), num=tot_num*gen_noise_index+1)\n",
    "    ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "\n",
    "    h = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "    c = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "\n",
    "    hn = h[0, :, :]\n",
    "    cn = c[0, :, :]\n",
    "\n",
    "    for t in reversed(range(samp_trajs_TE_test.size(1))):\n",
    "        obs = samp_trajs_TE_test[:, t, :]\n",
    "        out, hn, cn = rec.forward(obs, hn, cn)\n",
    "    qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "    epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "    #z0_noise = qz0_mean + epsilon * torch.exp(.5 * qz0_logvar) * 100\n",
    "\n",
    "    # forward in time and solve ode for reconstructions\n",
    "    \n",
    "    for i in range(total_run):\n",
    "        if i == 0:\n",
    "            pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "            pred_z_tot_noise = np.array(pred_z[:,:tot_num*gen_noise_index,:].detach().cpu().numpy())\n",
    "            #update z0 with noise\n",
    "            z0 = pred_z[:,-1,:]\n",
    "            z0_noise = gen_noise(z0, std_lvl)\n",
    "            pred_x = dec(pred_z)\n",
    "            pred_x_tot_noise = np.array(pred_x[:,:tot_num*gen_noise_index,:].detach().cpu().numpy())\n",
    "        else:\n",
    "            pred_z = odeint(func, z0_noise, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "            pred_z_tot_noise = np.append(pred_z_tot_noise, np.array(pred_z[:,:tot_num*gen_noise_index,:].detach().cpu().numpy()), axis =1)\n",
    "            #update z0 with noise\n",
    "            z0 = pred_z[:,-1,:]\n",
    "            z0_noise = gen_noise(z0, std_lvl)\n",
    "            pred_x = dec(pred_z)\n",
    "            pred_x_tot_noise = np.append(pred_x_tot_noise, np.array(pred_x[:,:tot_num*gen_noise_index,:].detach().cpu().numpy()), axis =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5a110e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x_noise_forgraph = pred_x_tot_noise\n",
    "pred_z_noise_forgraph = pred_z_tot_noise\n",
    "pred_x_forgraph = pred_x_tot\n",
    "\n",
    "#limit_x_forgraph = pred_x_forgraph[:, 2500:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a50c21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"NoiseComparison/tau{}k{}/longtimeseries/latent{}/lstm{}_lr0.008_timestep{}epoch{}_test/std{}\".format(tau, k, latent_dim, rnn_nhidden, tot_num, itr, std_lvl)\n",
    "times_index = 0 \n",
    "deriv_index = 3\n",
    "if not os.path.exists(path):\n",
    "   os.makedirs(path)\n",
    "\n",
    "for i in range(trial_num):\n",
    "    plot_graph_noise_nonoise(times_index, tot_index, i, deriv_index, itr, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb7fc7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 15000, 36)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_x_noise_forgraph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49fc342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_un_normalize(Gen_data, obs_dim, datafilepath):\n",
    "    #datafilepath = 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy'\n",
    "    data = np.load(datafilepath)\n",
    "    traj_tot = np.load(datafilepath).reshape(72, 1500, obs_dim)\n",
    "    traj_tot = traj_tot[:,50:1450,:]\n",
    "    pred_x_unormalize = Gen_data[:, : , deriv_index::(k+1)]\n",
    "    \n",
    "\n",
    "    X = np.zeros((data.shape[0],pred_x_unormalize.shape[1],data.shape[2]))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[2]):\n",
    "            trajs = pred_x_unormalize[i,:,j]\n",
    "            trajs_tot = traj_tot[i,:,j]\n",
    "            X[i,:,j] = (trajs * trajs_tot.std())+ trajs_tot.mean()\n",
    "            \n",
    "    #samp_trajs += npr.randn(*samp_trajs.shape) * noise_std #add noise\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5e88b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x_forgraph_noise = load_data_un_normalize(pred_x_noise_forgraph, 6, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bbfdca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('std0.5humangait_40gen.npy', pred_x_forgraph_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd847079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 15000, 6)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_x_forgraph_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022643da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
