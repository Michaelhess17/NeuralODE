{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "621560c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4c3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_normalize(obs_dim, datafilepath):\n",
    "    datafilepath = 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy'\n",
    "    data = np.load(datafilepath)\n",
    "    traj_tot = np.load(datafilepath).reshape(72, 1500, obs_dim)\n",
    "    traj_tot = traj_tot[:,150:1350,:]\n",
    "    data = data[:, 300:1300, :]\n",
    "    data = data.reshape(72, 1000, obs_dim)\n",
    "    noise_std = 0.2\n",
    "\n",
    "    orig_trajs = np.zeros((data.shape[0],data.shape[1],data.shape[2]))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[2]):\n",
    "            trajs = data[i,:,j]\n",
    "            trajs_tot = traj_tot[i,:,j]\n",
    "            orig_trajs[i,:,j] = (trajs - trajs_tot.mean()) / trajs_tot.std()\n",
    "            \n",
    "    #samp_trajs += npr.randn(*samp_trajs.shape) * noise_std #add noise\n",
    "\n",
    "    return orig_trajs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facbf8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_normalize(obs_dim, datafilepath):\n",
    "    datafilepath = 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy'\n",
    "    data = np.load(datafilepath)\n",
    "    traj_tot = np.load(datafilepath).reshape(72, 1500, obs_dim)\n",
    "    traj_tot = traj_tot[:,50:1450,:]\n",
    "    data = data[:, 50:1450, :]\n",
    "    data = data.reshape(72, 1400, obs_dim)\n",
    "    noise_std = 0.2\n",
    "\n",
    "    orig_trajs = np.zeros((data.shape[0],data.shape[1],data.shape[2]))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[2]):\n",
    "            trajs = data[i,:,j]\n",
    "            trajs_tot = traj_tot[i,:,j]\n",
    "            orig_trajs[i,:,j] = (trajs - trajs_tot.mean()) / trajs_tot.std()\n",
    "            \n",
    "    #samp_trajs += npr.randn(*samp_trajs.shape) * noise_std #add noise\n",
    "\n",
    "    return orig_trajs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c91a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takenembedding(data, tau, k, obs_dim, device):\n",
    "    data_TE = np.zeros((data.shape[0], data.shape[1]-tau*k, data.shape[2]), dtype = object)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[2]):\n",
    "            for t in range(data.shape[1]-tau*k):\n",
    "                data_TE[i,t,j] = data[i, t:t+tau*k+1, j][::tau][::-1]\n",
    "                \n",
    "    data_TE = np.array(data_TE.tolist())\n",
    "    data_TE = data_TE.reshape(data_TE.shape[0],data_TE.shape[1],obs_dim*(k+1))\n",
    "    \n",
    "    return data_TE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9f4ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data_normalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m obs_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m orig_trajs \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_normalize\u001b[49m(obs_dim, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m orig_trajs_TE \u001b[38;5;241m=\u001b[39m takenembedding(orig_trajs, tau, k, obs_dim, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data_normalize' is not defined"
     ]
    }
   ],
   "source": [
    "npr.seed(42)\n",
    "tau = 18\n",
    "k = 5\n",
    "\n",
    "obs_dim = 6\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "orig_trajs = load_data_normalize(obs_dim, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')\n",
    "\n",
    "orig_trajs_TE = takenembedding(orig_trajs, tau, k, obs_dim, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8e4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(42)\n",
    "tau = 18\n",
    "k = 5\n",
    "\n",
    "obs_dim = 6\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "orig_trajs = load_data_normalize(obs_dim, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')\n",
    "\n",
    "orig_trajs_TE = takenembedding(orig_trajs, tau, k, obs_dim, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9e981de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "axes = axes.flatten()\n",
    "gen_index = 10\n",
    "dataset_value = 58\n",
    "times_index = 0\n",
    "deriv_index=0\n",
    "ts_pos_combined = np.linspace(0, 0.25*gen_index, num=50*gen_index) \n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(ts_pos_combined[times_index:times_index+50*gen_index], orig_trajs[dataset_value,times_index:times_index+50*gen_index, i])\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "        \n",
    "plot_name = 'lookingatwhole_dataset{}.png'.format(dataset_value)\n",
    "plt.savefig(plot_name, dpi=500)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17777442",
   "metadata": {},
   "source": [
    "## Data for comparing two data RNN VS ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eef7580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs = np.load('C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "801a285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_data = np.load('C:/Users/shiny/Documents/NeuralODE_HumanGait/UNIT_512_LB_499_All_preds_with_smallest_noise.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3195480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "axes = axes.flatten()\n",
    "gen_index = 30\n",
    "dataset_value = 4\n",
    "times_index = 0\n",
    "deriv_index=0\n",
    "plot_index = 1500\n",
    "tot_index = 80\n",
    "ts_pos_combined = np.linspace(0, 0.25*tot_index, num=50*tot_index) \n",
    "for i, ax in enumerate(axes):\n",
    "    ax.scatter(ts_pos_combined[times_index:times_index+50*gen_index], second_orig_trajs[dataset_value,times_index:times_index+50*gen_index, i], s = 5)\n",
    "    ax.plot(ts_pos_combined[times_index:times_index+50*tot_index], RNN_data[dataset_value,times_index:times_index+50*tot_index, i],'r')\n",
    "    \n",
    "plot_name = 'Comparingtwodatasets_{}.png'.format(dataset_value)\n",
    "plt.savefig(plot_name, dpi=500)\n",
    "plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd6403ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "    axes = axes.flatten()\n",
    "    gen_index = 30\n",
    "    dataset_value = i\n",
    "    times_index = 0\n",
    "    deriv_index=0\n",
    "    plot_index = 1500\n",
    "    tot_index = 100\n",
    "    ts_pos_combined = np.linspace(0, 0.25*tot_index, num=50*tot_index) \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.scatter(ts_pos_combined[times_index:times_index+50*gen_index], second_orig_trajs[dataset_value,times_index:times_index+50*gen_index, i], s = 5)\n",
    "        ax.plot(ts_pos_combined[times_index:times_index+50*tot_index], RNN_data[dataset_value,times_index:times_index+50*tot_index, i],'r')\n",
    "\n",
    "    plot_name = 'Comparingtwodatasets_{}.png'.format(dataset_value)\n",
    "    plt.savefig(plot_name, dpi=500)\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d755f",
   "metadata": {},
   "source": [
    "## Adding Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02fc26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "speed = scipy.io.loadmat('SpeedLabels.mat')\n",
    "speed_label = speed['SpeedTrainTrials']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d5e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b3a2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((orig_trajs_TE.shape[0],orig_trajs_TE.shape[1],1))\n",
    "\n",
    "for i in range(orig_trajs_TE.shape[0]):\n",
    "    X[i, :, 0] = speed_label[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aafeef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.concatenate((orig_trajs_TE, X), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59ec05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('orig_trajs_TE_tau18k5_raw.npy',orig_trajs_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d79ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 6\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "orig_trajs = load_data_normalize(obs_dim, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d234a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((orig_trajs.shape[0],orig_trajs.shape[1],1))\n",
    "\n",
    "for i in range(orig_trajs.shape[0]):\n",
    "    X[i, :, 0] = speed_label[i]/100\n",
    "    \n",
    "orig_trajs_speed = np.concatenate((orig_trajs, X), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75d833c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 1000, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_trajs_speed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4dc8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('orig_trajs_speed.npy', orig_trajs_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88b6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(42)\n",
    "tau = 18\n",
    "k = 5\n",
    "\n",
    "obs_dim = 6\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e83057",
   "metadata": {},
   "source": [
    "## Creating Maximal LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b76c9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 1310, 36)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_trajs_TE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "645f11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('orig_trajs_TE_tau18k6_timestep500.npy', orig_trajs_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa1a91cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6_timestep500.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :1300, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72, 1300, obs_dim*(k+1))\n",
    "\n",
    "\n",
    "samp_trajs_TE = np.zeros((72*8, 500, obs_dim*(k+1)))\n",
    "samp_trajs_TE = torch.from_numpy(samp_trajs_TE).float().to(device)\n",
    "samplepoint = [0, 100, 200 ,300, 400 ,500, 600, 700]\n",
    "for j in range(72):\n",
    "    for i in range(8):\n",
    "        samp_trajs_TE[8*j+i,:, :] = orig_trajs_TE[j, samplepoint[i]:samplepoint[i]+500,:]\n",
    "    \n",
    "    \n",
    "samplepoint_val_TE = np.zeros((72*1, 500, obs_dim*(k+1)))\n",
    "samplepoint_val_TE = torch.from_numpy(samplepoint_val_TE).float().to(device)\n",
    "samplepoint_val = [800]    \n",
    "for j in range(72):\n",
    "    for i in range(1):\n",
    "        samplepoint_val_TE[1*j+i,:, :] = orig_trajs_TE[j, samplepoint_val[i]:samplepoint_val[i]+500,:]\n",
    "        \n",
    "        \n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k5_timestep500.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k5_timestep500.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4827c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([576, 500, 36])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_trajs_TE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad685716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ad2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8aa7f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k5_raw.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72, 900, obs_dim*(k+1)+1)\n",
    "\n",
    "\n",
    "samp_trajs_TE = np.zeros((72*6, 300, obs_dim*(k+1)+1))\n",
    "samp_trajs_TE = torch.from_numpy(samp_trajs_TE).float().to(device)\n",
    "samplepoint = [0, 100, 200 ,300, 400 ,500]\n",
    "for j in range(72):\n",
    "    for i in range(6):\n",
    "        samp_trajs_TE[6*j+i,:, :] = orig_trajs_TE[j, samplepoint[i]:samplepoint[i]+300,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "samp_trajs_val_TE = orig_trajs_TE[:, 600:900, :]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k5_raw_rlong.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k5_raw_rlong.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c71081a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k5.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72, 900, obs_dim*(k+1)+1)\n",
    "\n",
    "\n",
    "samp_trajs_TE = np.zeros((72*6, 300, obs_dim*(k+1)+1))\n",
    "samp_trajs_TE = torch.from_numpy(samp_trajs_TE).float().to(device)\n",
    "samplepoint = [0, 100, 200 ,300, 400 ,500]\n",
    "for j in range(72):\n",
    "    for i in range(6):\n",
    "        samp_trajs_TE[6*j+i,:, :] = orig_trajs_TE[j, samplepoint[i]:samplepoint[i]+300,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "samp_trajs_val_TE = orig_trajs_TE[:, 600:900, :]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k5_rlong.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k5_rlong.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a932dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b68e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k5.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72, 900, obs_dim*(k+1)+1)\n",
    "\n",
    "\n",
    "samp_trajs_TE = np.zeros((72*6, 300, obs_dim*(k+1)+1))\n",
    "samp_trajs_TE = torch.from_numpy(samp_trajs_TE).float().to(device)\n",
    "samplepoint = [0, 100, 200 ,300, 400 ,500]\n",
    "for j in range(72):\n",
    "    for i in range(6):\n",
    "        samp_trajs_TE[6*j+i,:, :] = orig_trajs_TE[j, samplepoint[i]:samplepoint[i]+300,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "samp_trajs_val_TE = orig_trajs_TE[:, 600:900, :]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k5_rlong.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k5_rlong.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bcd9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k5.npy')\n",
    "person = 0\n",
    "orig_trajs_TE = orig_trajs_TE[person*6:(person+1)*6, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(6*3, 300, obs_dim*(k+1)+1)\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:15]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[15:18]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_person{}_tau18k5_rlong.pt'.format(person))\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_person{}_tau18k5_rlong.pt'.format(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e13ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE EACH PERSON A SAMPLE!\n",
    "\n",
    "for i in range(12):\n",
    "    person = i\n",
    "    orig_trajs_TE = np.load('orig_trajs_TE_tau18k6.npy')\n",
    "    orig_trajs_TE = orig_trajs_TE[person*6:(person+1)*6, :900, :]\n",
    "    orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(6, 900, obs_dim*(k+1))\n",
    "    \n",
    "    samp_trajs_TE = np.zeros((6*6, 300, obs_dim*(k+1)))\n",
    "    samp_trajs_TE = torch.from_numpy(samp_trajs_TE).float().to(device)\n",
    "    samplepoint = [0, 100, 200 ,300, 400 ,500]\n",
    "    for j in range(6):\n",
    "        for k in range(6):\n",
    "            samp_trajs_TE[6*j+k,:, :] = orig_trajs_TE[j, samplepoint[k]:samplepoint[k]+300,:]\n",
    "    \n",
    "    samp_trajs_val_TE = orig_trajs_TE[:, 600:900, :]\n",
    "\n",
    "    \n",
    "    torch.save(samp_trajs_TE, 'samp_trajs_TE_person{}_tau18k6_rlong.pt'.format(person))\n",
    "    torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_person{}_tau18k6_rlong.pt'.format(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd31e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46997f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4442c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a78db35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72, 900, obs_dim*(k+1))\n",
    "\n",
    "\n",
    "samp_trajs_TE = np.zeros((72*6, 300, obs_dim*(k+1)))\n",
    "samp_trajs_TE = torch.from_numpy(samp_trajs_TE).float().to(device)\n",
    "samplepoint = [0, 100, 200 , 300,  400 , 500]\n",
    "for j in range(72):\n",
    "    for i in range(len(samplepoint)):\n",
    "        samp_trajs_TE[6*j+i,:, :] = orig_trajs_TE[j, samplepoint[i]:samplepoint[i]+300,:]\n",
    "        \n",
    "        \n",
    "samp_trajs_val_TE = np.zeros((72*1, 300, obs_dim*(k+1)))\n",
    "samp_trajs_val_TE = torch.from_numpy(samp_trajs_val_TE).float().to(device)\n",
    "samplepoint_val = [600]\n",
    "\n",
    "for j in range(72):\n",
    "    for i in range(len(samplepoint_val)):\n",
    "        samp_trajs_val_TE[len(samplepoint_val)*j+i,:, :] = orig_trajs_TE[j, samplepoint_val[i]:samplepoint_val[i]+300,:]    \n",
    "    \n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k6_rlong.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k6_rlong.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a29ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72*6, 150, obs_dim*(k+1))\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:360]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[360:432]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k6_long.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k6_long.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d0d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_speed.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72*3, 300, obs_dim+1)\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:36*5]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[180:216]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_speed_rlong.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_speed_rlong.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "299c0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_speed.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72*9, 100, obs_dim+1)\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:36*15]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[540:72*9]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_speed.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_speed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8baf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k5.npy')\n",
    "person = 0\n",
    "orig_trajs_TE = orig_trajs_TE[person*6:(person+1)*6, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(6*9, 100, obs_dim*(k+1)+1)\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:45]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[45:54]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_person{}_tau18k5.pt'.format(person))\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_person{}_tau18k5.pt'.format(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0228c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k5.npy')\n",
    "person = 0\n",
    "orig_trajs_TE = orig_trajs_TE[person*6:(person+1)*6, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(6*3, 300, obs_dim*(k+1)+1)\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:15]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[15:18]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_person{}_tau18k5_rlong.pt'.format(person))\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_person{}_tau18k5_rlong.pt'.format(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffae6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    person = i\n",
    "    orig_trajs_TE = np.load('orig_trajs_TE_tau18k5.npy')\n",
    "    orig_trajs_TE = orig_trajs_TE[person*6:(person+1)*6, :900, :]\n",
    "    orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(6*9, 100, obs_dim*(k+1)+1)\n",
    "    \n",
    "    perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "    samp_trajs_TE = orig_trajs_TE[perm_index[:45]]\n",
    "    samp_trajs_val_TE = orig_trajs_TE[perm_index[45:54]]\n",
    "    \n",
    "    torch.save(samp_trajs_TE, 'samp_trajs_TE_person{}_tau18k5.pt'.format(person))\n",
    "    torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_person{}_tau18k5.pt'.format(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    person = i\n",
    "    orig_trajs_TE = np.load('orig_trajs_TE_tau18k5.npy')\n",
    "    orig_trajs_TE = orig_trajs_TE[person*6:(person+1)*6, :900, :]\n",
    "    orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(6*3, 300, obs_dim*(k+1)+1)\n",
    "    \n",
    "    perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "    samp_trajs_TE = orig_trajs_TE[perm_index[:15]]\n",
    "    samp_trajs_val_TE = orig_trajs_TE[perm_index[15:18]]\n",
    "    \n",
    "    torch.save(samp_trajs_TE, 'samp_trajs_TE_person{}_tau18k5_rlong.pt'.format(person))\n",
    "    torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_person{}_tau18k5_rlong.pt'.format(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4248d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k5.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72*3, 300, obs_dim*(k+1)+1)\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:36*5]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[180:216]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k5_rlong.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k5_rlong.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb7c253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72*6, 150, obs_dim*(k+1))\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:360]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[360:432]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k6_long.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k6_long.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e24a5095",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :900, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72*18, 50, obs_dim*(k+1))\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:900]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[900:1200]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k6_short.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k6_short.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fc6d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6.npy')\n",
    "orig_trajs_TE = orig_trajs_TE[:, :875, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(72*5, 175, obs_dim*(k+1))\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:300]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[300:360]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_tau18k6_longer.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_tau18k6_longer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09b5ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 175, 36])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_trajs_TE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7185a8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2307, -0.8338,  0.0083,  0.4351])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "157e0691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1553)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "874bd4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau6k9.npy')\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(203*34*4, 50, obs_dim*(k+1)+2)\n",
    "\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:3600]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[4000:4600]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_nonoise_tau6k9.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_nonoise_tau6k9.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a0c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau6k9.npy')\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(203*34*4, 50, obs_dim*(k+1)+2)\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:15000]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[21000:24000]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_nonoise_tau6k9_long.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_nonoise_tau6k9_long.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8dbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau6k3.npy')\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(203*34*2, 100, obs_dim*(k+1)+2)\n",
    "\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:1500]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[4000:4200]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_nonoise_tau6k3_timestep100.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_nonoise_tau6k3_timestep100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a9637f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau6k3.npy')\n",
    "orig_trajs_TE = orig_trajs_TE.reshape(203, 34*200, obs_dim*(k+1)+2)[:, :2000, :]\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(203*10*2, 100, obs_dim*(k+1)+2)\n",
    "\n",
    "\n",
    "perm_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_TE = orig_trajs_TE[perm_index[:1500]]\n",
    "samp_trajs_val_TE = orig_trajs_TE[perm_index[1500:1800]]\n",
    "\n",
    "torch.save(samp_trajs_TE, 'samp_trajs_TE_nonoise_tau6k3_timestep100.pt')\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_val_TE_nonoise_tau6k3_timestep100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs_TE = np.load('orig_trajs_TE_tau6k3.npy')\n",
    "\n",
    "orig_trajs_TE = torch.from_numpy(orig_trajs_TE).float().to(device).reshape(203*34, 200, obs_dim*(k+1)+2)\n",
    "\n",
    "val_index = torch.randperm(orig_trajs_TE.shape[0])\n",
    "samp_trajs_val_TE = orig_trajs_TE[val_index[:1000]]\n",
    "\n",
    "torch.save(samp_trajs_val_TE, 'samp_trajs_TE_4cycle_tau6k3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_trajs_TE = torch.load('samp_trajs_TE_nonoise_tau6k3.pt')\n",
    "samp_trajs_val_TE = torch.load('samp_trajs_val_TE_nonoise_tau6k3.pt')\n",
    "\n",
    "tau = 6\n",
    "k = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "samp_ts = np.linspace(0, 0.25, num=50)\n",
    "samp_ts = torch.from_numpy(samp_ts).float().to(device)\n",
    "\n",
    "orig_trajs_TE = np.load('orig_trajs_TE_tau6k3.npy')\n",
    "orig_trajs_TE = orig_trajs_TE.reshape(203, 200*34, 31*(k+1)+2)\n",
    "samp_trajs_TE_test = orig_trajs_TE[:, :50, :]\n",
    "samp_trajs_TE_test = torch.from_numpy(samp_trajs_TE_test).float().to(device).reshape(203, 50, 31*(k+1)+2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
