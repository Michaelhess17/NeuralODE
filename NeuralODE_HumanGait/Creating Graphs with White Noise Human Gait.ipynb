{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d40171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running phaser\n"
     ]
    }
   ],
   "source": [
    "import fourierseries\n",
    "import util\n",
    "import phaser\n",
    "import dataloader\n",
    "# Preprocess data for a single subject - to be send to modeling frameworks\n",
    "def find_phase(k):\n",
    "    \"\"\"\n",
    "    Detrend and compute the phase estimate using Phaser\n",
    "    INPUT:\n",
    "      k -- dataframe\n",
    "    OUTPUT:\n",
    "      k -- dataframe\n",
    "    \"\"\"\n",
    "    #l = ['hip_flexion_l','hip_flexion_r'] # Phase variables = hip flexion angles\n",
    "    y = np.array(k)\n",
    "    print(y.shape)\n",
    "    y = util.detrend(y.T).T\n",
    "    print(y.shape)\n",
    "    phsr = phaser.Phaser(y=y)\n",
    "    k[:] = phsr.phaserEval(y)[0,:]\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aafc4f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torch.utils.data import DataLoader\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "samp_trajs_TE = torch.load('samp_trajs_TE_tau18k5_timestep500.pt')\n",
    "samp_trajs_val_TE = torch.load('samp_trajs_val_TE_tau18k5_timestep500.pt')\n",
    "\n",
    "tau = 18\n",
    "k = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch = 144\n",
    "trial_num = 72\n",
    "ts_num = 2.5\n",
    "tot_num = 500\n",
    "\n",
    "samp_ts = np.linspace(0, ts_num, num=tot_num)\n",
    "samp_ts = torch.from_numpy(samp_ts).float().to(device)\n",
    "\n",
    "orig_trajs_TE = np.load('orig_trajs_TE_tau18k6_timestep500.npy')\n",
    "orig_trajs_TE = orig_trajs_TE.reshape(72, 1310, 6*(k+1))\n",
    "samp_trajs_TE_test = orig_trajs_TE[:, :tot_num, :]\n",
    "samp_trajs_TE_test = torch.from_numpy(samp_trajs_TE_test).float().to(device).reshape(72, tot_num, 6*(k+1))\n",
    "\n",
    "#Load to Dataloader\n",
    "train_loader = DataLoader(dataset = samp_trajs_TE, batch_size = batch, shuffle = True, drop_last = True)\n",
    "val_loader = DataLoader(dataset = samp_trajs_TE, batch_size = 72, shuffle = True, drop_last = True)\n",
    "\n",
    "\n",
    "\n",
    "class LatentODEfunc(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, nhidden=50):\n",
    "        super(LatentODEfunc, self).__init__()\n",
    "        #self.tanh = nn.ELU(inplace= True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, nhidden)\n",
    "        self.fc3 = nn.Linear(nhidden, latent_dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "class RecognitionRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, obs_dim=46, nhidden=50, nbatch=1):\n",
    "        super(RecognitionRNN, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.nbatch = nbatch\n",
    "        #self.h1o = nn.Linear(obs_dim, latent_dim*4)\n",
    "        #self.h3o = nn.Linear(latent_dim*4, latent_dim*2)\n",
    "        #self.lstm = nn.LSTMCell(latent_dim*2, nhidden)\n",
    "        self.h1o = nn.Linear(obs_dim, 12)\n",
    "        self.h3o = nn.Linear(12, 6)\n",
    "        self.lstm = nn.LSTMCell(6, nhidden)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.h2o = nn.Linear(nhidden, latent_dim*2)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        xo = self.h1o(x)\n",
    "        xo = self.tanh(xo)\n",
    "        xxo = self.h3o(xo)\n",
    "        hn, cn = self.lstm(xxo, (h,c))\n",
    "        hn = self.tanh(hn)\n",
    "        out = self.h2o(hn)\n",
    "        return out, hn, cn\n",
    "    \n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.nbatch, self.nhidden)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, obs_dim=46, nhidden=50):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, nhidden*2)\n",
    "        self.fc3 = nn.Linear(nhidden*2, obs_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val\n",
    "\n",
    "\n",
    "def log_normal_pdf(x, mean, logvar):\n",
    "    const = torch.from_numpy(np.array([2. * np.pi])).float().to(x.device)\n",
    "    const = torch.log(const)\n",
    "    return -.5 * (const + logvar + (x - mean) ** 2. / torch.exp(logvar))\n",
    "\n",
    "def mseloss(x, mean):\n",
    "    loss = nn.MSELoss()\n",
    "    return loss(x, mean)\n",
    "\n",
    "def normal_kl(mu1, lv1, mu2, lv2):\n",
    "    v1 = torch.exp(lv1)\n",
    "    v2 = torch.exp(lv2)\n",
    "    lstd1 = lv1 / 2.\n",
    "    lstd2 = lv2 / 2.\n",
    "\n",
    "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
    "    return kl\n",
    "\n",
    "def MSELoss(yhat, y):\n",
    "    assert type(yhat) == torch.Tensor\n",
    "    assert type(y) == torch.Tensor\n",
    "    return torch.mean((yhat - y) ** 2)\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    return {'latent_dim': latent_dim,\n",
    "            'obs_dim': obs_dim,\n",
    "            'nhidden': nhidden,\n",
    "            'dec_nhidden' : dec_nhidden,\n",
    "            'rnn_nhidden': rnn_nhidden,\n",
    "            'device': device}\n",
    "\n",
    "def get_state_dicts():\n",
    "    return {'odefunc_state_dict': func.state_dict(),\n",
    "            'encoder_state_dict': rec.state_dict(),\n",
    "            'decoder_state_dict': dec.state_dict()}\n",
    "\n",
    "def data_get_dict():\n",
    "    return {\n",
    "        'samp_trajs_TE': samp_trajs_TE,\n",
    "        'samp_trajs_val_TE': samp_trajs_val_TE,\n",
    "        'samp_ts': samp_ts,\n",
    "    }\n",
    "\n",
    "def get_losses():\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_losses_k1': val_losses_k1,\n",
    "        'val_losses_k2': val_losses_k2,\n",
    "        'val_losses_k3': val_losses_k3,\n",
    "        'val_losses_k4': val_losses_k4,\n",
    "        'val_losses_k5': val_losses_k5\n",
    "    }\n",
    "\n",
    "def save_model(tau, k, latent_dim, itr):\n",
    "\n",
    "    save_dict = {\n",
    "        'model_args': get_args(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #'data': data_get_dict(),\n",
    "        'train_loss': get_losses()\n",
    "    }\n",
    "    \n",
    "    save_dict.update(get_state_dicts())\n",
    "    \n",
    "    torch.save(save_dict, 'model/ODE_TakenEmbedding_RLONG_rnn2_lstm{}_tau{}k{}_LSTM_lr0.008_latent{}_LSTMautoencoder_Dataloader_timestep{}_epoch{}.pth'.format(rnn_nhidden, tau, k, latent_dim,tot_num, itr))\n",
    "\n",
    "    \n",
    "def data_for_plot_graph(gen_index):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        ts_pos = np.linspace(0, ts_num*gen_index, num=tot_num*gen_index)\n",
    "        ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "    \n",
    "        h = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "        c = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "    \n",
    "        hn = h[0, :, :]\n",
    "        cn = c[0, :, :]\n",
    "    \n",
    "        for t in reversed(range(samp_trajs_TE_test.size(1))):\n",
    "            obs = samp_trajs_TE_test[:, t, :]\n",
    "            out, hn, cn = rec.forward(obs, hn, cn)\n",
    "        qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "        epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "        # forward in time and solve ode for reconstructions\n",
    "        pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "        pred_x = dec(pred_z)\n",
    "        \n",
    "        return pred_x, pred_z\n",
    "    \n",
    "def plot_graph(gen_index, times_index, tot_index, dataset_value, deriv_index, pred_x_forgraph, orig_trajs, itr, path):\n",
    "    with torch.no_grad():\n",
    "        orig_trajs_forgraph = orig_trajs\n",
    "        ts_pos_combined = np.linspace(0, ts_num*tot_index, num=tot_num*tot_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.scatter(ts_pos_combined[times_index:times_index+tot_num*gen_index], orig_trajs_forgraph[dataset_value,times_index:tot_num*gen_index, i*(k+1)+deriv_index], s = 5)\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_forgraph[dataset_value, times_index:times_index+tot_num*tot_index, i*(k+1)+deriv_index], 'r')\n",
    "            ax.set_ylim(-3, 3)\n",
    "\n",
    "        \n",
    "        plot_name = 'lstm_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, tot_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "latent_dim = 12\n",
    "nhidden = 64\n",
    "dec_nhidden = 12\n",
    "obs_dim = 6*(k+1)\n",
    "rnn_nhidden = 256\n",
    "nitrs = 3000\n",
    "noise_std = 0.2\n",
    "\n",
    "func = LatentODEfunc(latent_dim, nhidden).to(device)\n",
    "rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, batch).to(device)\n",
    "dec = Decoder(latent_dim, obs_dim, dec_nhidden).to(device)\n",
    "params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))\n",
    "optimizer = optim.Adam(params, lr=0.008)\n",
    "loss_meter = RunningAverageMeter()\n",
    "\n",
    "\n",
    "checkpoint = torch.load('model/ODE_TakenEmbedding_RLONG_rnn2_lstm256_tau18k5_LSTM_lr0.008_latent12_LSTMautoencoder_Dataloader_timestep500_Trial2_epoch5325.pth')\n",
    "rec.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "func.load_state_dict(checkpoint['odefunc_state_dict'])\n",
    "dec.load_state_dict(checkpoint['decoder_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7295e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_un_normalize(Gen_data, obs_dim, datafilepath):\n",
    "    #datafilepath = 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy'\n",
    "    data = np.load(datafilepath)\n",
    "    traj_tot = np.load(datafilepath).reshape(72, 1500, obs_dim)\n",
    "    traj_tot = traj_tot[:,50:1450,:]\n",
    "    pred_x_unormalize = Gen_data[:, : , deriv_index::(k+1)]\n",
    "    \n",
    "\n",
    "    X = np.zeros((data.shape[0],pred_x_unormalize.shape[1],data.shape[2]))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[2]):\n",
    "            trajs = pred_x_unormalize[i,:,j]\n",
    "            trajs_tot = traj_tot[i,:,j]\n",
    "            X[i,:,j] = (trajs * trajs_tot.std())+ trajs_tot.mean()\n",
    "            \n",
    "    #samp_trajs += npr.randn(*samp_trajs.shape) * noise_std #add noise\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fecdb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_index = 2\n",
    "itr=5325\n",
    "deriv_index = 3\n",
    "times_index = 0\n",
    "tot_index = 10\n",
    "\n",
    "orig_trajs = orig_trajs_TE[:, 0:1300, :]\n",
    "\n",
    "pred_x, pred_z = data_for_plot_graph(tot_index)\n",
    "pred_x = pred_x.reshape(72, tot_num*tot_index, 6*(k+1))\n",
    "pred_z = pred_z.reshape(72, tot_num*tot_index, latent_dim)\n",
    "pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "pred_z_forgraph = pred_z.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f03df6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x_forgraph_deriv_3 = load_data_un_normalize(pred_x_forgraph, 6, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca8bdddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"HumanGait5000predict_nonoise.npy\", pred_x_forgraph_deriv_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32a8e2",
   "metadata": {},
   "source": [
    "## Add noise to ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ce813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_plot_graph_noise(gen_index, noise_interval):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        ts_pos = np.linspace(0, ts_num*gen_index, num=tot_num*gen_index)\n",
    "        ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "    \n",
    "        h = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "        c = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "    \n",
    "        hn = h[0, :, :]\n",
    "        cn = c[0, :, :]\n",
    "    \n",
    "        for t in reversed(range(samp_trajs_TE_test.size(1))):\n",
    "            obs = samp_trajs_TE_test[:, t, :]\n",
    "            out, hn, cn = rec.forward(obs, hn, cn)\n",
    "        qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "        epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "        # forward in time and solve ode for reconstructions\n",
    "        pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "        for i in range(pred_z.shape[1]):   \n",
    "            if i%noise_interval == 0:\n",
    "                pred_z[:,i,:] = pred_z[:,i,:] + torch.rand(pred_z.shape[0],pred_z.shape[2]).to(device)*noise_std #add noise\n",
    "        pred_x = dec(pred_z)\n",
    "        \n",
    "        return pred_x, pred_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5af58b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_index = 2\n",
    "itr=5325\n",
    "deriv_index = 3\n",
    "times_index = 0\n",
    "tot_index = 10\n",
    "noise_interval = 10\n",
    "orig_trajs = orig_trajs_TE[:, 0:1300, :]\n",
    "\n",
    "pred_x_noise, pred_z_noise = data_for_plot_graph_noise(tot_index, noise_interval)\n",
    "pred_x_noise = pred_x_noise.reshape(72, tot_num*tot_index, 6*(k+1))\n",
    "pred_z_noise = pred_z_noise.reshape(72, tot_num*tot_index, latent_dim)\n",
    "pred_x_noise_forgraph = pred_x_noise.detach().cpu().numpy()\n",
    "pred_z_noise_forgraph = pred_z_noise.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff0a9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x_forgraph_deriv_3_noise = load_data_un_normalize(pred_x_noise_forgraph, 6, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')\n",
    "np.save(\"HumanGait5000predict_noise{}.npy\".format(noise_std), pred_x_forgraph_deriv_3_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca716f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_std = 0.5\n",
    "gen_index = 2\n",
    "itr=5325\n",
    "deriv_index = 3\n",
    "times_index = 0\n",
    "tot_index = 10\n",
    "noise_interval = 10\n",
    "orig_trajs = orig_trajs_TE[:, 0:1300, :]\n",
    "\n",
    "pred_x_noise, pred_z_noise = data_for_plot_graph_noise(tot_index, noise_interval)\n",
    "pred_x_noise = pred_x_noise.reshape(72, tot_num*tot_index, 6*(k+1))\n",
    "pred_z_noise = pred_z_noise.reshape(72, tot_num*tot_index, latent_dim)\n",
    "pred_x_noise_forgraph = pred_x_noise.detach().cpu().numpy()\n",
    "pred_z_noise_forgraph = pred_z_noise.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e7e2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x_forgraph_deriv_3_noise = load_data_un_normalize(pred_x_noise_forgraph, 6, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')\n",
    "np.save(\"HumanGait5000predict_noise{}.npy\".format(noise_std), pred_x_forgraph_deriv_3_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f729a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_std = 1\n",
    "gen_index = 2\n",
    "itr=5325\n",
    "deriv_index = 3\n",
    "times_index = 0\n",
    "tot_index = 10\n",
    "noise_interval = 10\n",
    "orig_trajs = orig_trajs_TE[:, 0:1300, :]\n",
    "\n",
    "pred_x_noise, pred_z_noise = data_for_plot_graph_noise(tot_index, noise_interval)\n",
    "pred_x_noise = pred_x_noise.reshape(72, tot_num*tot_index, 6*(k+1))\n",
    "pred_z_noise = pred_z_noise.reshape(72, tot_num*tot_index, latent_dim)\n",
    "pred_x_noise_forgraph = pred_x_noise.detach().cpu().numpy()\n",
    "pred_z_noise_forgraph = pred_z_noise.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075e70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x_forgraph_deriv_3_noise = load_data_un_normalize(pred_x_noise_forgraph, 6, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')\n",
    "np.save(\"HumanGait5000predict_noise{}.npy\".format(noise_std), pred_x_forgraph_deriv_3_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea5a4d",
   "metadata": {},
   "source": [
    "## Plotting Noise vs No-Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "195a0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph_noise_nonoise(gen_index, times_index, tot_index, dataset_value, deriv_index, pred_x_forgraph, orig_trajs, itr, path):\n",
    "    with torch.no_grad():\n",
    "        orig_trajs_forgraph = orig_trajs\n",
    "        ts_pos_combined = np.linspace(0, ts_num*tot_index, num=tot_num*tot_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_forgraph[dataset_value,times_index:tot_num*tot_index, i*(k+1)+deriv_index], 'r')\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*tot_index], pred_x_noise_forgraph[dataset_value, times_index:times_index+tot_num*tot_index, i*(k+1)+deriv_index], 'b')\n",
    "            ax.set_ylim(-3, 3)\n",
    "\n",
    "        \n",
    "        plot_name = 'Noise_vs_Nonoise_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, tot_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5672d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"NoiseComparison/tau{}k{}/longtimeseries/latent{}/Trial2_RLONG_data_loader_rnn2layer_lstm{}_lr0.008_timestep{}/epoch{}\".format(tau, k, latent_dim, rnn_nhidden, tot_num, itr)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "   os.makedirs(path)\n",
    "\n",
    "for i in range(72):\n",
    "    plot_graph_noise_nonoise(gen_index, times_index, tot_index, i, deriv_index, pred_x_forgraph, orig_trajs, itr, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670bf277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7a56b6b",
   "metadata": {},
   "source": [
    "## Multiple Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple_Trial_Index = 12\n",
    "\n",
    "for i in range(Multiple_Trial_Index):\n",
    "    noise_std = 1\n",
    "    gen_index = 2\n",
    "    itr=5325\n",
    "    deriv_index = 3\n",
    "    times_index = 0\n",
    "    tot_index = 10\n",
    "    noise_interval = 10\n",
    "    orig_trajs = orig_trajs_TE[:, 0:1300, :]\n",
    "\n",
    "    pred_x_noise, pred_z_noise = data_for_plot_graph_noise(tot_index, noise_interval)\n",
    "    pred_x_noise = pred_x_noise.reshape(72, tot_num*tot_index, 6*(k+1))\n",
    "    pred_z_noise = pred_z_noise.reshape(72, tot_num*tot_index, latent_dim)\n",
    "    pred_x_noise_forgraph = pred_x_noise.detach().cpu().numpy()\n",
    "    pred_z_noise_forgraph = pred_z_noise.detach().cpu().numpy()\n",
    "    \n",
    "    pred_x_forgraph_deriv_3_noise = load_data_un_normalize(pred_x_noise_forgraph, 6, 'C:/Users/shiny/Documents/NeuralODE_HumanGait/Humangaitdata.npy')\n",
    "    np.save(\"HumanGait500g0predict_noise{}_trial{}.npy\".format(noise_std, i), pred_x_forgraph_deriv_3_noise)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple_Trials_Concatenated = []\n",
    "for i in range(Multiple_Trial_Index):\n",
    "    Upload_Data = np.load(\"HumanGait5000predict_noise{}_trial{}.npy\".format(noise_std, i))\n",
    "    if i == 0:\n",
    "        Multiple_Trials_Concatenated = Upload_Data.copy()\n",
    "    else:\n",
    "        Multiple_Trials_Concatenated = np.append(Multiple_Trials_Concatenated, Upload_Data, axis = 1)\n",
    "        \n",
    "np.save(\"HumanGait5000predict_noise{}_total_trial{}.npy\".format(noise_std, Multiple_Trial_Index), Multiple_Trials_Concatenated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
