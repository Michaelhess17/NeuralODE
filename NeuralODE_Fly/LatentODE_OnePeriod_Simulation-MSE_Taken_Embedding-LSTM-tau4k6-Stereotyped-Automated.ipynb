{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "859b61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torch.utils.data import DataLoader\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18819eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_trajs_TE = torch.load('samp_trajs_TE_tau4k6_25.pt')\n",
    "samp_trajs_val_TE = torch.load('samp_trajs_val_TE_tau4k6_25.pt')\n",
    "tau = 4\n",
    "k = 6\n",
    "mesured_dim = 12\n",
    "\n",
    "trial_num = 16\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch = 1000 #for lstm256\n",
    "\n",
    "ts_num = 0.33\n",
    "tot_num = 25\n",
    "\n",
    "samp_ts = np.linspace(0, ts_num, num=tot_num)\n",
    "samp_ts = torch.from_numpy(samp_ts).float().to(device)\n",
    "\n",
    "orig_trajs_TE = np.load('orig_trajs_TE_Stereo_Stim_tau4k6.npy')\n",
    "samp_trajs_TE_test = orig_trajs_TE[:, :tot_num, :]\n",
    "samp_trajs_TE_test = torch.from_numpy(samp_trajs_TE_test).float().to(device).reshape(trial_num, tot_num, mesured_dim*(k+1))\n",
    "\n",
    "#Load to Dataloader\n",
    "train_loader = DataLoader(dataset = samp_trajs_TE, batch_size = batch, shuffle = True, drop_last = True)\n",
    "val_loader = DataLoader(dataset = samp_trajs_val_TE, batch_size = batch, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "510ca703",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('model'):\n",
    "           os.makedirs('model')\n",
    "        \n",
    "class LatentODEfunc(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, nhidden=50):\n",
    "        super(LatentODEfunc, self).__init__()\n",
    "        #self.tanh = nn.ELU(inplace= True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, nhidden)\n",
    "        self.fc3 = nn.Linear(nhidden, latent_dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "class RecognitionRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, obs_dim=46, nhidden=50, nbatch=1):\n",
    "        super(RecognitionRNN, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.nbatch = nbatch\n",
    "        #self.h1o = nn.Linear(obs_dim, 8)\n",
    "        self.h1o = nn.Linear(obs_dim, 36)\n",
    "        self.h3o = nn.Linear(36, latent_dim*2)\n",
    "        self.lstm = nn.LSTMCell(latent_dim*2, nhidden)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.h2o = nn.Linear(nhidden, latent_dim*2)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        xo = self.h1o(x)\n",
    "        xo = self.tanh(xo)\n",
    "        xxo = self.h3o(xo)\n",
    "        hn, cn = self.lstm(xxo, (h,c))\n",
    "        hn = self.tanh(hn)\n",
    "        out = self.h2o(hn)\n",
    "        return out, hn, cn\n",
    "    \n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.nbatch, self.nhidden)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=8, obs_dim=46, nhidden=50):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
    "        self.fc2 = nn.Linear(nhidden, nhidden*2)\n",
    "        self.fc3 = nn.Linear(nhidden*2, obs_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val\n",
    "\n",
    "\n",
    "def log_normal_pdf(x, mean, logvar):\n",
    "    const = torch.from_numpy(np.array([2. * np.pi])).float().to(x.device)\n",
    "    const = torch.log(const)\n",
    "    return -.5 * (const + logvar + (x - mean) ** 2. / torch.exp(logvar))\n",
    "\n",
    "def mseloss(x, mean):\n",
    "    loss = nn.MSELoss()\n",
    "    return loss(x, mean)\n",
    "\n",
    "def normal_kl(mu1, lv1, mu2, lv2):\n",
    "    v1 = torch.exp(lv1)\n",
    "    v2 = torch.exp(lv2)\n",
    "    lstd1 = lv1 / 2.\n",
    "    lstd2 = lv2 / 2.\n",
    "\n",
    "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
    "    return kl\n",
    "\n",
    "def MSELoss(yhat, y):\n",
    "    assert type(yhat) == torch.Tensor\n",
    "    assert type(y) == torch.Tensor\n",
    "    return torch.mean((yhat - y) ** 2)\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    return {'latent_dim': latent_dim,\n",
    "            'obs_dim': obs_dim,\n",
    "            'nhidden': nhidden,\n",
    "            'dec_nhidden' : dec_nhidden,\n",
    "            'rnn_nhidden': rnn_nhidden,\n",
    "            'device': device,\n",
    "            'learning_rate': learning_rate,\n",
    "            'tau': tau,\n",
    "            'k': k}\n",
    "\n",
    "def get_state_dicts():\n",
    "    return {'odefunc_state_dict': func.state_dict(),\n",
    "            'encoder_state_dict': rec.state_dict(),\n",
    "            'decoder_state_dict': dec.state_dict()}\n",
    "\n",
    "def data_get_dict():\n",
    "    return {\n",
    "        'samp_trajs_TE': samp_trajs_TE,\n",
    "        'samp_trajs_val_TE': samp_trajs_val_TE,\n",
    "        'samp_ts': samp_ts,\n",
    "    }\n",
    "\n",
    "def get_losses():\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_losses_k1': val_losses_k1,\n",
    "        'val_losses_k2': val_losses_k2,\n",
    "        'val_losses_k3': val_losses_k3,\n",
    "        'val_losses_k4': val_losses_k4,\n",
    "        'val_losses_k5': val_losses_k5,\n",
    "        'val_losses_k6': val_losses_k6,\n",
    "        'val_losses_k7': val_losses_k7,\n",
    "        'val_losses_k8': val_losses_k8,\n",
    "        'val_losses_k9': val_losses_k9,\n",
    "    }\n",
    "\n",
    "def save_model(Training_Trial, rnn_nhidden, tau, k, lr, latent_dim, itr):\n",
    "    if not os.path.exists('/model'):\n",
    "        os.makedirs('/model')\n",
    "    save_dict = {\n",
    "        'model_args': get_args(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #'data': data_get_dict(),\n",
    "        'train_loss': get_losses()\n",
    "    }\n",
    "    \n",
    "    save_dict.update(get_state_dicts())\n",
    "    \n",
    "    torch.save(save_dict, 'model/ODE_Xcoord_Trial{}_TakenEmbedding_rnn2_lstm{}_tau{}k{}_LSTM_lr{}_latent{}_LSTMautoencoder_Dataloader_epoch{}.pth'.format(Training_Trial, rnn_nhidden, tau, k, lr, latent_dim, itr))\n",
    "\n",
    "    \n",
    "def data_for_plot_graph(gen_index):\n",
    "    with torch.no_grad():\n",
    "        # sample from trajectorys' approx. posterior\n",
    "\n",
    "        ts_pos = np.linspace(0, ts_num*gen_index, num=tot_num*gen_index)\n",
    "        ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "    \n",
    "        h = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "        c = torch.zeros(1, samp_trajs_TE_test.shape[0], rnn_nhidden).to(device)\n",
    "    \n",
    "        hn = h[0, :, :]\n",
    "        cn = c[0, :, :]\n",
    "    \n",
    "        for t in reversed(range(samp_trajs_TE_test.size(1))):\n",
    "            obs = samp_trajs_TE_test[:, t, :]\n",
    "            out, hn, cn = rec.forward(obs, hn, cn)\n",
    "        qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "        epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "        # forward in time and solve ode for reconstructions\n",
    "        pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "        pred_x = dec(pred_z)\n",
    "        \n",
    "        return pred_x, pred_z\n",
    "    \n",
    "def plot_graph(gen_index, times_index, dataset_value, deriv_index, pred_x_forgraph, orig_trajs, itr, path):\n",
    "    with torch.no_grad():\n",
    "        orig_trajs_forgraph = orig_trajs\n",
    "        ts_pos_combined = np.linspace(0, ts_num*gen_index, num=tot_num*gen_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 9)) #####MAKE SURE ROW COL MATCHES THE NUM OF FEATURES\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.scatter(ts_pos_combined[times_index:times_index+tot_num*gen_index], orig_trajs_forgraph[dataset_value,times_index:tot_num*gen_index, i*(k+1)+deriv_index], label='sampled data', s = 5)\n",
    "            ax.plot(ts_pos_combined[times_index:times_index+tot_num*gen_index], pred_x_forgraph[dataset_value, times_index:times_index+tot_num*gen_index, i*(k+1)+deriv_index], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "            ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "        plt.legend()\n",
    "        plot_name = 'lstm_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, gen_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "def plot_z_graph(gen_index, times_index, dataset_value, deriv_index, pred_z_forgraph, orig_trajs, itr, path):\n",
    "    with torch.no_grad():\n",
    "        orig_trajs_forgraph = orig_trajs\n",
    "        out, hn, cn = rec.forward(orig_trajs)\n",
    "        qz_mean, qz_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "        epsilon = torch.randn(qz_mean.size()).to(device)\n",
    "        z = epsilon * torch.exp(.5 * qz_logvar) + qz_mean\n",
    "        \n",
    "        z_forgraph = z.detach().cpu().numpy()\n",
    "        ts_pos_combined = np.linspace(0, ts_num*gen_index, num=tot_num*gen_index) \n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(15, 9))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.scatter(ts_pos_combined[times_index:50*gen_index], z_forgraph[dataset_value, 0:50*gen_index, i], label='sampled data', s = 5)\n",
    "            ax.plot(ts_pos_combined[times_index:+50*gen_index], pred_z_forgraph[dataset_value, times_index:+50*gen_index, i], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "            ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "        plt.legend()\n",
    "        plot_name = 'Zgraph_lstm_datasetnum{}_latent{}_gen{}_deriv{}_epoch{}.png'.format(dataset_value, latent_dim, gen_index, deriv_index, itr)\n",
    "        save_path = os.path.join(path, plot_name)\n",
    "        plt.savefig(save_path, dpi=500)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36483446",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Trial = 1\n",
    "latent_dim = 8\n",
    "nhidden = 64 ##Trial1 = 64, Trial2 = 128, Trial3 = 128, Trial4 = 64, Trial5 = 64\n",
    "dec_nhidden = 32\n",
    "obs_dim = 12*(k+1)\n",
    "rnn_nhidden = 256\n",
    "nitrs = 1000\n",
    "noise_std = 0.2\n",
    "learning_rate = 0.008\n",
    "\n",
    "func = LatentODEfunc(latent_dim, nhidden).to(device)\n",
    "rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, batch).to(device)\n",
    "dec = Decoder(latent_dim, obs_dim, dec_nhidden).to(device)\n",
    "params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))\n",
    "optimizer = optim.Adam(params, lr=learning_rate)\n",
    "loss_meter = RunningAverageMeter()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_losses_k1 = []\n",
    "val_losses_k2 = []\n",
    "val_losses_k3 = []\n",
    "val_losses_k4 = []\n",
    "val_losses_k5 = []\n",
    "val_losses_k6 = []\n",
    "val_losses_k7 = []\n",
    "val_losses_k8 = []\n",
    "val_losses_k9 = []\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f15fb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, running avg mse: 1.0043 lowest val mse: 0.9891 at k 5\n",
      "Iter: 2, running avg mse: 0.9792 lowest val mse: 0.9586 at k 5\n",
      "Iter: 3, running avg mse: 0.9648 lowest val mse: 0.9479 at k 4\n",
      "Iter: 4, running avg mse: 0.9475 lowest val mse: 0.9408 at k 4\n",
      "Iter: 5, running avg mse: 0.9398 lowest val mse: 0.9364 at k 4\n",
      "Iter: 6, running avg mse: 0.9351 lowest val mse: 0.9368 at k 4\n",
      "Iter: 7, running avg mse: 0.9410 lowest val mse: 0.9347 at k 4\n",
      "Iter: 8, running avg mse: 0.9300 lowest val mse: 0.9320 at k 4\n",
      "Iter: 9, running avg mse: 0.9285 lowest val mse: 0.9242 at k 4\n",
      "Iter: 10, running avg mse: 0.9073 lowest val mse: 0.9071 at k 4\n",
      "Iter: 11, running avg mse: 0.9107 lowest val mse: 0.9014 at k 4\n",
      "Iter: 12, running avg mse: 0.9036 lowest val mse: 0.8997 at k 4\n",
      "Iter: 13, running avg mse: 0.9131 lowest val mse: 0.8960 at k 4\n",
      "Iter: 14, running avg mse: 0.8930 lowest val mse: 0.8900 at k 4\n",
      "Iter: 15, running avg mse: 0.8900 lowest val mse: 0.8846 at k 4\n",
      "Iter: 16, running avg mse: 0.8909 lowest val mse: 0.8804 at k 4\n",
      "Iter: 17, running avg mse: 0.8878 lowest val mse: 0.8781 at k 4\n",
      "Iter: 18, running avg mse: 0.9001 lowest val mse: 0.8781 at k 4\n",
      "Iter: 19, running avg mse: 0.8836 lowest val mse: 0.8750 at k 4\n",
      "Iter: 20, running avg mse: 0.8828 lowest val mse: 0.8750 at k 4\n",
      "Iter: 21, running avg mse: 0.8699 lowest val mse: 0.8720 at k 4\n",
      "Iter: 22, running avg mse: 0.8634 lowest val mse: 0.8701 at k 4\n",
      "Iter: 23, running avg mse: 0.8769 lowest val mse: 0.8673 at k 4\n",
      "Iter: 24, running avg mse: 0.8694 lowest val mse: 0.8686 at k 4\n",
      "Iter: 25, running avg mse: 0.8735 lowest val mse: 0.8625 at k 4\n",
      "Iter: 26, running avg mse: 0.8622 lowest val mse: 0.8599 at k 4\n",
      "Iter: 27, running avg mse: 0.8694 lowest val mse: 0.8524 at k 4\n",
      "Iter: 28, running avg mse: 0.8581 lowest val mse: 0.8433 at k 4\n",
      "Iter: 29, running avg mse: 0.8584 lowest val mse: 0.8359 at k 4\n",
      "Iter: 30, running avg mse: 0.8307 lowest val mse: 0.7853 at k 4\n",
      "Iter: 31, running avg mse: 0.8280 lowest val mse: 0.7959 at k 5\n",
      "Iter: 32, running avg mse: 0.8870 lowest val mse: 0.8620 at k 2\n",
      "Iter: 33, running avg mse: 0.8606 lowest val mse: 0.8459 at k 3\n",
      "Iter: 34, running avg mse: 0.8396 lowest val mse: 0.8155 at k 2\n",
      "Iter: 35, running avg mse: 0.8259 lowest val mse: 0.7844 at k 2\n",
      "Iter: 36, running avg mse: 0.7878 lowest val mse: 0.7356 at k 4\n",
      "Iter: 37, running avg mse: 0.7486 lowest val mse: 0.6678 at k 4\n",
      "Iter: 38, running avg mse: 0.8117 lowest val mse: 0.7960 at k 4\n",
      "Iter: 39, running avg mse: 0.8082 lowest val mse: 0.7869 at k 4\n",
      "Iter: 40, running avg mse: 0.7614 lowest val mse: 0.6831 at k 4\n",
      "Iter: 41, running avg mse: 0.7223 lowest val mse: 0.6521 at k 3\n",
      "Iter: 42, running avg mse: 0.7097 lowest val mse: 0.5852 at k 4\n",
      "Iter: 43, running avg mse: 0.7178 lowest val mse: 0.6329 at k 3\n",
      "Iter: 44, running avg mse: 0.7003 lowest val mse: 0.5968 at k 4\n",
      "Iter: 45, running avg mse: 0.6565 lowest val mse: 0.5655 at k 3\n",
      "Iter: 46, running avg mse: 0.6174 lowest val mse: 0.5450 at k 3\n",
      "Iter: 47, running avg mse: 0.6230 lowest val mse: 0.5894 at k 3\n",
      "Iter: 48, running avg mse: 0.6511 lowest val mse: 0.5764 at k 3\n",
      "Iter: 49, running avg mse: 0.6548 lowest val mse: 0.5351 at k 4\n",
      "Iter: 50, running avg mse: 0.6301 lowest val mse: 0.5329 at k 3\n",
      "Iter: 51, running avg mse: 0.5977 lowest val mse: 0.5159 at k 4\n",
      "Iter: 52, running avg mse: 0.5980 lowest val mse: 0.5047 at k 3\n",
      "Iter: 53, running avg mse: 0.5799 lowest val mse: 0.4984 at k 3\n",
      "Iter: 54, running avg mse: 0.5730 lowest val mse: 0.4856 at k 3\n",
      "Iter: 55, running avg mse: 0.5746 lowest val mse: 0.4782 at k 3\n",
      "Iter: 56, running avg mse: 0.5694 lowest val mse: 0.4733 at k 3\n",
      "Iter: 57, running avg mse: 0.5780 lowest val mse: 0.4658 at k 3\n",
      "Iter: 58, running avg mse: 0.5711 lowest val mse: 0.4621 at k 3\n",
      "Iter: 59, running avg mse: 0.5571 lowest val mse: 0.4577 at k 3\n",
      "Iter: 60, running avg mse: 0.5488 lowest val mse: 0.4591 at k 3\n",
      "Iter: 61, running avg mse: 0.5344 lowest val mse: 0.4490 at k 3\n",
      "Iter: 62, running avg mse: 0.5415 lowest val mse: 0.4482 at k 3\n",
      "Iter: 63, running avg mse: 0.5271 lowest val mse: 0.4398 at k 3\n",
      "Iter: 64, running avg mse: 0.5320 lowest val mse: 0.4601 at k 3\n",
      "Iter: 65, running avg mse: 0.4986 lowest val mse: 0.4434 at k 3\n",
      "Iter: 66, running avg mse: 0.5070 lowest val mse: 0.4449 at k 3\n",
      "Iter: 67, running avg mse: 0.4907 lowest val mse: 0.4530 at k 3\n",
      "Iter: 68, running avg mse: 0.5030 lowest val mse: 0.4306 at k 3\n",
      "Iter: 69, running avg mse: 0.4766 lowest val mse: 0.4325 at k 3\n",
      "Iter: 70, running avg mse: 0.4792 lowest val mse: 0.4350 at k 3\n",
      "Iter: 71, running avg mse: 0.4776 lowest val mse: 0.4222 at k 3\n",
      "Iter: 72, running avg mse: 0.4652 lowest val mse: 0.4157 at k 3\n",
      "Iter: 73, running avg mse: 0.4507 lowest val mse: 0.4102 at k 3\n",
      "Iter: 74, running avg mse: 0.4473 lowest val mse: 0.4109 at k 3\n",
      "Iter: 75, running avg mse: 0.4489 lowest val mse: 0.4058 at k 3\n",
      "Iter: 76, running avg mse: 0.4411 lowest val mse: 0.4020 at k 3\n",
      "Iter: 77, running avg mse: 0.4490 lowest val mse: 0.3961 at k 3\n",
      "Iter: 78, running avg mse: 0.4330 lowest val mse: 0.3932 at k 3\n",
      "Iter: 79, running avg mse: 0.4315 lowest val mse: 0.3905 at k 3\n",
      "Iter: 80, running avg mse: 0.4261 lowest val mse: 0.3899 at k 3\n",
      "Iter: 81, running avg mse: 0.4448 lowest val mse: 0.3905 at k 3\n",
      "Iter: 82, running avg mse: 0.4699 lowest val mse: 0.4235 at k 4\n",
      "Iter: 83, running avg mse: 0.4662 lowest val mse: 0.4023 at k 3\n",
      "Iter: 84, running avg mse: 0.4582 lowest val mse: 0.4085 at k 3\n",
      "Iter: 85, running avg mse: 0.4481 lowest val mse: 0.3956 at k 3\n",
      "Iter: 86, running avg mse: 0.4350 lowest val mse: 0.3918 at k 3\n",
      "Iter: 87, running avg mse: 0.4337 lowest val mse: 0.3905 at k 3\n",
      "Iter: 88, running avg mse: 0.4256 lowest val mse: 0.3854 at k 3\n",
      "Iter: 89, running avg mse: 0.4190 lowest val mse: 0.3812 at k 3\n",
      "Iter: 90, running avg mse: 0.4217 lowest val mse: 0.3801 at k 3\n",
      "Iter: 91, running avg mse: 0.4236 lowest val mse: 0.3780 at k 3\n",
      "Iter: 92, running avg mse: 0.4145 lowest val mse: 0.3771 at k 3\n",
      "Iter: 93, running avg mse: 0.4232 lowest val mse: 0.3767 at k 3\n",
      "Iter: 94, running avg mse: 0.4227 lowest val mse: 0.3754 at k 3\n",
      "Iter: 95, running avg mse: 0.4231 lowest val mse: 0.3755 at k 3\n",
      "Iter: 96, running avg mse: 0.4206 lowest val mse: 0.3752 at k 3\n",
      "Iter: 97, running avg mse: 0.4110 lowest val mse: 0.3727 at k 3\n",
      "Iter: 98, running avg mse: 0.4140 lowest val mse: 0.3732 at k 3\n",
      "Iter: 99, running avg mse: 0.4096 lowest val mse: 0.3736 at k 3\n",
      "Iter: 100, running avg mse: 0.4145 lowest val mse: 0.3710 at k 3\n",
      "Iter: 101, running avg mse: 0.4042 lowest val mse: 0.3726 at k 3\n",
      "Iter: 102, running avg mse: 0.4197 lowest val mse: 0.3736 at k 3\n",
      "Iter: 103, running avg mse: 0.4083 lowest val mse: 0.3745 at k 3\n",
      "Iter: 104, running avg mse: 0.4060 lowest val mse: 0.3739 at k 3\n",
      "Iter: 105, running avg mse: 0.4051 lowest val mse: 0.3704 at k 3\n",
      "Iter: 106, running avg mse: 0.4095 lowest val mse: 0.3694 at k 3\n",
      "Iter: 107, running avg mse: 0.4046 lowest val mse: 0.3698 at k 3\n",
      "Iter: 108, running avg mse: 0.4050 lowest val mse: 0.3708 at k 3\n",
      "Iter: 109, running avg mse: 0.4160 lowest val mse: 0.3832 at k 3\n",
      "Iter: 110, running avg mse: 0.4082 lowest val mse: 0.3749 at k 3\n",
      "Iter: 111, running avg mse: 0.4101 lowest val mse: 0.3709 at k 3\n",
      "Iter: 112, running avg mse: 0.4046 lowest val mse: 0.3673 at k 3\n",
      "Iter: 113, running avg mse: 0.4088 lowest val mse: 0.3678 at k 3\n",
      "Iter: 114, running avg mse: 0.4031 lowest val mse: 0.3658 at k 3\n",
      "Iter: 115, running avg mse: 0.4063 lowest val mse: 0.3644 at k 3\n",
      "Iter: 116, running avg mse: 0.3876 lowest val mse: 0.3642 at k 3\n",
      "Iter: 117, running avg mse: 0.3901 lowest val mse: 0.3643 at k 3\n",
      "Iter: 118, running avg mse: 0.4008 lowest val mse: 0.3629 at k 3\n",
      "Iter: 119, running avg mse: 0.3942 lowest val mse: 0.3626 at k 3\n",
      "Iter: 120, running avg mse: 0.3938 lowest val mse: 0.3620 at k 3\n",
      "Iter: 121, running avg mse: 0.3917 lowest val mse: 0.3621 at k 3\n",
      "Iter: 122, running avg mse: 0.3979 lowest val mse: 0.3697 at k 3\n",
      "Iter: 123, running avg mse: 0.3944 lowest val mse: 0.3644 at k 3\n",
      "Iter: 124, running avg mse: 0.3958 lowest val mse: 0.3655 at k 3\n",
      "Iter: 125, running avg mse: 0.3957 lowest val mse: 0.3611 at k 3\n",
      "Iter: 126, running avg mse: 0.4005 lowest val mse: 0.3611 at k 3\n",
      "Iter: 127, running avg mse: 0.3978 lowest val mse: 0.3585 at k 3\n",
      "Iter: 128, running avg mse: 0.3953 lowest val mse: 0.3610 at k 3\n",
      "Iter: 129, running avg mse: 0.3968 lowest val mse: 0.3603 at k 3\n",
      "Iter: 130, running avg mse: 0.3941 lowest val mse: 0.3597 at k 3\n",
      "Iter: 131, running avg mse: 0.3884 lowest val mse: 0.3574 at k 3\n",
      "Iter: 132, running avg mse: 0.3923 lowest val mse: 0.3569 at k 3\n",
      "Iter: 133, running avg mse: 0.3889 lowest val mse: 0.3560 at k 3\n",
      "Iter: 134, running avg mse: 0.3905 lowest val mse: 0.3635 at k 3\n",
      "Iter: 135, running avg mse: 0.4073 lowest val mse: 0.3719 at k 3\n",
      "Iter: 136, running avg mse: 0.3931 lowest val mse: 0.3696 at k 3\n",
      "Iter: 137, running avg mse: 0.4015 lowest val mse: 0.3615 at k 3\n",
      "Iter: 138, running avg mse: 0.3921 lowest val mse: 0.3599 at k 3\n",
      "Iter: 139, running avg mse: 0.3898 lowest val mse: 0.3567 at k 3\n",
      "Iter: 140, running avg mse: 0.3908 lowest val mse: 0.3554 at k 3\n",
      "Iter: 141, running avg mse: 0.3824 lowest val mse: 0.3555 at k 3\n",
      "Iter: 142, running avg mse: 0.3872 lowest val mse: 0.3540 at k 3\n",
      "Iter: 143, running avg mse: 0.3888 lowest val mse: 0.3525 at k 3\n",
      "Iter: 144, running avg mse: 0.3909 lowest val mse: 0.3522 at k 3\n",
      "Iter: 145, running avg mse: 0.3761 lowest val mse: 0.3515 at k 3\n",
      "Iter: 146, running avg mse: 0.3784 lowest val mse: 0.3517 at k 3\n",
      "Iter: 147, running avg mse: 0.3770 lowest val mse: 0.3527 at k 3\n",
      "Iter: 148, running avg mse: 0.3832 lowest val mse: 0.3555 at k 3\n",
      "Iter: 149, running avg mse: 0.3883 lowest val mse: 0.3516 at k 3\n",
      "Iter: 150, running avg mse: 0.3806 lowest val mse: 0.3518 at k 3\n",
      "Iter: 151, running avg mse: 0.3934 lowest val mse: 0.3545 at k 3\n",
      "Iter: 152, running avg mse: 0.3875 lowest val mse: 0.3496 at k 3\n",
      "Iter: 153, running avg mse: 0.3777 lowest val mse: 0.3518 at k 3\n",
      "Iter: 154, running avg mse: 0.3793 lowest val mse: 0.3499 at k 3\n",
      "Iter: 155, running avg mse: 0.3793 lowest val mse: 0.3477 at k 3\n",
      "Iter: 156, running avg mse: 0.3742 lowest val mse: 0.3484 at k 3\n",
      "Iter: 157, running avg mse: 0.3799 lowest val mse: 0.3500 at k 3\n",
      "Iter: 158, running avg mse: 0.3778 lowest val mse: 0.3542 at k 3\n",
      "Iter: 159, running avg mse: 0.3831 lowest val mse: 0.3475 at k 3\n",
      "Iter: 160, running avg mse: 0.3794 lowest val mse: 0.3516 at k 3\n",
      "Iter: 161, running avg mse: 0.3734 lowest val mse: 0.3471 at k 3\n",
      "Iter: 162, running avg mse: 0.3827 lowest val mse: 0.3466 at k 3\n",
      "Iter: 163, running avg mse: 0.3746 lowest val mse: 0.3470 at k 3\n",
      "Iter: 164, running avg mse: 0.3731 lowest val mse: 0.3453 at k 3\n",
      "Iter: 165, running avg mse: 0.3795 lowest val mse: 0.3471 at k 3\n",
      "Iter: 166, running avg mse: 0.3803 lowest val mse: 0.3537 at k 3\n",
      "Iter: 167, running avg mse: 0.3748 lowest val mse: 0.3455 at k 3\n",
      "Iter: 168, running avg mse: 0.3820 lowest val mse: 0.3498 at k 3\n",
      "Iter: 169, running avg mse: 0.3745 lowest val mse: 0.3472 at k 3\n",
      "Iter: 170, running avg mse: 0.3719 lowest val mse: 0.3461 at k 3\n",
      "Iter: 171, running avg mse: 0.3668 lowest val mse: 0.3453 at k 3\n",
      "Iter: 172, running avg mse: 0.3676 lowest val mse: 0.3442 at k 3\n",
      "Iter: 173, running avg mse: 0.3687 lowest val mse: 0.3442 at k 3\n",
      "Iter: 174, running avg mse: 0.3778 lowest val mse: 0.3438 at k 3\n",
      "Iter: 175, running avg mse: 0.3713 lowest val mse: 0.3424 at k 3\n",
      "Iter: 176, running avg mse: 0.3765 lowest val mse: 0.3435 at k 3\n",
      "Iter: 177, running avg mse: 0.3745 lowest val mse: 0.3486 at k 3\n",
      "Iter: 178, running avg mse: 0.3947 lowest val mse: 0.3615 at k 3\n",
      "Iter: 179, running avg mse: 0.3650 lowest val mse: 0.3522 at k 3\n",
      "Iter: 180, running avg mse: 0.3798 lowest val mse: 0.3459 at k 3\n",
      "Iter: 181, running avg mse: 0.3754 lowest val mse: 0.3553 at k 3\n",
      "Iter: 182, running avg mse: 0.3867 lowest val mse: 0.3491 at k 3\n",
      "Iter: 183, running avg mse: 0.3733 lowest val mse: 0.3567 at k 3\n",
      "Iter: 184, running avg mse: 0.3692 lowest val mse: 0.3516 at k 3\n",
      "Iter: 185, running avg mse: 0.3868 lowest val mse: 0.3469 at k 3\n",
      "Iter: 186, running avg mse: 0.3664 lowest val mse: 0.3442 at k 3\n",
      "Iter: 187, running avg mse: 0.3738 lowest val mse: 0.3426 at k 3\n",
      "Iter: 188, running avg mse: 0.3722 lowest val mse: 0.3423 at k 3\n",
      "Iter: 189, running avg mse: 0.3627 lowest val mse: 0.3421 at k 3\n",
      "Iter: 190, running avg mse: 0.3742 lowest val mse: 0.3394 at k 3\n",
      "Iter: 191, running avg mse: 0.3696 lowest val mse: 0.3412 at k 3\n",
      "Iter: 192, running avg mse: 0.3640 lowest val mse: 0.3400 at k 3\n",
      "Iter: 193, running avg mse: 0.3728 lowest val mse: 0.3394 at k 3\n",
      "Iter: 194, running avg mse: 0.3632 lowest val mse: 0.3432 at k 3\n",
      "Iter: 195, running avg mse: 0.3672 lowest val mse: 0.3393 at k 3\n",
      "Iter: 196, running avg mse: 0.3624 lowest val mse: 0.3386 at k 3\n",
      "Iter: 197, running avg mse: 0.3672 lowest val mse: 0.3420 at k 3\n",
      "Iter: 198, running avg mse: 0.3683 lowest val mse: 0.3382 at k 3\n",
      "Iter: 199, running avg mse: 0.3537 lowest val mse: 0.3402 at k 3\n",
      "Iter: 200, running avg mse: 0.3667 lowest val mse: 0.3383 at k 3\n",
      "Iter: 201, running avg mse: 0.3592 lowest val mse: 0.3384 at k 3\n",
      "Iter: 202, running avg mse: 0.3690 lowest val mse: 0.3384 at k 3\n",
      "Iter: 203, running avg mse: 0.3639 lowest val mse: 0.3390 at k 3\n",
      "Iter: 204, running avg mse: 0.3722 lowest val mse: 0.3384 at k 3\n",
      "Iter: 205, running avg mse: 0.3699 lowest val mse: 0.3364 at k 3\n",
      "Iter: 206, running avg mse: 0.3663 lowest val mse: 0.3378 at k 3\n",
      "Iter: 207, running avg mse: 0.3686 lowest val mse: 0.3408 at k 3\n",
      "Iter: 208, running avg mse: 0.3666 lowest val mse: 0.3396 at k 3\n",
      "Iter: 209, running avg mse: 0.3630 lowest val mse: 0.3376 at k 3\n",
      "Iter: 210, running avg mse: 0.3702 lowest val mse: 0.3400 at k 3\n",
      "Iter: 211, running avg mse: 0.3642 lowest val mse: 0.3375 at k 3\n",
      "Iter: 212, running avg mse: 0.3646 lowest val mse: 0.3373 at k 3\n",
      "Iter: 213, running avg mse: 0.3604 lowest val mse: 0.3379 at k 3\n",
      "Iter: 214, running avg mse: 0.3637 lowest val mse: 0.3360 at k 3\n",
      "Iter: 215, running avg mse: 0.3602 lowest val mse: 0.3369 at k 3\n",
      "Iter: 216, running avg mse: 0.3599 lowest val mse: 0.3410 at k 3\n",
      "Iter: 217, running avg mse: 0.3697 lowest val mse: 0.3389 at k 3\n",
      "Iter: 218, running avg mse: 0.3584 lowest val mse: 0.3370 at k 3\n",
      "Iter: 219, running avg mse: 0.3651 lowest val mse: 0.3392 at k 3\n",
      "Iter: 220, running avg mse: 0.3549 lowest val mse: 0.3376 at k 3\n",
      "Iter: 221, running avg mse: 0.3520 lowest val mse: 0.3368 at k 3\n",
      "Iter: 222, running avg mse: 0.3618 lowest val mse: 0.3364 at k 3\n",
      "Iter: 223, running avg mse: 0.3682 lowest val mse: 0.3374 at k 3\n",
      "Iter: 224, running avg mse: 0.3670 lowest val mse: 0.3393 at k 3\n",
      "Iter: 225, running avg mse: 0.3624 lowest val mse: 0.3369 at k 3\n",
      "Iter: 226, running avg mse: 0.3702 lowest val mse: 0.3389 at k 3\n",
      "Iter: 227, running avg mse: 0.3599 lowest val mse: 0.3378 at k 3\n",
      "Iter: 228, running avg mse: 0.3624 lowest val mse: 0.3356 at k 3\n",
      "Iter: 229, running avg mse: 0.3619 lowest val mse: 0.3370 at k 3\n",
      "Iter: 230, running avg mse: 0.3639 lowest val mse: 0.3364 at k 3\n",
      "Iter: 231, running avg mse: 0.3634 lowest val mse: 0.3338 at k 3\n",
      "Iter: 232, running avg mse: 0.3630 lowest val mse: 0.3363 at k 3\n",
      "Iter: 233, running avg mse: 0.3570 lowest val mse: 0.3344 at k 3\n",
      "Iter: 234, running avg mse: 0.3592 lowest val mse: 0.3330 at k 3\n",
      "Iter: 235, running avg mse: 0.3594 lowest val mse: 0.3333 at k 3\n",
      "Iter: 236, running avg mse: 0.3575 lowest val mse: 0.3334 at k 3\n",
      "Iter: 237, running avg mse: 0.3593 lowest val mse: 0.3340 at k 3\n",
      "Iter: 238, running avg mse: 0.3535 lowest val mse: 0.3349 at k 3\n",
      "Iter: 239, running avg mse: 0.3701 lowest val mse: 0.3429 at k 4\n",
      "Iter: 240, running avg mse: 0.3635 lowest val mse: 0.3371 at k 3\n",
      "Iter: 241, running avg mse: 0.3652 lowest val mse: 0.3361 at k 3\n",
      "Iter: 242, running avg mse: 0.3586 lowest val mse: 0.3329 at k 3\n",
      "Iter: 243, running avg mse: 0.3594 lowest val mse: 0.3335 at k 3\n",
      "Iter: 244, running avg mse: 0.3539 lowest val mse: 0.3331 at k 3\n",
      "Iter: 245, running avg mse: 0.3584 lowest val mse: 0.3353 at k 3\n",
      "Iter: 246, running avg mse: 0.3546 lowest val mse: 0.3331 at k 3\n",
      "Iter: 247, running avg mse: 0.3584 lowest val mse: 0.3340 at k 3\n",
      "Iter: 248, running avg mse: 0.3562 lowest val mse: 0.3339 at k 3\n",
      "Iter: 249, running avg mse: 0.3551 lowest val mse: 0.3313 at k 3\n",
      "Iter: 250, running avg mse: 0.3572 lowest val mse: 0.3327 at k 3\n",
      "Iter: 251, running avg mse: 0.3514 lowest val mse: 0.3333 at k 3\n",
      "Iter: 252, running avg mse: 0.3507 lowest val mse: 0.3343 at k 3\n",
      "Iter: 253, running avg mse: 0.3731 lowest val mse: 0.3477 at k 4\n",
      "Iter: 254, running avg mse: 0.3638 lowest val mse: 0.3403 at k 3\n",
      "Iter: 255, running avg mse: 0.3697 lowest val mse: 0.3404 at k 3\n",
      "Iter: 256, running avg mse: 0.3608 lowest val mse: 0.3383 at k 3\n",
      "Iter: 257, running avg mse: 0.3561 lowest val mse: 0.3391 at k 3\n",
      "Iter: 258, running avg mse: 0.3602 lowest val mse: 0.3368 at k 4\n",
      "Iter: 259, running avg mse: 0.3626 lowest val mse: 0.3349 at k 3\n",
      "Iter: 260, running avg mse: 0.3612 lowest val mse: 0.3340 at k 3\n",
      "Iter: 261, running avg mse: 0.3569 lowest val mse: 0.3316 at k 3\n",
      "Iter: 262, running avg mse: 0.3591 lowest val mse: 0.3304 at k 3\n",
      "Iter: 263, running avg mse: 0.3619 lowest val mse: 0.3307 at k 3\n",
      "Iter: 264, running avg mse: 0.3560 lowest val mse: 0.3320 at k 3\n",
      "Iter: 265, running avg mse: 0.3540 lowest val mse: 0.3307 at k 3\n",
      "Iter: 266, running avg mse: 0.3545 lowest val mse: 0.3311 at k 3\n",
      "Iter: 267, running avg mse: 0.3537 lowest val mse: 0.3298 at k 3\n",
      "Iter: 268, running avg mse: 0.3510 lowest val mse: 0.3304 at k 3\n",
      "Iter: 269, running avg mse: 0.3552 lowest val mse: 0.3376 at k 3\n",
      "Iter: 270, running avg mse: 0.3653 lowest val mse: 0.3392 at k 3\n",
      "Iter: 271, running avg mse: 0.3486 lowest val mse: 0.3360 at k 3\n",
      "Iter: 272, running avg mse: 0.3477 lowest val mse: 0.3318 at k 3\n",
      "Iter: 273, running avg mse: 0.3557 lowest val mse: 0.3321 at k 3\n",
      "Iter: 274, running avg mse: 0.3529 lowest val mse: 0.3312 at k 3\n",
      "Iter: 275, running avg mse: 0.3513 lowest val mse: 0.3298 at k 3\n",
      "Iter: 276, running avg mse: 0.3476 lowest val mse: 0.3302 at k 3\n",
      "Iter: 277, running avg mse: 0.3519 lowest val mse: 0.3299 at k 3\n",
      "Iter: 278, running avg mse: 0.3511 lowest val mse: 0.3307 at k 3\n",
      "Iter: 279, running avg mse: 0.3555 lowest val mse: 0.3304 at k 3\n",
      "Iter: 280, running avg mse: 0.3432 lowest val mse: 0.3299 at k 3\n",
      "Iter: 281, running avg mse: 0.3494 lowest val mse: 0.3290 at k 3\n",
      "Iter: 282, running avg mse: 0.3573 lowest val mse: 0.3294 at k 3\n",
      "Iter: 283, running avg mse: 0.3462 lowest val mse: 0.3298 at k 3\n",
      "Iter: 284, running avg mse: 0.3519 lowest val mse: 0.3324 at k 3\n",
      "Iter: 285, running avg mse: 0.3445 lowest val mse: 0.3317 at k 3\n",
      "Iter: 286, running avg mse: 0.3557 lowest val mse: 0.3340 at k 3\n",
      "Iter: 287, running avg mse: 0.3516 lowest val mse: 0.3320 at k 3\n",
      "Iter: 288, running avg mse: 0.3577 lowest val mse: 0.3317 at k 3\n",
      "Iter: 289, running avg mse: 0.3586 lowest val mse: 0.3292 at k 3\n",
      "Iter: 290, running avg mse: 0.3474 lowest val mse: 0.3327 at k 3\n",
      "Iter: 291, running avg mse: 0.3391 lowest val mse: 0.3286 at k 3\n",
      "Iter: 292, running avg mse: 0.3475 lowest val mse: 0.3324 at k 3\n",
      "Iter: 293, running avg mse: 0.3454 lowest val mse: 0.3301 at k 3\n",
      "Iter: 294, running avg mse: 0.3491 lowest val mse: 0.3284 at k 3\n",
      "Iter: 295, running avg mse: 0.3520 lowest val mse: 0.3294 at k 3\n",
      "Iter: 296, running avg mse: 0.3407 lowest val mse: 0.3295 at k 3\n",
      "Iter: 297, running avg mse: 0.3513 lowest val mse: 0.3292 at k 3\n",
      "Iter: 298, running avg mse: 0.3447 lowest val mse: 0.3300 at k 3\n",
      "Iter: 299, running avg mse: 0.3553 lowest val mse: 0.3290 at k 3\n",
      "Iter: 300, running avg mse: 0.3551 lowest val mse: 0.3300 at k 3\n",
      "Iter: 301, running avg mse: 0.3497 lowest val mse: 0.3289 at k 3\n",
      "Iter: 302, running avg mse: 0.3464 lowest val mse: 0.3272 at k 3\n",
      "Iter: 303, running avg mse: 0.3372 lowest val mse: 0.3291 at k 3\n",
      "Iter: 304, running avg mse: 0.3496 lowest val mse: 0.3271 at k 3\n",
      "Iter: 305, running avg mse: 0.3459 lowest val mse: 0.3286 at k 3\n",
      "Iter: 306, running avg mse: 0.3481 lowest val mse: 0.3337 at k 3\n",
      "Iter: 307, running avg mse: 0.3494 lowest val mse: 0.3312 at k 3\n",
      "Iter: 308, running avg mse: 0.3455 lowest val mse: 0.3313 at k 3\n",
      "Iter: 309, running avg mse: 0.3427 lowest val mse: 0.3294 at k 3\n",
      "Iter: 310, running avg mse: 0.3413 lowest val mse: 0.3280 at k 3\n",
      "Iter: 311, running avg mse: 0.3452 lowest val mse: 0.3281 at k 3\n",
      "Iter: 312, running avg mse: 0.3572 lowest val mse: 0.3298 at k 3\n",
      "Iter: 313, running avg mse: 0.3450 lowest val mse: 0.3307 at k 3\n",
      "Iter: 314, running avg mse: 0.3444 lowest val mse: 0.3294 at k 3\n",
      "Iter: 315, running avg mse: 0.3419 lowest val mse: 0.3276 at k 3\n",
      "Iter: 316, running avg mse: 0.3506 lowest val mse: 0.3278 at k 3\n",
      "Iter: 317, running avg mse: 0.3473 lowest val mse: 0.3295 at k 3\n",
      "Iter: 318, running avg mse: 0.3504 lowest val mse: 0.3351 at k 3\n",
      "Iter: 319, running avg mse: 0.3510 lowest val mse: 0.3308 at k 3\n",
      "Iter: 320, running avg mse: 0.3530 lowest val mse: 0.3313 at k 3\n",
      "Iter: 321, running avg mse: 0.3542 lowest val mse: 0.3264 at k 3\n",
      "Iter: 322, running avg mse: 0.3547 lowest val mse: 0.3304 at k 3\n",
      "Iter: 323, running avg mse: 0.3451 lowest val mse: 0.3289 at k 3\n",
      "Iter: 324, running avg mse: 0.3438 lowest val mse: 0.3304 at k 3\n",
      "Iter: 325, running avg mse: 0.3484 lowest val mse: 0.3270 at k 3\n",
      "Iter: 326, running avg mse: 0.3446 lowest val mse: 0.3319 at k 3\n",
      "Iter: 327, running avg mse: 0.3419 lowest val mse: 0.3272 at k 3\n",
      "Iter: 328, running avg mse: 0.3490 lowest val mse: 0.3298 at k 3\n",
      "Iter: 329, running avg mse: 0.3453 lowest val mse: 0.3275 at k 3\n",
      "Iter: 330, running avg mse: 0.3489 lowest val mse: 0.3280 at k 3\n",
      "Iter: 331, running avg mse: 0.3406 lowest val mse: 0.3263 at k 3\n",
      "Iter: 332, running avg mse: 0.3428 lowest val mse: 0.3259 at k 3\n",
      "Iter: 333, running avg mse: 0.3371 lowest val mse: 0.3263 at k 3\n",
      "Iter: 334, running avg mse: 0.3386 lowest val mse: 0.3269 at k 3\n",
      "Iter: 335, running avg mse: 0.3485 lowest val mse: 0.3262 at k 3\n",
      "Iter: 336, running avg mse: 0.3396 lowest val mse: 0.3258 at k 3\n",
      "Iter: 337, running avg mse: 0.3454 lowest val mse: 0.3259 at k 3\n",
      "Iter: 338, running avg mse: 0.3393 lowest val mse: 0.3266 at k 3\n",
      "Iter: 339, running avg mse: 0.3500 lowest val mse: 0.3349 at k 4\n",
      "Iter: 340, running avg mse: 0.3592 lowest val mse: 0.3341 at k 3\n",
      "Iter: 341, running avg mse: 0.3518 lowest val mse: 0.3390 at k 4\n",
      "Iter: 342, running avg mse: 0.3467 lowest val mse: 0.3344 at k 3\n",
      "Iter: 343, running avg mse: 0.3473 lowest val mse: 0.3338 at k 3\n",
      "Iter: 344, running avg mse: 0.3450 lowest val mse: 0.3316 at k 3\n",
      "Iter: 345, running avg mse: 0.3471 lowest val mse: 0.3301 at k 4\n",
      "Iter: 346, running avg mse: 0.3473 lowest val mse: 0.3312 at k 3\n",
      "Iter: 347, running avg mse: 0.3529 lowest val mse: 0.3298 at k 3\n",
      "Iter: 348, running avg mse: 0.3502 lowest val mse: 0.3293 at k 3\n",
      "Iter: 349, running avg mse: 0.3458 lowest val mse: 0.3265 at k 3\n",
      "Iter: 350, running avg mse: 0.3528 lowest val mse: 0.3277 at k 3\n",
      "Iter: 351, running avg mse: 0.3404 lowest val mse: 0.3255 at k 3\n",
      "Iter: 352, running avg mse: 0.3397 lowest val mse: 0.3250 at k 3\n",
      "Iter: 353, running avg mse: 0.3398 lowest val mse: 0.3262 at k 3\n",
      "Iter: 354, running avg mse: 0.3411 lowest val mse: 0.3260 at k 3\n",
      "Iter: 355, running avg mse: 0.3484 lowest val mse: 0.3251 at k 3\n",
      "Iter: 356, running avg mse: 0.3454 lowest val mse: 0.3259 at k 3\n",
      "Iter: 357, running avg mse: 0.3476 lowest val mse: 0.3247 at k 3\n",
      "Iter: 358, running avg mse: 0.3431 lowest val mse: 0.3245 at k 3\n",
      "Iter: 359, running avg mse: 0.3453 lowest val mse: 0.3261 at k 3\n",
      "Iter: 360, running avg mse: 0.3478 lowest val mse: 0.3288 at k 3\n",
      "Iter: 361, running avg mse: 0.3453 lowest val mse: 0.3268 at k 3\n",
      "Iter: 362, running avg mse: 0.3423 lowest val mse: 0.3247 at k 3\n",
      "Iter: 363, running avg mse: 0.3387 lowest val mse: 0.3267 at k 3\n",
      "Iter: 364, running avg mse: 0.3359 lowest val mse: 0.3242 at k 3\n",
      "Iter: 365, running avg mse: 0.3418 lowest val mse: 0.3247 at k 3\n",
      "Iter: 366, running avg mse: 0.3527 lowest val mse: 0.3243 at k 3\n",
      "Iter: 367, running avg mse: 0.3458 lowest val mse: 0.3235 at k 3\n",
      "Iter: 368, running avg mse: 0.3390 lowest val mse: 0.3241 at k 3\n",
      "Iter: 369, running avg mse: 0.3378 lowest val mse: 0.3235 at k 3\n",
      "Iter: 370, running avg mse: 0.3389 lowest val mse: 0.3238 at k 3\n",
      "Iter: 371, running avg mse: 0.3415 lowest val mse: 0.3244 at k 3\n",
      "Iter: 372, running avg mse: 0.3399 lowest val mse: 0.3285 at k 3\n",
      "Iter: 373, running avg mse: 0.3416 lowest val mse: 0.3290 at k 3\n",
      "Iter: 374, running avg mse: 0.3430 lowest val mse: 0.3253 at k 3\n",
      "Iter: 375, running avg mse: 0.3445 lowest val mse: 0.3252 at k 3\n",
      "Iter: 376, running avg mse: 0.3379 lowest val mse: 0.3242 at k 3\n",
      "Iter: 377, running avg mse: 0.3384 lowest val mse: 0.3242 at k 3\n",
      "Iter: 378, running avg mse: 0.3394 lowest val mse: 0.3243 at k 3\n",
      "Iter: 379, running avg mse: 0.3393 lowest val mse: 0.3237 at k 3\n",
      "Iter: 380, running avg mse: 0.3376 lowest val mse: 0.3237 at k 3\n",
      "Iter: 381, running avg mse: 0.3383 lowest val mse: 0.3243 at k 3\n",
      "Iter: 382, running avg mse: 0.3397 lowest val mse: 0.3251 at k 3\n",
      "Iter: 383, running avg mse: 0.3393 lowest val mse: 0.3277 at k 3\n",
      "Iter: 384, running avg mse: 0.3507 lowest val mse: 0.3387 at k 3\n",
      "Iter: 385, running avg mse: 0.3369 lowest val mse: 0.3346 at k 3\n",
      "Iter: 386, running avg mse: 0.3461 lowest val mse: 0.3276 at k 3\n",
      "Iter: 387, running avg mse: 0.3424 lowest val mse: 0.3311 at k 3\n",
      "Iter: 388, running avg mse: 0.3448 lowest val mse: 0.3256 at k 3\n",
      "Iter: 389, running avg mse: 0.3370 lowest val mse: 0.3265 at k 3\n",
      "Iter: 390, running avg mse: 0.3503 lowest val mse: 0.3245 at k 3\n",
      "Iter: 391, running avg mse: 0.3429 lowest val mse: 0.3249 at k 3\n",
      "Iter: 392, running avg mse: 0.3319 lowest val mse: 0.3234 at k 3\n",
      "Iter: 393, running avg mse: 0.3402 lowest val mse: 0.3241 at k 3\n",
      "Iter: 394, running avg mse: 0.3374 lowest val mse: 0.3248 at k 3\n",
      "Iter: 395, running avg mse: 0.3304 lowest val mse: 0.3230 at k 3\n",
      "Iter: 396, running avg mse: 0.3413 lowest val mse: 0.3258 at k 3\n",
      "Iter: 397, running avg mse: 0.3387 lowest val mse: 0.3263 at k 3\n",
      "Iter: 398, running avg mse: 0.3292 lowest val mse: 0.3233 at k 3\n",
      "Iter: 399, running avg mse: 0.3361 lowest val mse: 0.3235 at k 3\n",
      "Iter: 400, running avg mse: 0.3293 lowest val mse: 0.3226 at k 3\n",
      "Iter: 401, running avg mse: 0.3419 lowest val mse: 0.3234 at k 3\n",
      "Iter: 402, running avg mse: 0.3426 lowest val mse: 0.3227 at k 3\n",
      "Iter: 403, running avg mse: 0.3396 lowest val mse: 0.3228 at k 3\n",
      "Iter: 404, running avg mse: 0.3425 lowest val mse: 0.3237 at k 3\n",
      "Iter: 405, running avg mse: 0.3336 lowest val mse: 0.3248 at k 3\n",
      "Iter: 406, running avg mse: 0.3346 lowest val mse: 0.3248 at k 3\n",
      "Iter: 407, running avg mse: 0.3468 lowest val mse: 0.3248 at k 3\n",
      "Iter: 408, running avg mse: 0.3396 lowest val mse: 0.3245 at k 3\n",
      "Iter: 409, running avg mse: 0.3351 lowest val mse: 0.3226 at k 3\n",
      "Iter: 410, running avg mse: 0.3390 lowest val mse: 0.3228 at k 3\n",
      "Iter: 411, running avg mse: 0.3402 lowest val mse: 0.3231 at k 3\n",
      "Iter: 412, running avg mse: 0.3357 lowest val mse: 0.3242 at k 3\n",
      "Iter: 413, running avg mse: 0.3361 lowest val mse: 0.3242 at k 3\n",
      "Iter: 414, running avg mse: 0.3358 lowest val mse: 0.3223 at k 3\n",
      "Iter: 415, running avg mse: 0.3406 lowest val mse: 0.3237 at k 3\n",
      "Iter: 416, running avg mse: 0.3307 lowest val mse: 0.3252 at k 3\n",
      "Iter: 417, running avg mse: 0.3418 lowest val mse: 0.3233 at k 3\n",
      "Iter: 418, running avg mse: 0.3309 lowest val mse: 0.3232 at k 3\n",
      "Iter: 419, running avg mse: 0.3297 lowest val mse: 0.3220 at k 3\n",
      "Iter: 420, running avg mse: 0.3313 lowest val mse: 0.3222 at k 3\n",
      "Iter: 421, running avg mse: 0.3348 lowest val mse: 0.3217 at k 3\n",
      "Iter: 422, running avg mse: 0.3399 lowest val mse: 0.3230 at k 3\n",
      "Iter: 423, running avg mse: 0.3469 lowest val mse: 0.3310 at k 3\n",
      "Iter: 424, running avg mse: 0.3393 lowest val mse: 0.3245 at k 3\n",
      "Iter: 425, running avg mse: 0.3346 lowest val mse: 0.3258 at k 3\n",
      "Iter: 426, running avg mse: 0.3420 lowest val mse: 0.3256 at k 3\n",
      "Iter: 427, running avg mse: 0.3412 lowest val mse: 0.3238 at k 3\n",
      "Iter: 428, running avg mse: 0.3283 lowest val mse: 0.3233 at k 3\n",
      "Iter: 429, running avg mse: 0.3377 lowest val mse: 0.3236 at k 3\n",
      "Iter: 430, running avg mse: 0.3332 lowest val mse: 0.3225 at k 3\n",
      "Iter: 431, running avg mse: 0.3358 lowest val mse: 0.3223 at k 3\n",
      "Iter: 432, running avg mse: 0.3331 lowest val mse: 0.3226 at k 3\n",
      "Iter: 433, running avg mse: 0.3333 lowest val mse: 0.3238 at k 3\n",
      "Iter: 434, running avg mse: 0.3407 lowest val mse: 0.3252 at k 3\n",
      "Iter: 435, running avg mse: 0.3393 lowest val mse: 0.3256 at k 3\n",
      "Iter: 436, running avg mse: 0.3333 lowest val mse: 0.3247 at k 3\n",
      "Iter: 437, running avg mse: 0.3280 lowest val mse: 0.3247 at k 3\n",
      "Iter: 438, running avg mse: 0.3335 lowest val mse: 0.3227 at k 3\n",
      "Iter: 439, running avg mse: 0.3310 lowest val mse: 0.3222 at k 3\n",
      "Iter: 440, running avg mse: 0.3395 lowest val mse: 0.3247 at k 3\n",
      "Iter: 441, running avg mse: 0.3425 lowest val mse: 0.3255 at k 3\n",
      "Iter: 442, running avg mse: 0.3342 lowest val mse: 0.3229 at k 3\n",
      "Iter: 443, running avg mse: 0.3353 lowest val mse: 0.3234 at k 3\n",
      "Iter: 444, running avg mse: 0.3382 lowest val mse: 0.3228 at k 3\n",
      "Iter: 445, running avg mse: 0.3436 lowest val mse: 0.3227 at k 3\n",
      "Iter: 446, running avg mse: 0.3352 lowest val mse: 0.3220 at k 3\n",
      "Iter: 447, running avg mse: 0.3319 lowest val mse: 0.3288 at k 3\n",
      "Iter: 448, running avg mse: 0.3337 lowest val mse: 0.3245 at k 3\n",
      "Iter: 449, running avg mse: 0.3346 lowest val mse: 0.3238 at k 3\n",
      "Iter: 450, running avg mse: 0.3399 lowest val mse: 0.3246 at k 3\n",
      "Iter: 451, running avg mse: 0.3363 lowest val mse: 0.3234 at k 3\n",
      "Iter: 452, running avg mse: 0.3314 lowest val mse: 0.3227 at k 3\n",
      "Iter: 453, running avg mse: 0.3236 lowest val mse: 0.3211 at k 3\n",
      "Iter: 454, running avg mse: 0.3309 lowest val mse: 0.3206 at k 3\n",
      "Iter: 455, running avg mse: 0.3359 lowest val mse: 0.3214 at k 3\n",
      "Iter: 456, running avg mse: 0.3364 lowest val mse: 0.3213 at k 3\n",
      "Iter: 457, running avg mse: 0.3326 lowest val mse: 0.3220 at k 3\n",
      "Iter: 458, running avg mse: 0.3378 lowest val mse: 0.3235 at k 3\n",
      "Iter: 459, running avg mse: 0.3425 lowest val mse: 0.3295 at k 3\n",
      "Iter: 460, running avg mse: 0.3359 lowest val mse: 0.3233 at k 3\n",
      "Iter: 461, running avg mse: 0.3447 lowest val mse: 0.3295 at k 3\n",
      "Iter: 462, running avg mse: 0.3374 lowest val mse: 0.3224 at k 3\n",
      "Iter: 463, running avg mse: 0.3401 lowest val mse: 0.3241 at k 3\n",
      "Iter: 464, running avg mse: 0.3330 lowest val mse: 0.3222 at k 3\n",
      "Iter: 465, running avg mse: 0.3333 lowest val mse: 0.3223 at k 3\n",
      "Iter: 466, running avg mse: 0.3358 lowest val mse: 0.3226 at k 3\n",
      "Iter: 467, running avg mse: 0.3349 lowest val mse: 0.3223 at k 3\n",
      "Iter: 468, running avg mse: 0.3291 lowest val mse: 0.3222 at k 3\n",
      "Iter: 469, running avg mse: 0.3311 lowest val mse: 0.3215 at k 3\n",
      "Iter: 470, running avg mse: 0.3348 lowest val mse: 0.3209 at k 3\n",
      "Iter: 471, running avg mse: 0.3275 lowest val mse: 0.3204 at k 3\n",
      "Iter: 472, running avg mse: 0.3348 lowest val mse: 0.3208 at k 3\n",
      "Iter: 473, running avg mse: 0.3352 lowest val mse: 0.3209 at k 3\n",
      "Iter: 474, running avg mse: 0.3296 lowest val mse: 0.3213 at k 3\n",
      "Iter: 475, running avg mse: 0.3288 lowest val mse: 0.3219 at k 3\n",
      "Iter: 476, running avg mse: 0.3375 lowest val mse: 0.3252 at k 3\n",
      "Iter: 477, running avg mse: 0.3318 lowest val mse: 0.3257 at k 3\n",
      "Iter: 478, running avg mse: 0.3331 lowest val mse: 0.3222 at k 3\n",
      "Iter: 479, running avg mse: 0.3377 lowest val mse: 0.3236 at k 3\n",
      "Iter: 480, running avg mse: 0.3410 lowest val mse: 0.3215 at k 3\n",
      "Iter: 481, running avg mse: 0.3348 lowest val mse: 0.3212 at k 3\n",
      "Iter: 482, running avg mse: 0.3265 lowest val mse: 0.3207 at k 3\n",
      "Iter: 483, running avg mse: 0.3343 lowest val mse: 0.3212 at k 3\n",
      "Iter: 484, running avg mse: 0.3339 lowest val mse: 0.3214 at k 3\n",
      "Iter: 485, running avg mse: 0.3363 lowest val mse: 0.3204 at k 3\n",
      "Iter: 486, running avg mse: 0.3282 lowest val mse: 0.3219 at k 3\n",
      "Iter: 487, running avg mse: 0.3365 lowest val mse: 0.3233 at k 3\n",
      "Iter: 488, running avg mse: 0.3334 lowest val mse: 0.3219 at k 3\n",
      "Iter: 489, running avg mse: 0.3351 lowest val mse: 0.3245 at k 3\n",
      "Iter: 490, running avg mse: 0.3444 lowest val mse: 0.3231 at k 3\n",
      "Iter: 491, running avg mse: 0.3346 lowest val mse: 0.3217 at k 3\n",
      "Iter: 492, running avg mse: 0.3327 lowest val mse: 0.3244 at k 3\n",
      "Iter: 493, running avg mse: 0.3331 lowest val mse: 0.3218 at k 3\n",
      "Iter: 494, running avg mse: 0.3320 lowest val mse: 0.3236 at k 3\n",
      "Iter: 495, running avg mse: 0.3417 lowest val mse: 0.3200 at k 3\n",
      "Iter: 496, running avg mse: 0.3307 lowest val mse: 0.3207 at k 3\n",
      "Iter: 497, running avg mse: 0.3388 lowest val mse: 0.3224 at k 3\n",
      "Iter: 498, running avg mse: 0.3359 lowest val mse: 0.3217 at k 3\n",
      "Iter: 499, running avg mse: 0.3332 lowest val mse: 0.3229 at k 3\n",
      "Iter: 500, running avg mse: 0.3312 lowest val mse: 0.3213 at k 3\n",
      "Iter: 501, running avg mse: 0.3339 lowest val mse: 0.3201 at k 3\n",
      "Iter: 502, running avg mse: 0.3313 lowest val mse: 0.3215 at k 3\n",
      "Iter: 503, running avg mse: 0.3390 lowest val mse: 0.3228 at k 3\n",
      "Iter: 504, running avg mse: 0.3341 lowest val mse: 0.3235 at k 3\n",
      "Iter: 505, running avg mse: 0.3305 lowest val mse: 0.3220 at k 3\n",
      "Iter: 506, running avg mse: 0.3291 lowest val mse: 0.3214 at k 3\n",
      "Iter: 507, running avg mse: 0.3250 lowest val mse: 0.3211 at k 3\n",
      "Iter: 508, running avg mse: 0.3313 lowest val mse: 0.3213 at k 3\n",
      "Iter: 509, running avg mse: 0.3285 lowest val mse: 0.3211 at k 3\n",
      "Iter: 510, running avg mse: 0.3313 lowest val mse: 0.3211 at k 3\n",
      "Iter: 511, running avg mse: 0.3362 lowest val mse: 0.3221 at k 3\n",
      "Iter: 512, running avg mse: 0.3293 lowest val mse: 0.3247 at k 3\n",
      "Iter: 513, running avg mse: 0.3493 lowest val mse: 0.3309 at k 3\n",
      "Iter: 514, running avg mse: 0.3344 lowest val mse: 0.3247 at k 3\n",
      "Iter: 515, running avg mse: 0.3291 lowest val mse: 0.3233 at k 3\n",
      "Iter: 516, running avg mse: 0.3371 lowest val mse: 0.3219 at k 3\n",
      "Iter: 517, running avg mse: 0.3352 lowest val mse: 0.3210 at k 3\n",
      "Iter: 518, running avg mse: 0.3328 lowest val mse: 0.3245 at k 3\n",
      "Iter: 519, running avg mse: 0.3422 lowest val mse: 0.3246 at k 3\n",
      "Iter: 520, running avg mse: 0.3341 lowest val mse: 0.3208 at k 3\n",
      "Iter: 521, running avg mse: 0.3272 lowest val mse: 0.3203 at k 3\n",
      "Iter: 522, running avg mse: 0.3272 lowest val mse: 0.3198 at k 3\n",
      "Iter: 523, running avg mse: 0.3300 lowest val mse: 0.3199 at k 3\n",
      "Iter: 524, running avg mse: 0.3294 lowest val mse: 0.3211 at k 3\n",
      "Iter: 525, running avg mse: 0.3274 lowest val mse: 0.3199 at k 3\n",
      "Iter: 526, running avg mse: 0.3297 lowest val mse: 0.3202 at k 3\n",
      "Iter: 527, running avg mse: 0.3331 lowest val mse: 0.3207 at k 3\n",
      "Iter: 528, running avg mse: 0.3293 lowest val mse: 0.3205 at k 3\n",
      "Iter: 529, running avg mse: 0.3319 lowest val mse: 0.3195 at k 3\n",
      "Iter: 530, running avg mse: 0.3264 lowest val mse: 0.3212 at k 3\n",
      "Iter: 531, running avg mse: 0.3332 lowest val mse: 0.3196 at k 3\n",
      "Iter: 532, running avg mse: 0.3267 lowest val mse: 0.3209 at k 3\n",
      "Iter: 533, running avg mse: 0.3293 lowest val mse: 0.3198 at k 3\n",
      "Iter: 534, running avg mse: 0.3348 lowest val mse: 0.3245 at k 3\n",
      "Iter: 535, running avg mse: 0.3396 lowest val mse: 0.3219 at k 3\n",
      "Iter: 536, running avg mse: 0.3339 lowest val mse: 0.3197 at k 3\n",
      "Iter: 537, running avg mse: 0.3337 lowest val mse: 0.3199 at k 3\n",
      "Iter: 538, running avg mse: 0.3301 lowest val mse: 0.3203 at k 3\n",
      "Iter: 539, running avg mse: 0.3266 lowest val mse: 0.3196 at k 3\n",
      "Iter: 540, running avg mse: 0.3293 lowest val mse: 0.3202 at k 3\n",
      "Iter: 541, running avg mse: 0.3271 lowest val mse: 0.3199 at k 3\n",
      "Iter: 542, running avg mse: 0.3317 lowest val mse: 0.3195 at k 3\n",
      "Iter: 543, running avg mse: 0.3367 lowest val mse: 0.3201 at k 3\n",
      "Iter: 544, running avg mse: 0.3355 lowest val mse: 0.3216 at k 3\n",
      "Iter: 545, running avg mse: 0.3309 lowest val mse: 0.3214 at k 3\n",
      "Iter: 546, running avg mse: 0.3298 lowest val mse: 0.3196 at k 3\n",
      "Iter: 547, running avg mse: 0.3317 lowest val mse: 0.3198 at k 3\n",
      "Iter: 548, running avg mse: 0.3275 lowest val mse: 0.3217 at k 3\n",
      "Iter: 549, running avg mse: 0.3318 lowest val mse: 0.3238 at k 3\n",
      "Iter: 550, running avg mse: 0.3383 lowest val mse: 0.3238 at k 3\n",
      "Iter: 551, running avg mse: 0.3281 lowest val mse: 0.3206 at k 3\n",
      "Iter: 552, running avg mse: 0.3261 lowest val mse: 0.3222 at k 3\n",
      "Iter: 553, running avg mse: 0.3303 lowest val mse: 0.3206 at k 3\n",
      "Iter: 554, running avg mse: 0.3306 lowest val mse: 0.3222 at k 3\n",
      "Iter: 555, running avg mse: 0.3245 lowest val mse: 0.3205 at k 3\n",
      "Iter: 556, running avg mse: 0.3312 lowest val mse: 0.3214 at k 3\n",
      "Iter: 557, running avg mse: 0.3300 lowest val mse: 0.3203 at k 3\n",
      "Iter: 558, running avg mse: 0.3262 lowest val mse: 0.3222 at k 3\n",
      "Iter: 559, running avg mse: 0.3317 lowest val mse: 0.3221 at k 3\n",
      "Iter: 560, running avg mse: 0.3356 lowest val mse: 0.3220 at k 3\n",
      "Iter: 561, running avg mse: 0.3346 lowest val mse: 0.3263 at k 3\n",
      "Iter: 562, running avg mse: 0.3353 lowest val mse: 0.3209 at k 3\n",
      "Iter: 563, running avg mse: 0.3384 lowest val mse: 0.3215 at k 3\n",
      "Iter: 564, running avg mse: 0.3310 lowest val mse: 0.3196 at k 3\n",
      "Iter: 565, running avg mse: 0.3323 lowest val mse: 0.3206 at k 3\n",
      "Iter: 566, running avg mse: 0.3286 lowest val mse: 0.3200 at k 3\n",
      "Iter: 567, running avg mse: 0.3284 lowest val mse: 0.3216 at k 3\n",
      "Iter: 568, running avg mse: 0.3392 lowest val mse: 0.3217 at k 3\n",
      "Iter: 569, running avg mse: 0.3250 lowest val mse: 0.3207 at k 3\n",
      "Iter: 570, running avg mse: 0.3340 lowest val mse: 0.3225 at k 3\n",
      "Iter: 571, running avg mse: 0.3336 lowest val mse: 0.3206 at k 3\n",
      "Iter: 572, running avg mse: 0.3338 lowest val mse: 0.3212 at k 3\n",
      "Iter: 573, running avg mse: 0.3303 lowest val mse: 0.3190 at k 3\n",
      "Iter: 574, running avg mse: 0.3317 lowest val mse: 0.3190 at k 3\n",
      "Iter: 575, running avg mse: 0.3321 lowest val mse: 0.3192 at k 3\n",
      "Iter: 576, running avg mse: 0.3345 lowest val mse: 0.3209 at k 3\n",
      "Iter: 577, running avg mse: 0.3342 lowest val mse: 0.3220 at k 3\n",
      "Iter: 578, running avg mse: 0.3305 lowest val mse: 0.3206 at k 3\n",
      "Iter: 579, running avg mse: 0.3263 lowest val mse: 0.3207 at k 3\n",
      "Iter: 580, running avg mse: 0.3279 lowest val mse: 0.3205 at k 3\n",
      "Iter: 581, running avg mse: 0.3293 lowest val mse: 0.3194 at k 3\n",
      "Iter: 582, running avg mse: 0.3270 lowest val mse: 0.3189 at k 3\n",
      "Iter: 583, running avg mse: 0.3284 lowest val mse: 0.3197 at k 3\n",
      "Iter: 584, running avg mse: 0.3304 lowest val mse: 0.3195 at k 3\n",
      "Iter: 585, running avg mse: 0.3246 lowest val mse: 0.3192 at k 3\n",
      "Iter: 586, running avg mse: 0.3319 lowest val mse: 0.3198 at k 3\n",
      "Iter: 587, running avg mse: 0.3256 lowest val mse: 0.3209 at k 3\n",
      "Iter: 588, running avg mse: 0.3351 lowest val mse: 0.3212 at k 3\n",
      "Iter: 589, running avg mse: 0.3245 lowest val mse: 0.3195 at k 3\n",
      "Iter: 590, running avg mse: 0.3262 lowest val mse: 0.3205 at k 3\n",
      "Iter: 591, running avg mse: 0.3354 lowest val mse: 0.3212 at k 3\n",
      "Iter: 592, running avg mse: 0.3290 lowest val mse: 0.3195 at k 3\n",
      "Iter: 593, running avg mse: 0.3391 lowest val mse: 0.3217 at k 3\n",
      "Iter: 594, running avg mse: 0.3317 lowest val mse: 0.3227 at k 3\n",
      "Iter: 595, running avg mse: 0.3269 lowest val mse: 0.3187 at k 3\n",
      "Iter: 596, running avg mse: 0.3336 lowest val mse: 0.3232 at k 3\n",
      "Iter: 597, running avg mse: 0.3317 lowest val mse: 0.3229 at k 3\n",
      "Iter: 598, running avg mse: 0.3294 lowest val mse: 0.3243 at k 3\n",
      "Iter: 599, running avg mse: 0.3326 lowest val mse: 0.3226 at k 3\n",
      "Iter: 600, running avg mse: 0.3357 lowest val mse: 0.3215 at k 3\n",
      "Iter: 601, running avg mse: 0.3230 lowest val mse: 0.3198 at k 3\n",
      "Iter: 602, running avg mse: 0.3252 lowest val mse: 0.3185 at k 3\n",
      "Iter: 603, running avg mse: 0.3205 lowest val mse: 0.3190 at k 3\n",
      "Iter: 604, running avg mse: 0.3259 lowest val mse: 0.3193 at k 3\n",
      "Iter: 605, running avg mse: 0.3264 lowest val mse: 0.3199 at k 3\n",
      "Iter: 606, running avg mse: 0.3273 lowest val mse: 0.3200 at k 3\n",
      "Iter: 607, running avg mse: 0.3312 lowest val mse: 0.3184 at k 3\n",
      "Iter: 608, running avg mse: 0.3342 lowest val mse: 0.3182 at k 3\n",
      "Iter: 609, running avg mse: 0.3274 lowest val mse: 0.3200 at k 3\n",
      "Iter: 610, running avg mse: 0.3305 lowest val mse: 0.3217 at k 3\n",
      "Iter: 611, running avg mse: 0.3359 lowest val mse: 0.3253 at k 3\n",
      "Iter: 612, running avg mse: 0.3278 lowest val mse: 0.3219 at k 3\n",
      "Iter: 613, running avg mse: 0.3356 lowest val mse: 0.3252 at k 3\n",
      "Iter: 614, running avg mse: 0.3335 lowest val mse: 0.3226 at k 3\n",
      "Iter: 615, running avg mse: 0.3314 lowest val mse: 0.3225 at k 3\n",
      "Iter: 616, running avg mse: 0.3353 lowest val mse: 0.3220 at k 3\n",
      "Iter: 617, running avg mse: 0.3254 lowest val mse: 0.3200 at k 3\n",
      "Iter: 618, running avg mse: 0.3268 lowest val mse: 0.3197 at k 3\n",
      "Iter: 619, running avg mse: 0.4541 lowest val mse: 0.4476 at k 3\n",
      "Iter: 620, running avg mse: 0.4785 lowest val mse: 0.4299 at k 2\n",
      "Iter: 621, running avg mse: 0.4387 lowest val mse: 0.3830 at k 4\n",
      "Iter: 622, running avg mse: 0.3909 lowest val mse: 0.3720 at k 4\n",
      "Iter: 623, running avg mse: 0.3788 lowest val mse: 0.3523 at k 4\n",
      "Iter: 624, running avg mse: 0.3694 lowest val mse: 0.3454 at k 4\n",
      "Iter: 625, running avg mse: 0.3642 lowest val mse: 0.3419 at k 4\n",
      "Iter: 626, running avg mse: 0.3529 lowest val mse: 0.3336 at k 3\n",
      "Iter: 627, running avg mse: 0.3443 lowest val mse: 0.3315 at k 3\n",
      "Iter: 628, running avg mse: 0.3429 lowest val mse: 0.3300 at k 3\n",
      "Iter: 629, running avg mse: 0.3399 lowest val mse: 0.3269 at k 3\n",
      "Iter: 630, running avg mse: 0.3508 lowest val mse: 0.3291 at k 3\n",
      "Iter: 631, running avg mse: 0.3421 lowest val mse: 0.3251 at k 3\n",
      "Iter: 632, running avg mse: 0.3420 lowest val mse: 0.3285 at k 3\n",
      "Iter: 633, running avg mse: 0.3421 lowest val mse: 0.3267 at k 3\n",
      "Iter: 634, running avg mse: 0.3405 lowest val mse: 0.3228 at k 3\n",
      "Iter: 635, running avg mse: 0.3412 lowest val mse: 0.3229 at k 3\n",
      "Iter: 636, running avg mse: 0.3369 lowest val mse: 0.3236 at k 3\n",
      "Iter: 637, running avg mse: 0.3424 lowest val mse: 0.3221 at k 3\n",
      "Iter: 638, running avg mse: 0.3384 lowest val mse: 0.3231 at k 3\n",
      "Iter: 639, running avg mse: 0.3318 lowest val mse: 0.3239 at k 3\n",
      "Iter: 640, running avg mse: 0.3410 lowest val mse: 0.3210 at k 3\n",
      "Iter: 641, running avg mse: 0.3357 lowest val mse: 0.3220 at k 3\n",
      "Iter: 642, running avg mse: 0.3299 lowest val mse: 0.3207 at k 3\n",
      "Iter: 643, running avg mse: 0.3293 lowest val mse: 0.3220 at k 3\n",
      "Iter: 644, running avg mse: 0.3342 lowest val mse: 0.3204 at k 3\n",
      "Iter: 645, running avg mse: 0.3342 lowest val mse: 0.3204 at k 3\n",
      "Iter: 646, running avg mse: 0.3284 lowest val mse: 0.3203 at k 3\n",
      "Iter: 647, running avg mse: 0.3343 lowest val mse: 0.3195 at k 3\n",
      "Iter: 648, running avg mse: 0.3360 lowest val mse: 0.3188 at k 3\n",
      "Iter: 649, running avg mse: 0.3361 lowest val mse: 0.3195 at k 3\n",
      "Iter: 650, running avg mse: 0.3310 lowest val mse: 0.3191 at k 3\n",
      "Iter: 651, running avg mse: 0.3287 lowest val mse: 0.3198 at k 3\n",
      "Iter: 652, running avg mse: 0.3367 lowest val mse: 0.3211 at k 3\n",
      "Iter: 653, running avg mse: 0.3306 lowest val mse: 0.3199 at k 3\n",
      "Iter: 654, running avg mse: 0.3337 lowest val mse: 0.3195 at k 3\n",
      "Iter: 655, running avg mse: 0.3278 lowest val mse: 0.3193 at k 3\n",
      "Iter: 656, running avg mse: 0.3287 lowest val mse: 0.3192 at k 3\n",
      "Iter: 657, running avg mse: 0.3293 lowest val mse: 0.3210 at k 3\n",
      "Iter: 658, running avg mse: 0.3299 lowest val mse: 0.3188 at k 3\n",
      "Iter: 659, running avg mse: 0.3260 lowest val mse: 0.3184 at k 3\n",
      "Iter: 660, running avg mse: 0.3388 lowest val mse: 0.3184 at k 3\n",
      "Iter: 661, running avg mse: 0.3292 lowest val mse: 0.3205 at k 3\n",
      "Iter: 662, running avg mse: 0.3359 lowest val mse: 0.3219 at k 3\n",
      "Iter: 663, running avg mse: 0.3344 lowest val mse: 0.3207 at k 3\n",
      "Iter: 664, running avg mse: 0.3323 lowest val mse: 0.3192 at k 3\n",
      "Iter: 665, running avg mse: 0.3289 lowest val mse: 0.3193 at k 3\n",
      "Iter: 666, running avg mse: 0.3289 lowest val mse: 0.3186 at k 3\n",
      "Iter: 667, running avg mse: 0.3327 lowest val mse: 0.3190 at k 3\n",
      "Iter: 668, running avg mse: 0.3308 lowest val mse: 0.3199 at k 3\n",
      "Iter: 669, running avg mse: 0.3378 lowest val mse: 0.3230 at k 3\n",
      "Iter: 670, running avg mse: 0.3306 lowest val mse: 0.3182 at k 3\n",
      "Iter: 671, running avg mse: 0.3345 lowest val mse: 0.3202 at k 3\n",
      "Iter: 672, running avg mse: 0.3319 lowest val mse: 0.3201 at k 3\n",
      "Iter: 673, running avg mse: 0.3285 lowest val mse: 0.3201 at k 3\n",
      "Iter: 674, running avg mse: 0.3280 lowest val mse: 0.3195 at k 3\n",
      "Iter: 675, running avg mse: 0.3304 lowest val mse: 0.3186 at k 3\n",
      "Iter: 676, running avg mse: 0.3318 lowest val mse: 0.3190 at k 3\n",
      "Iter: 677, running avg mse: 0.3269 lowest val mse: 0.3186 at k 3\n",
      "Iter: 678, running avg mse: 0.3333 lowest val mse: 0.3190 at k 3\n",
      "Iter: 679, running avg mse: 0.3342 lowest val mse: 0.3189 at k 3\n",
      "Iter: 680, running avg mse: 0.3292 lowest val mse: 0.3193 at k 3\n",
      "Iter: 681, running avg mse: 0.3250 lowest val mse: 0.3201 at k 3\n",
      "Iter: 682, running avg mse: 0.3233 lowest val mse: 0.3188 at k 3\n",
      "Iter: 683, running avg mse: 0.3312 lowest val mse: 0.3199 at k 3\n",
      "Iter: 684, running avg mse: 0.3313 lowest val mse: 0.3184 at k 3\n",
      "Iter: 685, running avg mse: 0.3225 lowest val mse: 0.3189 at k 3\n",
      "Iter: 686, running avg mse: 0.3255 lowest val mse: 0.3191 at k 3\n",
      "Iter: 687, running avg mse: 0.3317 lowest val mse: 0.3207 at k 3\n",
      "Iter: 688, running avg mse: 0.3301 lowest val mse: 0.3192 at k 3\n",
      "Iter: 689, running avg mse: 0.3291 lowest val mse: 0.3184 at k 3\n",
      "Iter: 690, running avg mse: 0.3284 lowest val mse: 0.3203 at k 3\n",
      "Iter: 691, running avg mse: 0.3421 lowest val mse: 0.3183 at k 3\n",
      "Iter: 692, running avg mse: 0.3312 lowest val mse: 0.3192 at k 3\n",
      "Iter: 693, running avg mse: 0.3352 lowest val mse: 0.3180 at k 3\n",
      "Iter: 694, running avg mse: 0.3299 lowest val mse: 0.3185 at k 3\n",
      "Iter: 695, running avg mse: 0.3245 lowest val mse: 0.3186 at k 3\n",
      "Iter: 696, running avg mse: 0.3304 lowest val mse: 0.3189 at k 3\n",
      "Iter: 697, running avg mse: 0.3280 lowest val mse: 0.3197 at k 3\n",
      "Iter: 698, running avg mse: 0.3268 lowest val mse: 0.3180 at k 3\n",
      "Iter: 699, running avg mse: 0.3291 lowest val mse: 0.3188 at k 3\n",
      "Iter: 700, running avg mse: 0.3245 lowest val mse: 0.3211 at k 3\n",
      "Iter: 701, running avg mse: 0.3324 lowest val mse: 0.3233 at k 3\n",
      "Iter: 702, running avg mse: 0.3285 lowest val mse: 0.3194 at k 3\n",
      "Iter: 703, running avg mse: 0.3372 lowest val mse: 0.3267 at k 3\n",
      "Iter: 704, running avg mse: 0.3221 lowest val mse: 0.3241 at k 3\n",
      "Iter: 705, running avg mse: 0.3240 lowest val mse: 0.3225 at k 3\n",
      "Iter: 706, running avg mse: 0.3316 lowest val mse: 0.3223 at k 3\n",
      "Iter: 707, running avg mse: 0.3348 lowest val mse: 0.3200 at k 3\n",
      "Iter: 708, running avg mse: 0.3306 lowest val mse: 0.3214 at k 3\n",
      "Iter: 709, running avg mse: 0.3347 lowest val mse: 0.3194 at k 3\n",
      "Iter: 710, running avg mse: 0.3270 lowest val mse: 0.3193 at k 3\n",
      "Iter: 711, running avg mse: 0.3272 lowest val mse: 0.3189 at k 3\n",
      "Iter: 712, running avg mse: 0.3296 lowest val mse: 0.3185 at k 3\n",
      "Iter: 713, running avg mse: 0.3297 lowest val mse: 0.3188 at k 3\n",
      "Iter: 714, running avg mse: 0.3219 lowest val mse: 0.3183 at k 3\n",
      "Iter: 715, running avg mse: 0.3329 lowest val mse: 0.3195 at k 3\n",
      "Iter: 716, running avg mse: 0.3239 lowest val mse: 0.3175 at k 3\n",
      "Iter: 717, running avg mse: 0.3299 lowest val mse: 0.3182 at k 3\n",
      "Iter: 718, running avg mse: 0.3199 lowest val mse: 0.3183 at k 3\n",
      "Iter: 719, running avg mse: 0.3228 lowest val mse: 0.3179 at k 3\n",
      "Iter: 720, running avg mse: 0.3287 lowest val mse: 0.3185 at k 3\n",
      "Iter: 721, running avg mse: 0.3232 lowest val mse: 0.3179 at k 3\n",
      "Iter: 722, running avg mse: 0.3229 lowest val mse: 0.3184 at k 3\n",
      "Iter: 723, running avg mse: 0.3250 lowest val mse: 0.3192 at k 3\n",
      "Iter: 724, running avg mse: 0.3271 lowest val mse: 0.3177 at k 3\n",
      "Iter: 725, running avg mse: 0.3315 lowest val mse: 0.3183 at k 3\n",
      "Iter: 726, running avg mse: 0.3227 lowest val mse: 0.3178 at k 3\n",
      "Iter: 727, running avg mse: 0.3324 lowest val mse: 0.3197 at k 3\n",
      "Iter: 728, running avg mse: 0.3285 lowest val mse: 0.3212 at k 3\n",
      "Iter: 729, running avg mse: 0.3283 lowest val mse: 0.3205 at k 3\n",
      "Iter: 730, running avg mse: 0.3252 lowest val mse: 0.3181 at k 3\n",
      "Iter: 731, running avg mse: 0.3246 lowest val mse: 0.3185 at k 3\n",
      "Iter: 732, running avg mse: 0.3253 lowest val mse: 0.3212 at k 3\n",
      "Iter: 733, running avg mse: 0.3273 lowest val mse: 0.3204 at k 3\n",
      "Iter: 734, running avg mse: 0.3331 lowest val mse: 0.3185 at k 3\n",
      "Iter: 735, running avg mse: 0.3245 lowest val mse: 0.3200 at k 3\n",
      "Iter: 736, running avg mse: 0.3267 lowest val mse: 0.3189 at k 3\n",
      "Iter: 737, running avg mse: 0.3351 lowest val mse: 0.3195 at k 3\n",
      "Iter: 738, running avg mse: 0.3269 lowest val mse: 0.3189 at k 3\n",
      "Iter: 739, running avg mse: 0.3213 lowest val mse: 0.3178 at k 3\n",
      "Iter: 740, running avg mse: 0.3219 lowest val mse: 0.3194 at k 3\n",
      "Iter: 741, running avg mse: 0.3260 lowest val mse: 0.3189 at k 3\n",
      "Iter: 742, running avg mse: 0.3329 lowest val mse: 0.3196 at k 3\n",
      "Iter: 743, running avg mse: 0.3306 lowest val mse: 0.3206 at k 3\n",
      "Iter: 744, running avg mse: 0.3254 lowest val mse: 0.3192 at k 3\n",
      "Iter: 745, running avg mse: 0.3278 lowest val mse: 0.3193 at k 3\n",
      "Iter: 746, running avg mse: 0.3304 lowest val mse: 0.3190 at k 3\n",
      "Iter: 747, running avg mse: 0.3253 lowest val mse: 0.3189 at k 3\n",
      "Iter: 748, running avg mse: 0.3273 lowest val mse: 0.3184 at k 3\n",
      "Iter: 749, running avg mse: 0.3281 lowest val mse: 0.3189 at k 3\n",
      "Iter: 750, running avg mse: 0.3280 lowest val mse: 0.3183 at k 3\n",
      "Iter: 751, running avg mse: 0.3270 lowest val mse: 0.3186 at k 3\n",
      "Iter: 752, running avg mse: 0.3162 lowest val mse: 0.3180 at k 3\n",
      "Iter: 753, running avg mse: 0.3297 lowest val mse: 0.3175 at k 3\n",
      "Iter: 754, running avg mse: 0.3295 lowest val mse: 0.3178 at k 3\n",
      "Iter: 755, running avg mse: 0.3233 lowest val mse: 0.3194 at k 3\n",
      "Iter: 756, running avg mse: 0.3290 lowest val mse: 0.3173 at k 3\n",
      "Iter: 757, running avg mse: 0.3283 lowest val mse: 0.3175 at k 3\n",
      "Iter: 758, running avg mse: 0.3350 lowest val mse: 0.3179 at k 3\n",
      "Iter: 759, running avg mse: 0.3198 lowest val mse: 0.3181 at k 3\n",
      "Iter: 760, running avg mse: 0.3299 lowest val mse: 0.3199 at k 3\n",
      "Iter: 761, running avg mse: 0.3369 lowest val mse: 0.3318 at k 4\n",
      "Iter: 762, running avg mse: 0.3419 lowest val mse: 0.3213 at k 3\n",
      "Iter: 763, running avg mse: 0.3339 lowest val mse: 0.3297 at k 3\n",
      "Iter: 764, running avg mse: 0.3307 lowest val mse: 0.3221 at k 3\n",
      "Iter: 765, running avg mse: 0.3370 lowest val mse: 0.3297 at k 3\n",
      "Iter: 766, running avg mse: 0.3425 lowest val mse: 0.3292 at k 3\n",
      "Iter: 767, running avg mse: 0.3426 lowest val mse: 0.3265 at k 3\n",
      "Iter: 768, running avg mse: 0.3400 lowest val mse: 0.3256 at k 3\n",
      "Iter: 769, running avg mse: 0.3407 lowest val mse: 0.3246 at k 3\n",
      "Iter: 770, running avg mse: 0.3296 lowest val mse: 0.3267 at k 3\n",
      "Iter: 771, running avg mse: 0.3353 lowest val mse: 0.3220 at k 3\n",
      "Iter: 772, running avg mse: 0.3361 lowest val mse: 0.3274 at k 3\n",
      "Iter: 773, running avg mse: 0.3340 lowest val mse: 0.3245 at k 3\n",
      "Iter: 774, running avg mse: 0.3338 lowest val mse: 0.3237 at k 3\n",
      "Iter: 775, running avg mse: 0.3314 lowest val mse: 0.3247 at k 3\n",
      "Iter: 776, running avg mse: 0.3369 lowest val mse: 0.3270 at k 3\n",
      "Iter: 777, running avg mse: 0.3468 lowest val mse: 0.3275 at k 3\n",
      "Iter: 778, running avg mse: 0.3475 lowest val mse: 0.3298 at k 4\n",
      "Iter: 779, running avg mse: 0.3521 lowest val mse: 0.3357 at k 4\n",
      "Iter: 780, running avg mse: 0.3466 lowest val mse: 0.3279 at k 4\n",
      "Iter: 781, running avg mse: 0.3540 lowest val mse: 0.3318 at k 4\n",
      "Iter: 782, running avg mse: 0.3398 lowest val mse: 0.3267 at k 3\n",
      "Iter: 783, running avg mse: 0.3391 lowest val mse: 0.3232 at k 3\n",
      "Iter: 784, running avg mse: 0.3326 lowest val mse: 0.3232 at k 3\n",
      "Iter: 785, running avg mse: 0.3320 lowest val mse: 0.3216 at k 3\n",
      "Iter: 786, running avg mse: 0.3289 lowest val mse: 0.3187 at k 3\n",
      "Iter: 787, running avg mse: 0.3338 lowest val mse: 0.3179 at k 3\n",
      "Iter: 788, running avg mse: 0.3356 lowest val mse: 0.3167 at k 3\n",
      "Iter: 789, running avg mse: 0.3354 lowest val mse: 0.3166 at k 3\n",
      "Iter: 790, running avg mse: 0.3286 lowest val mse: 0.3175 at k 3\n",
      "Iter: 791, running avg mse: 0.3308 lowest val mse: 0.3173 at k 3\n",
      "Iter: 792, running avg mse: 0.3269 lowest val mse: 0.3174 at k 3\n",
      "Iter: 793, running avg mse: 0.3220 lowest val mse: 0.3169 at k 3\n",
      "Iter: 794, running avg mse: 0.3291 lowest val mse: 0.3165 at k 3\n",
      "Iter: 795, running avg mse: 0.3223 lowest val mse: 0.3167 at k 3\n",
      "Iter: 796, running avg mse: 0.3332 lowest val mse: 0.3162 at k 3\n",
      "Iter: 797, running avg mse: 0.3298 lowest val mse: 0.3162 at k 3\n",
      "Iter: 798, running avg mse: 0.3259 lowest val mse: 0.3160 at k 3\n",
      "Iter: 799, running avg mse: 0.3223 lowest val mse: 0.3158 at k 3\n",
      "Iter: 800, running avg mse: 0.3168 lowest val mse: 0.3160 at k 3\n",
      "Iter: 801, running avg mse: 0.3245 lowest val mse: 0.3157 at k 3\n",
      "Iter: 802, running avg mse: 0.3257 lowest val mse: 0.3153 at k 3\n",
      "Iter: 803, running avg mse: 0.3242 lowest val mse: 0.3156 at k 3\n",
      "Iter: 804, running avg mse: 0.3235 lowest val mse: 0.3151 at k 3\n",
      "Iter: 805, running avg mse: 0.3258 lowest val mse: 0.3153 at k 3\n",
      "Iter: 806, running avg mse: 0.3217 lowest val mse: 0.3156 at k 3\n",
      "Iter: 807, running avg mse: 0.3326 lowest val mse: 0.3157 at k 3\n",
      "Iter: 808, running avg mse: 0.3262 lowest val mse: 0.3164 at k 3\n",
      "Iter: 809, running avg mse: 0.3285 lowest val mse: 0.3161 at k 3\n",
      "Iter: 810, running avg mse: 0.3296 lowest val mse: 0.3156 at k 3\n",
      "Iter: 811, running avg mse: 0.3245 lowest val mse: 0.3154 at k 3\n",
      "Iter: 812, running avg mse: 0.3250 lowest val mse: 0.3152 at k 3\n",
      "Iter: 813, running avg mse: 0.3283 lowest val mse: 0.3160 at k 3\n",
      "Iter: 814, running avg mse: 0.3205 lowest val mse: 0.3161 at k 3\n",
      "Iter: 815, running avg mse: 0.3322 lowest val mse: 0.3172 at k 3\n",
      "Iter: 816, running avg mse: 0.3185 lowest val mse: 0.3165 at k 3\n",
      "Iter: 817, running avg mse: 0.3218 lowest val mse: 0.3163 at k 3\n",
      "Iter: 818, running avg mse: 0.3230 lowest val mse: 0.3178 at k 3\n",
      "Iter: 819, running avg mse: 0.3214 lowest val mse: 0.3165 at k 3\n",
      "Iter: 820, running avg mse: 0.3231 lowest val mse: 0.3165 at k 3\n",
      "Iter: 821, running avg mse: 0.3314 lowest val mse: 0.3174 at k 3\n",
      "Iter: 822, running avg mse: 0.3184 lowest val mse: 0.3160 at k 3\n",
      "Iter: 823, running avg mse: 0.3292 lowest val mse: 0.3229 at k 3\n",
      "Iter: 824, running avg mse: 0.3259 lowest val mse: 0.3168 at k 3\n",
      "Iter: 825, running avg mse: 0.3292 lowest val mse: 0.3214 at k 3\n",
      "Iter: 826, running avg mse: 0.3289 lowest val mse: 0.3199 at k 3\n",
      "Iter: 827, running avg mse: 0.3243 lowest val mse: 0.3187 at k 3\n",
      "Iter: 828, running avg mse: 0.3271 lowest val mse: 0.3178 at k 3\n",
      "Iter: 829, running avg mse: 0.3249 lowest val mse: 0.3167 at k 3\n",
      "Iter: 830, running avg mse: 0.3218 lowest val mse: 0.3154 at k 3\n",
      "Iter: 831, running avg mse: 0.3255 lowest val mse: 0.3161 at k 3\n",
      "Iter: 832, running avg mse: 0.3184 lowest val mse: 0.3156 at k 3\n",
      "Iter: 833, running avg mse: 0.3250 lowest val mse: 0.3161 at k 3\n",
      "Iter: 834, running avg mse: 0.3266 lowest val mse: 0.3152 at k 3\n",
      "Iter: 835, running avg mse: 0.3236 lowest val mse: 0.3165 at k 3\n",
      "Iter: 836, running avg mse: 0.3241 lowest val mse: 0.3150 at k 3\n",
      "Iter: 837, running avg mse: 0.3204 lowest val mse: 0.3153 at k 3\n",
      "Iter: 838, running avg mse: 0.3251 lowest val mse: 0.3151 at k 3\n",
      "Iter: 839, running avg mse: 0.3225 lowest val mse: 0.3149 at k 3\n",
      "Iter: 840, running avg mse: 0.3217 lowest val mse: 0.3151 at k 3\n",
      "Iter: 841, running avg mse: 0.3249 lowest val mse: 0.3159 at k 3\n",
      "Iter: 842, running avg mse: 0.3236 lowest val mse: 0.3153 at k 3\n",
      "Iter: 843, running avg mse: 0.3254 lowest val mse: 0.3175 at k 3\n",
      "Iter: 844, running avg mse: 0.3278 lowest val mse: 0.3165 at k 3\n",
      "Iter: 845, running avg mse: 0.3290 lowest val mse: 0.3171 at k 3\n",
      "Iter: 846, running avg mse: 0.3234 lowest val mse: 0.3163 at k 3\n",
      "Iter: 847, running avg mse: 0.3251 lowest val mse: 0.3179 at k 3\n",
      "Iter: 848, running avg mse: 0.3278 lowest val mse: 0.3172 at k 3\n",
      "Iter: 849, running avg mse: 0.3283 lowest val mse: 0.3177 at k 3\n",
      "Iter: 850, running avg mse: 0.3214 lowest val mse: 0.3163 at k 3\n",
      "Iter: 851, running avg mse: 0.3307 lowest val mse: 0.3168 at k 3\n",
      "Iter: 852, running avg mse: 0.3252 lowest val mse: 0.3190 at k 3\n",
      "Iter: 853, running avg mse: 0.3212 lowest val mse: 0.3183 at k 3\n",
      "Iter: 854, running avg mse: 0.3269 lowest val mse: 0.3163 at k 3\n",
      "Iter: 855, running avg mse: 0.3235 lowest val mse: 0.3158 at k 3\n",
      "Iter: 856, running avg mse: 0.3214 lowest val mse: 0.3155 at k 3\n",
      "Iter: 857, running avg mse: 0.3293 lowest val mse: 0.3151 at k 3\n",
      "Iter: 858, running avg mse: 0.3253 lowest val mse: 0.3160 at k 3\n",
      "Iter: 859, running avg mse: 0.3327 lowest val mse: 0.3178 at k 3\n",
      "Iter: 860, running avg mse: 0.3265 lowest val mse: 0.3200 at k 3\n",
      "Iter: 861, running avg mse: 0.3263 lowest val mse: 0.3165 at k 3\n",
      "Iter: 862, running avg mse: 0.3298 lowest val mse: 0.3187 at k 3\n",
      "Iter: 863, running avg mse: 0.3235 lowest val mse: 0.3154 at k 3\n",
      "Iter: 864, running avg mse: 0.3261 lowest val mse: 0.3161 at k 3\n",
      "Iter: 865, running avg mse: 0.3202 lowest val mse: 0.3174 at k 3\n",
      "Iter: 866, running avg mse: 0.3283 lowest val mse: 0.3189 at k 3\n",
      "Iter: 867, running avg mse: 0.3282 lowest val mse: 0.3174 at k 3\n",
      "Iter: 868, running avg mse: 0.3286 lowest val mse: 0.3191 at k 3\n",
      "Iter: 869, running avg mse: 0.3283 lowest val mse: 0.3177 at k 3\n",
      "Iter: 870, running avg mse: 0.3204 lowest val mse: 0.3189 at k 3\n",
      "Iter: 871, running avg mse: 0.3278 lowest val mse: 0.3192 at k 3\n",
      "Iter: 872, running avg mse: 0.3313 lowest val mse: 0.3182 at k 3\n",
      "Iter: 873, running avg mse: 0.3186 lowest val mse: 0.3167 at k 3\n",
      "Iter: 874, running avg mse: 0.3233 lowest val mse: 0.3166 at k 3\n",
      "Iter: 875, running avg mse: 0.3317 lowest val mse: 0.3162 at k 3\n",
      "Iter: 876, running avg mse: 0.3260 lowest val mse: 0.3166 at k 3\n",
      "Iter: 877, running avg mse: 0.3219 lowest val mse: 0.3156 at k 3\n",
      "Iter: 878, running avg mse: 0.3222 lowest val mse: 0.3156 at k 3\n",
      "Iter: 879, running avg mse: 0.3212 lowest val mse: 0.3164 at k 3\n",
      "Iter: 880, running avg mse: 0.3256 lowest val mse: 0.3159 at k 3\n",
      "Iter: 881, running avg mse: 0.3228 lowest val mse: 0.3163 at k 3\n",
      "Iter: 882, running avg mse: 0.3231 lowest val mse: 0.3149 at k 3\n",
      "Iter: 883, running avg mse: 0.3194 lowest val mse: 0.3153 at k 3\n",
      "Iter: 884, running avg mse: 0.3246 lowest val mse: 0.3169 at k 3\n",
      "Iter: 885, running avg mse: 0.3206 lowest val mse: 0.3168 at k 3\n",
      "Iter: 886, running avg mse: 0.3225 lowest val mse: 0.3159 at k 3\n",
      "Iter: 887, running avg mse: 0.3248 lowest val mse: 0.3169 at k 3\n",
      "Iter: 888, running avg mse: 0.3177 lowest val mse: 0.3162 at k 3\n",
      "Iter: 889, running avg mse: 0.3250 lowest val mse: 0.3168 at k 3\n",
      "Iter: 890, running avg mse: 0.3268 lowest val mse: 0.3162 at k 3\n",
      "Iter: 891, running avg mse: 0.3275 lowest val mse: 0.3166 at k 3\n",
      "Iter: 892, running avg mse: 0.3274 lowest val mse: 0.3165 at k 3\n",
      "Iter: 893, running avg mse: 0.3222 lowest val mse: 0.3162 at k 3\n",
      "Iter: 894, running avg mse: 0.3236 lowest val mse: 0.3175 at k 3\n",
      "Iter: 895, running avg mse: 0.3253 lowest val mse: 0.3163 at k 3\n",
      "Iter: 896, running avg mse: 0.3282 lowest val mse: 0.3159 at k 3\n",
      "Iter: 897, running avg mse: 0.3287 lowest val mse: 0.3174 at k 3\n",
      "Iter: 898, running avg mse: 0.3285 lowest val mse: 0.3166 at k 3\n",
      "Iter: 899, running avg mse: 0.3202 lowest val mse: 0.3164 at k 3\n",
      "Iter: 900, running avg mse: 0.3189 lowest val mse: 0.3169 at k 3\n",
      "Iter: 901, running avg mse: 0.3215 lowest val mse: 0.3166 at k 3\n",
      "Iter: 902, running avg mse: 0.3250 lowest val mse: 0.3172 at k 3\n",
      "Iter: 903, running avg mse: 0.3232 lowest val mse: 0.3206 at k 3\n",
      "Iter: 904, running avg mse: 0.3260 lowest val mse: 0.3191 at k 3\n",
      "Iter: 905, running avg mse: 0.3263 lowest val mse: 0.3173 at k 3\n",
      "Iter: 906, running avg mse: 0.3170 lowest val mse: 0.3172 at k 3\n",
      "Iter: 907, running avg mse: 0.3178 lowest val mse: 0.3148 at k 3\n",
      "Iter: 908, running avg mse: 0.3249 lowest val mse: 0.3162 at k 3\n",
      "Iter: 909, running avg mse: 0.3239 lowest val mse: 0.3162 at k 3\n",
      "Iter: 910, running avg mse: 0.3258 lowest val mse: 0.3171 at k 3\n",
      "Iter: 911, running avg mse: 0.3173 lowest val mse: 0.3158 at k 3\n",
      "Iter: 912, running avg mse: 0.3275 lowest val mse: 0.3183 at k 3\n",
      "Iter: 913, running avg mse: 0.3168 lowest val mse: 0.3154 at k 3\n",
      "Iter: 914, running avg mse: 0.3278 lowest val mse: 0.3167 at k 3\n",
      "Iter: 915, running avg mse: 0.3209 lowest val mse: 0.3184 at k 3\n",
      "Iter: 916, running avg mse: 0.3292 lowest val mse: 0.3180 at k 3\n",
      "Iter: 917, running avg mse: 0.3264 lowest val mse: 0.3180 at k 3\n",
      "Iter: 918, running avg mse: 0.3229 lowest val mse: 0.3193 at k 3\n",
      "Iter: 919, running avg mse: 0.3188 lowest val mse: 0.3157 at k 3\n",
      "Iter: 920, running avg mse: 0.3255 lowest val mse: 0.3165 at k 3\n",
      "Iter: 921, running avg mse: 0.3230 lowest val mse: 0.3168 at k 3\n",
      "Iter: 922, running avg mse: 0.3160 lowest val mse: 0.3164 at k 3\n",
      "Iter: 923, running avg mse: 0.3235 lowest val mse: 0.3173 at k 3\n",
      "Iter: 924, running avg mse: 0.3183 lowest val mse: 0.3161 at k 3\n",
      "Iter: 925, running avg mse: 0.3230 lowest val mse: 0.3166 at k 3\n",
      "Iter: 926, running avg mse: 0.3235 lowest val mse: 0.3171 at k 3\n",
      "Iter: 927, running avg mse: 0.3241 lowest val mse: 0.3170 at k 3\n",
      "Iter: 928, running avg mse: 0.3250 lowest val mse: 0.3166 at k 3\n",
      "Iter: 929, running avg mse: 0.3193 lowest val mse: 0.3157 at k 3\n",
      "Iter: 930, running avg mse: 0.3183 lowest val mse: 0.3160 at k 3\n",
      "Iter: 931, running avg mse: 0.3278 lowest val mse: 0.3154 at k 3\n",
      "Iter: 932, running avg mse: 0.3243 lowest val mse: 0.3163 at k 3\n",
      "Iter: 933, running avg mse: 0.3216 lowest val mse: 0.3161 at k 3\n",
      "Iter: 934, running avg mse: 0.3204 lowest val mse: 0.3155 at k 3\n",
      "Iter: 935, running avg mse: 0.3227 lowest val mse: 0.3176 at k 3\n",
      "Iter: 936, running avg mse: 0.3342 lowest val mse: 0.3258 at k 4\n",
      "Iter: 937, running avg mse: 0.3295 lowest val mse: 0.3171 at k 3\n",
      "Iter: 938, running avg mse: 0.3277 lowest val mse: 0.3175 at k 3\n",
      "Iter: 939, running avg mse: 0.3244 lowest val mse: 0.3196 at k 3\n",
      "Iter: 940, running avg mse: 0.3210 lowest val mse: 0.3174 at k 3\n",
      "Iter: 941, running avg mse: 0.3291 lowest val mse: 0.3172 at k 3\n",
      "Iter: 942, running avg mse: 0.3222 lowest val mse: 0.3187 at k 3\n",
      "Iter: 943, running avg mse: 0.3214 lowest val mse: 0.3172 at k 3\n",
      "Iter: 944, running avg mse: 0.3184 lowest val mse: 0.3181 at k 3\n",
      "Iter: 945, running avg mse: 0.3194 lowest val mse: 0.3165 at k 3\n",
      "Iter: 946, running avg mse: 0.3265 lowest val mse: 0.3151 at k 3\n",
      "Iter: 947, running avg mse: 0.3251 lowest val mse: 0.3165 at k 3\n",
      "Iter: 948, running avg mse: 0.3224 lowest val mse: 0.3191 at k 3\n",
      "Iter: 949, running avg mse: 0.3298 lowest val mse: 0.3175 at k 3\n",
      "Iter: 950, running avg mse: 0.3244 lowest val mse: 0.3185 at k 3\n",
      "Iter: 951, running avg mse: 0.3243 lowest val mse: 0.3170 at k 3\n",
      "Iter: 952, running avg mse: 0.3239 lowest val mse: 0.3159 at k 3\n",
      "Iter: 953, running avg mse: 0.3239 lowest val mse: 0.3188 at k 3\n",
      "Iter: 954, running avg mse: 0.3267 lowest val mse: 0.3169 at k 3\n",
      "Iter: 955, running avg mse: 0.3252 lowest val mse: 0.3189 at k 3\n",
      "Iter: 956, running avg mse: 0.3330 lowest val mse: 0.3200 at k 3\n",
      "Iter: 957, running avg mse: 0.3246 lowest val mse: 0.3161 at k 3\n",
      "Iter: 958, running avg mse: 0.3267 lowest val mse: 0.3162 at k 3\n",
      "Iter: 959, running avg mse: 0.3224 lowest val mse: 0.3161 at k 3\n",
      "Iter: 960, running avg mse: 0.3271 lowest val mse: 0.3164 at k 3\n",
      "Iter: 961, running avg mse: 0.3222 lowest val mse: 0.3169 at k 3\n",
      "Iter: 962, running avg mse: 0.3204 lowest val mse: 0.3165 at k 3\n",
      "Iter: 963, running avg mse: 0.3232 lowest val mse: 0.3160 at k 3\n",
      "Iter: 964, running avg mse: 0.3221 lowest val mse: 0.3163 at k 3\n",
      "Iter: 965, running avg mse: 0.3204 lowest val mse: 0.3170 at k 3\n",
      "Iter: 966, running avg mse: 0.3092 lowest val mse: 0.3175 at k 3\n",
      "Iter: 967, running avg mse: 0.3152 lowest val mse: 0.3166 at k 3\n",
      "Iter: 968, running avg mse: 0.3231 lowest val mse: 0.3165 at k 3\n",
      "Iter: 969, running avg mse: 0.3171 lowest val mse: 0.3157 at k 3\n",
      "Iter: 970, running avg mse: 0.3178 lowest val mse: 0.3155 at k 3\n",
      "Iter: 971, running avg mse: 0.3312 lowest val mse: 0.3176 at k 3\n",
      "Iter: 972, running avg mse: 0.3255 lowest val mse: 0.3166 at k 3\n",
      "Iter: 973, running avg mse: 0.3255 lowest val mse: 0.3160 at k 3\n",
      "Iter: 974, running avg mse: 0.3208 lowest val mse: 0.3188 at k 3\n",
      "Iter: 975, running avg mse: 0.3219 lowest val mse: 0.3192 at k 3\n",
      "Iter: 976, running avg mse: 0.3181 lowest val mse: 0.3170 at k 3\n",
      "Iter: 977, running avg mse: 0.3209 lowest val mse: 0.3170 at k 3\n",
      "Iter: 978, running avg mse: 0.3178 lowest val mse: 0.3163 at k 3\n",
      "Iter: 979, running avg mse: 0.3238 lowest val mse: 0.3168 at k 3\n",
      "Iter: 980, running avg mse: 0.3196 lowest val mse: 0.3164 at k 3\n",
      "Iter: 981, running avg mse: 0.3224 lowest val mse: 0.3178 at k 3\n",
      "Iter: 982, running avg mse: 0.3214 lowest val mse: 0.3168 at k 3\n",
      "Iter: 983, running avg mse: 0.3256 lowest val mse: 0.3163 at k 3\n",
      "Iter: 984, running avg mse: 0.3184 lowest val mse: 0.3169 at k 3\n",
      "Iter: 985, running avg mse: 0.3164 lowest val mse: 0.3159 at k 3\n",
      "Iter: 986, running avg mse: 0.3157 lowest val mse: 0.3159 at k 3\n",
      "Iter: 987, running avg mse: 0.3204 lowest val mse: 0.3155 at k 3\n",
      "Iter: 988, running avg mse: 0.3146 lowest val mse: 0.3160 at k 3\n",
      "Iter: 989, running avg mse: 0.3206 lowest val mse: 0.3154 at k 3\n",
      "Iter: 990, running avg mse: 0.3267 lowest val mse: 0.3155 at k 3\n",
      "Iter: 991, running avg mse: 0.3217 lowest val mse: 0.3156 at k 3\n",
      "Iter: 992, running avg mse: 0.3219 lowest val mse: 0.3159 at k 3\n",
      "Iter: 993, running avg mse: 0.3263 lowest val mse: 0.3167 at k 3\n",
      "Iter: 994, running avg mse: 0.3228 lowest val mse: 0.3171 at k 3\n",
      "Iter: 995, running avg mse: 0.3288 lowest val mse: 0.3173 at k 3\n",
      "Iter: 996, running avg mse: 0.3245 lowest val mse: 0.3163 at k 3\n",
      "Iter: 997, running avg mse: 0.3182 lowest val mse: 0.3164 at k 3\n",
      "Iter: 998, running avg mse: 0.3243 lowest val mse: 0.3189 at k 3\n",
      "Iter: 999, running avg mse: 0.3201 lowest val mse: 0.3182 at k 3\n",
      "Iter: 1000, running avg mse: 0.3245 lowest val mse: 0.3160 at k 3\n"
     ]
    }
   ],
   "source": [
    "for itr in range(1, nitrs + 1):\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        h = rec.initHidden().to(device)\n",
    "        c = rec.initHidden().to(device)\n",
    "        hn = h[0, :, :]\n",
    "        cn = c[0, :, :]\n",
    "        for t in reversed(range(data.size(1))):\n",
    "            obs = data[:, t, :]\n",
    "            out, hn, cn = rec.forward(obs, hn, cn)\n",
    "        qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "        epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean   \n",
    "        \n",
    "        # forward in time and solve ode for reconstructions\n",
    "        pred_z = odeint(func, z0, samp_ts).permute(1, 0, 2)\n",
    "        pred_x = dec(pred_z)\n",
    "\n",
    "        # compute loss\n",
    "        loss = MSELoss(pred_x, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            h = torch.zeros(1, batch, rnn_nhidden).to(device)\n",
    "            c = torch.zeros(1, batch, rnn_nhidden).to(device)\n",
    "            hn = h[0, :, :]\n",
    "            cn = c[0, :, :]\n",
    "            \n",
    "            for t in reversed(range(data.size(1))):\n",
    "                obs = data[:, t, :]\n",
    "                out, hn, cn = rec.forward(obs, hn, cn)\n",
    "            qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "            epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "            z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "            #forward in time and solve ode for reconstructions\n",
    "            pred_z = odeint(func, z0, samp_ts).permute(1, 0, 2)\n",
    "            pred_x = dec(pred_z)\n",
    "        \n",
    "            #val_loss = MSELoss(pred_x, samp_trajs_val_TE) + torch.mean(-0.5 * torch.sum(1 + qz0_logvar - qz0_mean**2 - torch.exp(qz0_logvar), dim = -1)/(31*(k+1)+2))\n",
    "            val_loss = MSELoss(pred_x[:,:,::(k+1)], data[:,:,::(k+1)])\n",
    "            val_loss_k1 = MSELoss(pred_x[:,:,1::(k+1)], data[:,:,1::(k+1)])\n",
    "            val_loss_k2 = MSELoss(pred_x[:,:,2::(k+1)], data[:,:,2::(k+1)])\n",
    "            val_loss_k3 = MSELoss(pred_x[:,:,3::(k+1)], data[:,:,3::(k+1)])\n",
    "            val_loss_k4 = MSELoss(pred_x[:,:,4::(k+1)], data[:,:,4::(k+1)])\n",
    "            val_loss_k5 = MSELoss(pred_x[:,:,5::(k+1)], data[:,:,5::(k+1)])\n",
    "            val_loss_k6 = MSELoss(pred_x[:,:,6::(k+1)], data[:,:,6::(k+1)])\n",
    "\n",
    "            val_losses.append(val_loss)\n",
    "            val_losses_k1.append(val_loss_k1)\n",
    "            val_losses_k2.append(val_loss_k2)\n",
    "            val_losses_k3.append(val_loss_k3)\n",
    "            val_losses_k4.append(val_loss_k4)\n",
    "            val_losses_k5.append(val_loss_k5)\n",
    "            val_losses_k6.append(val_loss_k6)\n",
    "\n",
    "            V = [val_loss, val_loss_k1, val_loss_k2, val_loss_k3, val_loss_k4, val_loss_k5, val_loss_k6]\n",
    "            lowest_val_loss = torch.asarray(V).min(0)[0]\n",
    "            deriv_index = torch.asarray(V).min(0)[1]\n",
    "\n",
    "    if ((itr > 100) and (itr % 10 == 0)):\n",
    "        save_model(Training_Trial, rnn_nhidden, tau, k, learning_rate, latent_dim, itr)\n",
    "        tot_index = 40\n",
    "        times_index = 0\n",
    "        deriv_index = deriv_index.numpy()\n",
    "        \n",
    "        orig_trajs = orig_trajs_TE[:, 0:0+tot_num*tot_index, :]\n",
    "\n",
    "        pred_x, pred_z = data_for_plot_graph(tot_index)\n",
    "        pred_x = pred_x.reshape(trial_num, tot_num*tot_index, mesured_dim*(k+1))\n",
    "        pred_z = pred_z.reshape(trial_num, tot_num*tot_index, latent_dim)\n",
    "        pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "        pred_z_forgraph = pred_z.detach().cpu().numpy()\n",
    "\n",
    "        path = \"Results_pic/tau{}k{}/latent{}/data_loader_rnn2layer_lstm{}_lr{}_Trial{}/epoch{}\".format(tau, k, latent_dim, rnn_nhidden, learning_rate, Training_Trial, itr)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "           os.makedirs(path)\n",
    "\n",
    "        plotgraph_index = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "        gen_index = 40\n",
    "        \n",
    "        for i in range(len(plotgraph_index)):\n",
    "            plot_graph(gen_index, times_index, plotgraph_index[i], deriv_index, pred_x_forgraph, orig_trajs, itr, path)\n",
    "        \n",
    "    print('Iter: {}, running avg mse: {:.4f} lowest val mse: {:.4f} at k {}'.format(itr, loss, lowest_val_loss, deriv_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42e20865",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trial_tot_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec3a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(3, Trial_tot_num):\n",
    "    Training_Trial = p\n",
    "    \n",
    "    latent_dim = 8\n",
    "    nhidden = 64 ##Trial1 = 64, Trial2 = 128, Trial3 = 128, Trial4 = 64, Trial5 = 64\n",
    "    dec_nhidden = 32\n",
    "    obs_dim = 12*(k+1)\n",
    "    rnn_nhidden = 256\n",
    "    nitrs = 600\n",
    "    noise_std = 0.2\n",
    "    learning_rate = 0.008\n",
    "\n",
    "    func = LatentODEfunc(latent_dim, nhidden).to(device)\n",
    "    rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, batch).to(device)\n",
    "    dec = Decoder(latent_dim, obs_dim, dec_nhidden).to(device)\n",
    "    params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))\n",
    "    optimizer = optim.Adam(params, lr=learning_rate)\n",
    "    loss_meter = RunningAverageMeter()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_losses_k1 = []\n",
    "    val_losses_k2 = []\n",
    "    val_losses_k3 = []\n",
    "    val_losses_k4 = []\n",
    "    val_losses_k5 = []\n",
    "    val_losses_k6 = []\n",
    "    val_losses_k7 = []\n",
    "    val_losses_k8 = []\n",
    "    val_losses_k9 = []\n",
    "    torch.cuda.empty_cache()\n",
    "    for itr in range(1, nitrs + 1):\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            h = rec.initHidden().to(device)\n",
    "            c = rec.initHidden().to(device)\n",
    "            hn = h[0, :, :]\n",
    "            cn = c[0, :, :]\n",
    "            for t in reversed(range(data.size(1))):\n",
    "                obs = data[:, t, :]\n",
    "                out, hn, cn = rec.forward(obs, hn, cn)\n",
    "            qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "            epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "            z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean   \n",
    "\n",
    "            # forward in time and solve ode for reconstructions\n",
    "            pred_z = odeint(func, z0, samp_ts).permute(1, 0, 2)\n",
    "            pred_x = dec(pred_z)\n",
    "\n",
    "            # compute loss\n",
    "            loss = MSELoss(pred_x, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                h = torch.zeros(1, batch, rnn_nhidden).to(device)\n",
    "                c = torch.zeros(1, batch, rnn_nhidden).to(device)\n",
    "                hn = h[0, :, :]\n",
    "                cn = c[0, :, :]\n",
    "\n",
    "                for t in reversed(range(data.size(1))):\n",
    "                    obs = data[:, t, :]\n",
    "                    out, hn, cn = rec.forward(obs, hn, cn)\n",
    "                qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "                epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "                z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "                #forward in time and solve ode for reconstructions\n",
    "                pred_z = odeint(func, z0, samp_ts).permute(1, 0, 2)\n",
    "                pred_x = dec(pred_z)\n",
    "\n",
    "                #val_loss = MSELoss(pred_x, samp_trajs_val_TE) + torch.mean(-0.5 * torch.sum(1 + qz0_logvar - qz0_mean**2 - torch.exp(qz0_logvar), dim = -1)/(31*(k+1)+2))\n",
    "                val_loss = MSELoss(pred_x[:,:,::(k+1)], data[:,:,::(k+1)])\n",
    "                val_loss_k1 = MSELoss(pred_x[:,:,1::(k+1)], data[:,:,1::(k+1)])\n",
    "                val_loss_k2 = MSELoss(pred_x[:,:,2::(k+1)], data[:,:,2::(k+1)])\n",
    "                val_loss_k3 = MSELoss(pred_x[:,:,3::(k+1)], data[:,:,3::(k+1)])\n",
    "                val_loss_k4 = MSELoss(pred_x[:,:,4::(k+1)], data[:,:,4::(k+1)])\n",
    "                val_loss_k5 = MSELoss(pred_x[:,:,5::(k+1)], data[:,:,5::(k+1)])\n",
    "                val_loss_k6 = MSELoss(pred_x[:,:,6::(k+1)], data[:,:,6::(k+1)])\n",
    "\n",
    "                val_losses.append(val_loss)\n",
    "                val_losses_k1.append(val_loss_k1)\n",
    "                val_losses_k2.append(val_loss_k2)\n",
    "                val_losses_k3.append(val_loss_k3)\n",
    "                val_losses_k4.append(val_loss_k4)\n",
    "                val_losses_k5.append(val_loss_k5)\n",
    "                val_losses_k6.append(val_loss_k6)\n",
    "\n",
    "                V = [val_loss, val_loss_k1, val_loss_k2, val_loss_k3, val_loss_k4, val_loss_k5, val_loss_k6]\n",
    "                lowest_val_loss = torch.asarray(V).min(0)[0]\n",
    "                deriv_index = torch.asarray(V).min(0)[1]\n",
    "\n",
    "        if ((itr > 100) and (itr % 10 == 0)):\n",
    "            save_model(Training_Trial, rnn_nhidden, tau, k, learning_rate, latent_dim, itr)\n",
    "            tot_index = 40\n",
    "            times_index = 0\n",
    "            deriv_index = deriv_index.numpy()\n",
    "\n",
    "            orig_trajs = orig_trajs_TE[:, 0:0+tot_num*tot_index, :]\n",
    "\n",
    "            pred_x, pred_z = data_for_plot_graph(tot_index)\n",
    "            pred_x = pred_x.reshape(trial_num, tot_num*tot_index, mesured_dim*(k+1))\n",
    "            pred_z = pred_z.reshape(trial_num, tot_num*tot_index, latent_dim)\n",
    "            pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "            pred_z_forgraph = pred_z.detach().cpu().numpy()\n",
    "\n",
    "            path = \"Results_pic/tau{}k{}/latent{}/data_loader_rnn2layer_lstm{}_lr{}_Trial{}/epoch{}\".format(tau, k, latent_dim, rnn_nhidden, learning_rate, Training_Trial, itr)\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "               os.makedirs(path)\n",
    "\n",
    "            plotgraph_index = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "            gen_index = 40\n",
    "\n",
    "            for i in range(len(plotgraph_index)):\n",
    "                plot_graph(gen_index, times_index, plotgraph_index[i], deriv_index, pred_x_forgraph, orig_trajs, itr, path)\n",
    "\n",
    "        print('Iter: {}, running avg mse: {:.4f} lowest val mse: {:.4f} at k {}'.format(itr, loss, lowest_val_loss, deriv_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b8567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5a73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7b132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336c54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441306ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da73157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa25a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba681c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c83c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(plotgraph_index)):\n",
    "    plot_graph(gen_index, times_index, plotgraph_index[i], deriv_index, pred_x_forgraph, orig_trajs, itr, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd672ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_trajs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752960c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.array(train_losses)\n",
    "\n",
    "plt.plot(train_loss, 'r')\n",
    "plt.savefig('C:/Users/shiny/Documents/NeuralODE_RatTreadMill/Results_pic/TrainingLossGraph/tau6k3/trainloss_0.005_nonoise_latent8_lstm256.png')\n",
    "np.save('C:/Users/shiny/Documents/NeuralODE_RatTreadMill/Results_pic/TrainingLossGraph/tau6k3/trainloss_0.005_nonoise_latent8_lstm256.npy', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'runs/model_'\n",
    "\n",
    "def save_model():\n",
    "    folder = 'runs/model'\n",
    "    folder = os.path.join(folder, 'ckpt')\n",
    "\n",
    "    ckpt_path = os.path.join(folder, f'ODE_normalized_4_128_2tanh.pth')\n",
    "\n",
    "    save_dict = {\n",
    "        'model_args': get_args(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'data': data_get_dict(),\n",
    "        'train_loss': get_losses()\n",
    "    }\n",
    "    \n",
    "    save_dict.update(get_state_dicts())\n",
    "    \n",
    "    torch.save(save_dict, 'C:/Users/shiny/Documents/NeuralODE_RatTreadMill/model/All_rodent_ODE_TakenEmbedding_tau6k3_LSTM_lr0.008_latent8_LSTMautoencoder_epoch500.pth')\n",
    "\n",
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85463199",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model/All_rodent_ODE_TakenEmbedding_tau6k3_LSTM_lr0.008_latent8_LSTMautoencoder_epoch380.pth')\n",
    "rec.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "func.load_state_dict(checkpoint['odefunc_state_dict'])\n",
    "dec.load_state_dict(checkpoint['decoder_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218c9c1",
   "metadata": {},
   "source": [
    "## Long time series generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4314436",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_index = 20\n",
    "times_index = 0\n",
    "deriv_index = 0\n",
    "itr= 380\n",
    "orig_trajs_TE = np.load('orig_trajs_TE_tau6k3.npy')\n",
    "orig_trajs_TE = orig_trajs_TE.reshape(203, 200*34, 31*(k+1)+2)\n",
    "samp_trajs_TE_test = orig_trajs_TE[:, :50, :]\n",
    "\n",
    "samp_trajs_TE_test = torch.from_numpy(samp_trajs_TE_test).float().to(device).reshape(203, 50, 31*(k+1)+2)\n",
    "orig_trajs = orig_trajs_TE[:, 0:0+50*gen_index, :]\n",
    "\n",
    "pred_x = data_for_plot_graph(gen_index)\n",
    "\n",
    "path = \"Results_pic/tau6k3/longtimeseries/epoch{}\".format(itr)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "   os.makedirs(path)\n",
    "\n",
    "plot_graph(gen_index, times_index, 0, deriv_index, pred_x, orig_trajs, itr, path)\n",
    "plot_graph(gen_index, times_index, 4, deriv_index, pred_x, orig_trajs, itr, path)\n",
    "plot_graph(gen_index, times_index, 20, deriv_index, pred_x, orig_trajs, itr, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debce494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ec85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # sample from trajectorys' approx. posterior\n",
    "\n",
    "    ts_pos = np.linspace(0, 0.25*gen_index, num=50*gen_index)\n",
    "    ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "    \n",
    "    h = torch.zeros(1, samp_trajs_TE.shape[0], rnn_nhidden).to(device)\n",
    "    c = torch.zeros(1, samp_trajs_TE.shape[0], rnn_nhidden).to(device)\n",
    "    \n",
    "    hn = h[0, :, :]\n",
    "    cn = c[0, :, :]\n",
    "    \n",
    "    for t in reversed(range(samp_trajs_TE.size(1))):\n",
    "        obs = samp_trajs_TE[:, t, :]\n",
    "        out, hn, cn = rec.forward(obs, hn, cn)\n",
    "    qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "    epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "    # forward in time and solve ode for reconstructions\n",
    "    pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2) #change time and batch with permute\n",
    "    pred_x = dec(pred_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    samp_ts_forgraph = samp_ts.detach().cpu().numpy()\n",
    "    pred_x = pred_x.reshape(203, 50*gen_index, 28*(k+1)+2)\n",
    "    pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "    orig_trajs_forgraph = orig_trajs\n",
    "    ts_pos_forgraph = ts_pos.detach().cpu().numpy()\n",
    "    ts_pos_combined = np.linspace(0, 0.25*gen_index, num=50*gen_index) \n",
    "    \n",
    "    times_index = 0\n",
    "    dataset_value = 0\n",
    "    deriv_index = 0\n",
    "    fig, axes = plt.subplots(nrows=6, ncols=5, figsize=(15, 9))\n",
    "    axes = axes.flatten()\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.scatter(ts_pos_combined[times_index:50*gen_index], orig_trajs_forgraph[dataset_value,0:50*gen_index, i], label='sampled data', s = 5)\n",
    "        ax.plot(ts_pos_combined[times_index:+50*gen_index], pred_x_forgraph[dataset_value, times_index:+50*gen_index, i*(k+1)+deriv_index], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('./Results_pic/tau6k3/longtimeseries/lstm_Tied_latent8_gen10_deriv0_50.png', dpi=500)\n",
    "    #plt.savefig('./minibatchfps200_take300_predict900_positionalvalue3.png', dpi=500)\n",
    "    print('Saved visualization figure at {}'.format('./test.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd946b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    samp_ts_forgraph = samp_ts.detach().cpu().numpy()\n",
    "    pred_x = pred_x.reshape(203, 50*gen_index, 28*(k+1)+2)\n",
    "    pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "    orig_trajs_forgraph = orig_trajs\n",
    "    ts_pos_forgraph = ts_pos.detach().cpu().numpy()\n",
    "    ts_pos_combined = np.linspace(0, 0.25*gen_index, num=50*gen_index) \n",
    "    \n",
    "    times_index = 0\n",
    "    dataset_value = 4\n",
    "    deriv_index = 0\n",
    "    fig, axes = plt.subplots(nrows=6, ncols=5, figsize=(15, 9))\n",
    "    axes = axes.flatten()\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.scatter(ts_pos_combined[times_index:50*gen_index], orig_trajs_forgraph[dataset_value,0:50*gen_index, i], label='sampled data', s = 5)\n",
    "        ax.plot(ts_pos_combined[times_index:+50*gen_index], pred_x_forgraph[dataset_value, times_index:+50*gen_index, i*(k+1)+deriv_index], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('./Results_pic/tau6k3/longtimeseries/lstm_split_latent8_gen10_deriv0_50.png', dpi=500)\n",
    "    #plt.savefig('./minibatchfps200_take300_predict900_positionalvalue3.png', dpi=500)\n",
    "    print('Saved visualization figure at {}'.format('./test.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    samp_ts_forgraph = samp_ts.detach().cpu().numpy()\n",
    "    pred_x = pred_x.reshape(203, 50*gen_index, 28*(k+1)+2)\n",
    "    pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "    orig_trajs_forgraph = orig_trajs\n",
    "    ts_pos_forgraph = ts_pos.detach().cpu().numpy()\n",
    "    ts_pos_combined = np.linspace(0, 0.25*gen_index, num=50*gen_index) \n",
    "    \n",
    "    times_index = 0\n",
    "    dataset_value = 20\n",
    "    deriv_index = 0\n",
    "    fig, axes = plt.subplots(nrows=6, ncols=5, figsize=(15, 9))\n",
    "    axes = axes.flatten()\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.scatter(ts_pos_combined[times_index:50*gen_index], orig_trajs_forgraph[dataset_value,0:50*gen_index, i], label='sampled data', s = 5)\n",
    "        ax.plot(ts_pos_combined[times_index:+50*gen_index], pred_x_forgraph[dataset_value, times_index:+50*gen_index, i*(k+1)+deriv_index], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('./Results_pic/tau6k3/longtimeseries/lstm_Tied_latent8_gen10_deriv0_50_wash.png', dpi=500)\n",
    "    #plt.savefig('./minibatchfps200_take300_predict900_positionalvalue3.png', dpi=500)\n",
    "    print('Saved visualization figure at {}'.format('./test.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9bd75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8362e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e11230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    samp_ts_forgraph = samp_ts.detach().cpu().numpy()\n",
    "    pred_x = pred_x.reshape(203, 50*gen_index, 31*(k+1)+2)\n",
    "    pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "    orig_trajs_forgraph = orig_trajs\n",
    "    ts_pos_forgraph = ts_pos.detach().cpu().numpy()\n",
    "    ts_pos_combined = np.linspace(0, 0.25*gen_index, num=2500) \n",
    "    \n",
    "    times_index = 0\n",
    "    positional_value = 0\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(15, 9))\n",
    "    axes = axes.flatten()\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.scatter(ts_pos_combined[0:50*gen_index], orig_trajs_forgraph[i,0:50*gen_index, positional_value], label='sampled data', s = 5)\n",
    "        ax.plot(ts_pos_combined[times_index:+50*gen_index], pred_x_forgraph[i, times_index:+50*gen_index, positional_value*(k+1)], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('./Results_pic/tau6k3/longtimeseries/Allrodent_Tau6k3_takenembedding_longepochgeneration_position0.png', dpi=500)\n",
    "    #plt.savefig('./minibatchfps200_take300_predict900_positionalvalue3.png', dpi=500)\n",
    "    print('Saved visualization figure at {}'.format('./test.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aead8be",
   "metadata": {},
   "source": [
    "## Predicting longer timescales with combining minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # sample from trajectorys' approx. posterior\n",
    "\n",
    "    ts_pos = np.linspace(0, np.pi*2, num=50)\n",
    "    ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "    #ts_neg = np.linspace(-np.pi*20, 0., num=400)[::-1].copy()\n",
    "    #ts_neg = torch.from_numpy(ts_neg).float().to(device)\n",
    "    \n",
    "    h = rec.initHidden().to(device)\n",
    "    for t in reversed(range(samp_trajs.size(1))):\n",
    "        obs = samp_trajs[:, t, :]\n",
    "        out, h = rec.forward(obs, h)\n",
    "    qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "    epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "    # forward in time and solve ode for reconstructions\n",
    "    pred_z = odeint(func, z0, ts_pos).permute(1, 0, 2)\n",
    "    pred_x = dec(pred_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1218877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    samp_ts_forgraph = samp_ts.detach().cpu().numpy()\n",
    "    pred_x = pred_x.reshape(64, 1500, 46)\n",
    "    pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "    samp_trajs = samp_trajs.reshape(64, 300, 46)\n",
    "    samp_trajs_forgraph = samp_trajs.detach().cpu().numpy()\n",
    "    ts_pos_forgraph = ts_pos.detach().cpu().numpy()\n",
    "    samp_ts_combined = np.linspace(0, 299, num=300)\n",
    "    ts_pos_combined = np.linspace(0, 1499, num=1500) \n",
    "    \n",
    "    times_index = 0\n",
    "    positional_value = 3\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 9))\n",
    "    axes = axes.flatten()\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.scatter(samp_ts_combined[times_index:+300], samp_trajs_forgraph[i,times_index:+300, positional_value], label='sampled data', s = 5)\n",
    "        ax.plot(ts_pos_combined[times_index:+1200], pred_x_forgraph[i, times_index:+1200, positional_value], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('./1200.png', dpi=500)\n",
    "    #plt.savefig('./minibatchfps200_take300_predict900_positionalvalue3.png', dpi=500)\n",
    "    print('Saved visualization figure at {}'.format('./test.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce562e47",
   "metadata": {},
   "source": [
    "## Predicting longer timescales: looking at each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07acaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    samp_ts_forgraph = samp_ts.detach().cpu().numpy()\n",
    "    pred_x_forgraph = pred_x.detach().cpu().numpy()\n",
    "    samp_trajs_forgraph = samp_trajs.detach().cpu().numpy()\n",
    "    ts_pos_forgraph = ts_pos.detach().cpu().numpy()\n",
    "    \n",
    "    times_index = 0\n",
    "    positional_value = 0\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 9))\n",
    "    axes = axes.flatten()\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.scatter(samp_ts_combined[times_index:+50], samp_trajs_forgraph[i,times_index:+50, positional_value], label='sampled data', s = 5)\n",
    "        ax.plot(ts_pos_combined[times_index:+250], pred_x_forgraph[i, times_index:+250, positional_value], 'r',\n",
    "                 label='learned trajectory (t>0)')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('./test.png', dpi=500)\n",
    "    print('Saved visualization figure at {}'.format('./test.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645eb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df32fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d48b4c",
   "metadata": {},
   "source": [
    "## PCA for z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c2137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ts_pos = np.linspace(0, np.pi*2*5, num=250)\n",
    "    ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
    "    \n",
    "    h = torch.zeros(samp_trajs.shape[0], rnn_nhidden).to(device)\n",
    "    \n",
    "    for t in reversed(range(samp_trajs.size(1))):\n",
    "        obs = samp_trajs[:, t, :]\n",
    "        out, h = rec.forward(obs, h)\n",
    "    qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "    epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "    z0 = z0.cpu()\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(z0.cpu())\n",
    "    print(\"Explained variance:\", pca.explained_variance_ratio_)\n",
    "    z0_red = pca.fit_transform(z0)\n",
    "    \n",
    "    print(z0_red[:, 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = z0.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169773f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(z0.cpu())\n",
    "    print(\"Explained variance:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75131b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_z = PCA(n_components=2)\n",
    "pca.fit(z0)\n",
    "\n",
    "z0_red = pca.fit_transform(z0)\n",
    "\n",
    "d = {'PC1': z0_red[:, 0], 'PC2': z0_red[:, 1]}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(z0_red[:, 0], z0_red[:, 1], 'o', label='z0 samples in 2D', linewidth=2, zorder=1)\n",
    "plt.legend()\n",
    "plt.savefig('./PCAgraph.png', dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea75b1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021888d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83863d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(data_subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
